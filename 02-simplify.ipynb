{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f5aaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRECIPITATION</th>\n",
       "      <th>MAX_TEMP</th>\n",
       "      <th>MIN_TEMP</th>\n",
       "      <th>AVG_WIND_SPEED</th>\n",
       "      <th>FIRE_START_DAY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TEMP_RANGE</th>\n",
       "      <th>WIND_TEMP_RATIO</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>LAGGED_PRECIPITATION</th>\n",
       "      <th>LAGGED_AVG_WIND_SPEED</th>\n",
       "      <th>DAY_OF_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>False</td>\n",
       "      <td>1984</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.059494</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>False</td>\n",
       "      <td>1984</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.078732</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5.37</td>\n",
       "      <td>False</td>\n",
       "      <td>1984</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.076714</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>False</td>\n",
       "      <td>1984</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.090</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>5.14</td>\n",
       "      <td>False</td>\n",
       "      <td>1984</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.069459</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  PRECIPITATION  MAX_TEMP  MIN_TEMP  AVG_WIND_SPEED  \\\n",
       "0  1984-01-01            0.0      79.0      51.0            4.70   \n",
       "1  1984-01-02            0.0      71.0      46.0            5.59   \n",
       "2  1984-01-03            0.0      70.0      47.0            5.37   \n",
       "3  1984-01-04            0.0      76.0      45.0            4.70   \n",
       "4  1984-01-05            0.0      74.0      49.0            5.14   \n",
       "\n",
       "   FIRE_START_DAY  YEAR  TEMP_RANGE  WIND_TEMP_RATIO  MONTH  SEASON  \\\n",
       "0           False  1984        28.0         0.059494      1  Winter   \n",
       "1           False  1984        25.0         0.078732      1  Winter   \n",
       "2           False  1984        23.0         0.076714      1  Winter   \n",
       "3           False  1984        31.0         0.061842      1  Winter   \n",
       "4           False  1984        25.0         0.069459      1  Winter   \n",
       "\n",
       "   LAGGED_PRECIPITATION  LAGGED_AVG_WIND_SPEED  DAY_OF_YEAR  \n",
       "0                   0.0                  4.700            1  \n",
       "1                   0.0                  5.145            2  \n",
       "2                   0.0                  5.220            3  \n",
       "3                   0.0                  5.090            4  \n",
       "4                   0.0                  5.100            5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 讀取資料\n",
    "df = pd.read_csv('data/CA_Weather_Fire_Dataset_1984-2025.csv')\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade8477",
   "metadata": {},
   "source": [
    "| 欄位名稱               | 說明                                                                 |\n",
    "|------------------------|----------------------------------------------------------------------|\n",
    "| DATE                   | 當天的觀測日期                                                       |\n",
    "| PRECIPITATION          | 每日降水量（英吋）                                                   |\n",
    "| MAX_TEMP               | 每日最高氣溫（華氏）                                                 |\n",
    "| MIN_TEMP               | 每日最低氣溫（華氏）                                                 |\n",
    "| AVG_WIND_SPEED         | 每日平均風速（英里/小時）                                           |\n",
    "| FIRE_START_DAY         | 是否於該日發生野火（布林值：True/False）                            |\n",
    "| YEAR                   | 年份                                                                 |\n",
    "| TEMP_RANGE             | 當日最高與最低溫差，反映氣溫變化程度                                |\n",
    "| WIND_TEMP_RATIO        | 平均風速與最高溫度的比值，捕捉風與溫度間的動態關係                  |\n",
    "| MONTH                  | 月份（1–12）                                                        |\n",
    "| SEASON                 | 季節（Winter, Spring, Summer, Fall）                                |\n",
    "| LAGGED_PRECIPITATION   | 前 7 天的累積降水量，反映近一週的濕潤條件                            |\n",
    "| LAGGED_AVG_WIND_SPEED  | 前 7 天的平均風速，反映持續的風力狀況                                |\n",
    "| DAY_OF_YEAR            | 當年度中的天數（1–365 或 366）                                     |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5005b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 刪除欄位\n",
    "df = df.drop(columns=['DATE'])\n",
    "df = df.drop(columns=['DAY_OF_YEAR'])\n",
    "\n",
    "# 將 FIRE_START_DAY 轉為整數型（0 或 1）\n",
    "df['FIRE_START_DAY'] = df['FIRE_START_DAY'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0552091c",
   "metadata": {},
   "source": [
    "- 根據[NOAA](https://www.noaa.gov/noaa-wildfire)\n",
    "- 和[Climate](https://www.climate.gov/news-features/event-tracker/weather-and-climate-influences-january-2025-fires-around-los-angeles)\n",
    "\n",
    "### 1. 氣溫變異指數（Temperature Variation Index）  \n",
    "\n",
    "| **項目**      | **內容**                                                                                   |\n",
    "|---------------|--------------------------------------------------------------------------------------------|\n",
    "| **定義**      | 每日氣溫的變異程度，反映當天最高和最低氣溫之間的差異。較大的溫差可能與氣候極端性相關，進一步加劇火災風險。 |\n",
    "| **公式**      | `TEMP_VARIATION = MAX_TEMP - MIN_TEMP`                                                     |\n",
    "\n",
    "### 2. 降水與風速比率（Precipitation-Wind Ratio）  \n",
    "\n",
    "| **項目**      | **內容**                                                                                   |\n",
    "|---------------|--------------------------------------------------------------------------------------------|\n",
    "| **定義**      | 衡量降水量與風速之間的關聯。當降水量低且風速高時，通常意味著乾燥條件與強風並存，火災風險上升。            |\n",
    "| **公式**      | `PRECIPITATION_WIND_RATIO = PRECIPITATION / AVG_WIND_SPEED`                                |\n",
    "\n",
    "### 3. 季節性降水與風速關聯指數（Seasonal Precipitation-Wind Index）  \n",
    "\n",
    "| **項目**      | **內容**                                                                                   |\n",
    "|---------------|--------------------------------------------------------------------------------------------|\n",
    "| **定義**      | 綜合考量季節（SEASON）對降水與風速影響的指標。不同季節降水和風速的組合，會對火災風險產生不同作用。          |\n",
    "| **公式**      | `SEASONAL_PRECIP_WIND = (PRECIPITATION * (SEASON == 'Winter')) + (AVG_WIND_SPEED * (SEASON == 'Summer'))` |\n",
    "\n",
    "### 4. 季節性乾燥指數（Seasonal Dryness Index）  \n",
    "\n",
    "| **項目**      | **內容**                                                                                   |\n",
    "|---------------|--------------------------------------------------------------------------------------------|\n",
    "| **定義**      | 根據當季（秋季或冬季）的降水量與日溫差來評估乾燥程度。乾燥季節中的高乾燥值與火災風險高度相關。             |\n",
    "| **公式**      | `SEASONAL_DRYNESS = (PRECIPITATION * (SEASON == 'Fall' or SEASON == 'Winter')) / (MAX_TEMP - MIN_TEMP)` |\n",
    "\n",
    "### 5. 日中溫差與風速結合指數（Diurnal Temperature and Wind Speed Index） \n",
    "\n",
    "| **項目**      | **內容**                                                                                   |\n",
    "|---------------|--------------------------------------------------------------------------------------------|\n",
    "| **定義**      | 此指標將每日的氣溫差（即日間溫度變化）與風速結合，評估乾燥和高風速的條件下，火災風險的潛在性。            |\n",
    "| **公式**      | `DIURNAL_TEMP_WIND = (MAX_TEMP - MIN_TEMP) * AVG_WIND_SPEED` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "819cab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# 我分析而得的衍生指標 :\n",
    "'''\n",
    "df['TEMP_VARIATION'] = df['MAX_TEMP'] - df['MIN_TEMP']\n",
    "df['PRECIPITATION_WIND_RATIO'] = df['PRECIPITATION'] / df['AVG_WIND_SPEED']\n",
    "df['SEASONAL_PRECIP_WIND'] = (df['PRECIPITATION'] * (df['SEASON'] == 'Winter')) + (df['AVG_WIND_SPEED'] * (df['SEASON'] == 'Summer'))\n",
    "df['SEASONAL_DRYNESS'] = (df['PRECIPITATION'] * ((df['SEASON'] == 'Fall') | (df['SEASON'] == 'Winter'))) / (df['MAX_TEMP'] - df['MIN_TEMP'])\n",
    "df['DIURNAL_TEMP_WIND'] = (df['MAX_TEMP'] - df['MIN_TEMP']) * df['AVG_WIND_SPEED']\n",
    "\n",
    "'''\n",
    "\n",
    "# One-Hot Encoding: SEASON\n",
    "df = pd.get_dummies(df, columns=['SEASON'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54a4cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徵與目標分離\n",
    "X = df.drop(['FIRE_START_DAY'], axis=1)\n",
    "y = df['FIRE_START_DAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb46795",
   "metadata": {},
   "source": [
    "2. 數值特徵標準化（Standardization）\n",
    "為避免某些欄位（如溫度或風速）對模型訓練造成不公平的權重，我們可以對所有數值特徵做 **Z-score** 標準化 **（均值為0，標準差為1）**，但不包含 One-Hot 欄位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38bb768e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 找出所有數值欄位（排除 one-hot 和目標變數）\n",
    "numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# 建立標準化物件並套用於訓練集和測試集\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b7cd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14988 entries, 0 to 14987\n",
      "Data columns (total 14 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   PRECIPITATION          14987 non-null  float64\n",
      " 1   MAX_TEMP               14987 non-null  float64\n",
      " 2   MIN_TEMP               14987 non-null  float64\n",
      " 3   AVG_WIND_SPEED         14976 non-null  float64\n",
      " 4   YEAR                   14988 non-null  float64\n",
      " 5   TEMP_RANGE             14987 non-null  float64\n",
      " 6   WIND_TEMP_RATIO        14976 non-null  float64\n",
      " 7   MONTH                  14988 non-null  float64\n",
      " 8   LAGGED_PRECIPITATION   14988 non-null  float64\n",
      " 9   LAGGED_AVG_WIND_SPEED  14988 non-null  float64\n",
      " 10  SEASON_Fall            14988 non-null  bool   \n",
      " 11  SEASON_Spring          14988 non-null  bool   \n",
      " 12  SEASON_Summer          14988 non-null  bool   \n",
      " 13  SEASON_Winter          14988 non-null  bool   \n",
      "dtypes: bool(4), float64(10)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "940a74e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECIPITATION             1\n",
      "MAX_TEMP                  1\n",
      "MIN_TEMP                  1\n",
      "AVG_WIND_SPEED           12\n",
      "YEAR                      0\n",
      "TEMP_RANGE                1\n",
      "WIND_TEMP_RATIO          12\n",
      "MONTH                     0\n",
      "LAGGED_PRECIPITATION      0\n",
      "LAGGED_AVG_WIND_SPEED     0\n",
      "SEASON_Fall               0\n",
      "SEASON_Spring             0\n",
      "SEASON_Summer             0\n",
      "SEASON_Winter             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7554559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.fillna(X.median())\n",
    "assert X.isna().sum().sum() == 0, \"There are still missing values in the dataset.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e398ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ba4b1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRE_START_DAY\n",
      "0    0.668335\n",
      "1    0.331665\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "75fdb62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/ygz08/Desktop/Git/localgit/MLOPs/Predictable_wildfire/mlruns/995565665349288736', creation_time=1746261086177, experiment_id='995565665349288736', last_update_time=1746261086177, lifecycle_stage='active', name='CA_Weather_Fire', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "mlflow.set_experiment(\"CA_Weather_Fire\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e192d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in run 7b02c83dbf85402eb203f028ae06e937\n",
      "Train score: 0.7556000381279192\n",
      "Test score: 0.7496108516788971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/03 17:41:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'LogisticRegression-model' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'LogisticRegression-model'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "with mlflow.start_run(run_name='LogisticRegression'):#mlflow\n",
    "    mlflow.tensorflow.autolog()#mlflow\n",
    "    max_iter=1000 \n",
    "    #mlflow.log_param(\"max_iter\", max_iter) #mlflow紀錄參數n_estimators\n",
    "# 方法四：使用 class_weight='balanced'\n",
    "    log_reg = LogisticRegression(max_iter=max_iter, class_weight='balanced')\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    run_id = mlflow.active_run().info.run_id#mlflow\n",
    "    print(f\"Model saved in run {run_id}\")#mlflow\n",
    "    \n",
    "\n",
    "    # 檢查訓練與測試分數\n",
    "    print(\"Train score:\", log_reg.score(X_train, y_train))\n",
    "    print(\"Test score:\", log_reg.score(X_test, y_test))\n",
    "\n",
    "    mlflow.log_metric(\"Train score\", log_reg.score(X_train, y_train))#mlflow\n",
    "    mlflow.log_metric(\"Test score\", log_reg.score(X_test, y_test))#mlflow\n",
    "\n",
    "\n",
    "    # 存檔模型mlflow\n",
    "    model_name = \"LogisticRegression-model\"\n",
    "    mlflow.sklearn.log_model(     #mlflow.sklearn.log_model() #紀錄sklearn模型\n",
    "        sk_model=log_reg, \n",
    "        artifact_path=\"LogisticRegression-model\",\n",
    "        registered_model_name=model_name,  #\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cdc51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46c0601b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization             │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/03 17:41:38 WARNING mlflow.tensorflow: Encountered unexpected error while inferring batch size from training dataset: Sequential model 'sequential' has no defined input shape yet.\n",
      "2025/05/03 17:41:38 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'pandas.core.frame.DataFrame'>. Dataset logging skipped.\n",
      "2025/05/03 17:41:38 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'DataFrame' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m77/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6352 - Recall: 0.5184 - acc: 0.7321 - loss: 0.5166"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 11ms/step - Precision: 0.6379 - Recall: 0.5233 - acc: 0.7345 - loss: 0.5139 - val_Precision: 0.6386 - val_Recall: 0.6338 - val_acc: 0.7663 - val_loss: 0.4740\n",
      "Epoch 2/100\n",
      "\u001b[1m69/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6851 - Recall: 0.6007 - acc: 0.7736 - loss: 0.4642"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - Precision: 0.6852 - Recall: 0.6000 - acc: 0.7736 - loss: 0.4647 - val_Precision: 0.6263 - val_Recall: 0.6448 - val_acc: 0.7614 - val_loss: 0.4727\n",
      "Epoch 3/100\n",
      "\u001b[1m75/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6571 - Recall: 0.5999 - acc: 0.7639 - loss: 0.4615"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - Precision: 0.6590 - Recall: 0.6000 - acc: 0.7645 - loss: 0.4616 - val_Precision: 0.6495 - val_Recall: 0.6455 - val_acc: 0.7734 - val_loss: 0.4660\n",
      "Epoch 4/100\n",
      "\u001b[1m72/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6770 - Recall: 0.6126 - acc: 0.7743 - loss: 0.4618"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - Precision: 0.6775 - Recall: 0.6129 - acc: 0.7742 - loss: 0.4616 - val_Precision: 0.6614 - val_Recall: 0.5766 - val_acc: 0.7683 - val_loss: 0.4624\n",
      "Epoch 5/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6802 - Recall: 0.6190 - acc: 0.7764 - loss: 0.4546 - val_Precision: 0.6556 - val_Recall: 0.6407 - val_acc: 0.7756 - val_loss: 0.4660\n",
      "Epoch 6/100\n",
      "\u001b[1m71/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6790 - Recall: 0.6323 - acc: 0.7760 - loss: 0.4639"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - Precision: 0.6795 - Recall: 0.6323 - acc: 0.7761 - loss: 0.4631 - val_Precision: 0.6740 - val_Recall: 0.5703 - val_acc: 0.7725 - val_loss: 0.4591\n",
      "Epoch 7/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7008 - Recall: 0.6203 - acc: 0.7821 - loss: 0.4492 - val_Precision: 0.6519 - val_Recall: 0.6483 - val_acc: 0.7750 - val_loss: 0.4596\n",
      "Epoch 8/100\n",
      "\u001b[1m79/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6841 - Recall: 0.6340 - acc: 0.7810 - loss: 0.4475"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6843 - Recall: 0.6339 - acc: 0.7809 - loss: 0.4478 - val_Precision: 0.6672 - val_Recall: 0.5752 - val_acc: 0.7705 - val_loss: 0.4571\n",
      "Epoch 9/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6881 - Recall: 0.6202 - acc: 0.7817 - loss: 0.4466 - val_Precision: 0.6860 - val_Recall: 0.5379 - val_acc: 0.7716 - val_loss: 0.4589\n",
      "Epoch 10/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7003 - Recall: 0.6072 - acc: 0.7804 - loss: 0.4468 - val_Precision: 0.6622 - val_Recall: 0.6434 - val_acc: 0.7792 - val_loss: 0.4594\n",
      "Epoch 11/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7062 - Recall: 0.6529 - acc: 0.7880 - loss: 0.4421 - val_Precision: 0.6637 - val_Recall: 0.6586 - val_acc: 0.7823 - val_loss: 0.4581\n",
      "Epoch 12/100\n",
      "\u001b[1m78/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6891 - Recall: 0.6497 - acc: 0.7840 - loss: 0.4416"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6889 - Recall: 0.6484 - acc: 0.7836 - loss: 0.4420 - val_Precision: 0.6603 - val_Recall: 0.6676 - val_acc: 0.7821 - val_loss: 0.4566\n",
      "Epoch 13/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6819 - Recall: 0.6387 - acc: 0.7752 - loss: 0.4578 - val_Precision: 0.7032 - val_Recall: 0.5703 - val_acc: 0.7839 - val_loss: 0.4610\n",
      "Epoch 14/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6851 - Recall: 0.6402 - acc: 0.7824 - loss: 0.4480 - val_Precision: 0.6674 - val_Recall: 0.6103 - val_acc: 0.7763 - val_loss: 0.4603\n",
      "Epoch 15/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7137 - Recall: 0.6271 - acc: 0.7860 - loss: 0.4424 - val_Precision: 0.6548 - val_Recall: 0.6621 - val_acc: 0.7785 - val_loss: 0.4605\n",
      "Epoch 16/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6843 - Recall: 0.6591 - acc: 0.7860 - loss: 0.4388 - val_Precision: 0.6736 - val_Recall: 0.6262 - val_acc: 0.7816 - val_loss: 0.4578\n",
      "Epoch 17/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6699 - Recall: 0.6480 - acc: 0.7751 - loss: 0.4492 - val_Precision: 0.6687 - val_Recall: 0.6152 - val_acc: 0.7776 - val_loss: 0.4582\n",
      "Epoch 18/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6978 - Recall: 0.6493 - acc: 0.7910 - loss: 0.4317 - val_Precision: 0.6580 - val_Recall: 0.6607 - val_acc: 0.7799 - val_loss: 0.4577\n",
      "Epoch 19/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7019 - Recall: 0.6659 - acc: 0.7890 - loss: 0.4385 - val_Precision: 0.7103 - val_Recall: 0.5276 - val_acc: 0.7783 - val_loss: 0.4633\n",
      "Epoch 20/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6898 - Recall: 0.6401 - acc: 0.7853 - loss: 0.4399 - val_Precision: 0.6808 - val_Recall: 0.6297 - val_acc: 0.7854 - val_loss: 0.4569\n",
      "Epoch 21/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6837 - Recall: 0.6704 - acc: 0.7849 - loss: 0.4387 - val_Precision: 0.6853 - val_Recall: 0.6186 - val_acc: 0.7854 - val_loss: 0.4578\n",
      "Epoch 22/100\n",
      "\u001b[1m78/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6968 - Recall: 0.6595 - acc: 0.7869 - loss: 0.4332"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6967 - Recall: 0.6591 - acc: 0.7869 - loss: 0.4334 - val_Precision: 0.6890 - val_Recall: 0.6110 - val_acc: 0.7856 - val_loss: 0.4545\n",
      "Epoch 23/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6972 - Recall: 0.6509 - acc: 0.7898 - loss: 0.4366 - val_Precision: 0.6567 - val_Recall: 0.6662 - val_acc: 0.7801 - val_loss: 0.4606\n",
      "Epoch 24/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6935 - Recall: 0.6698 - acc: 0.7921 - loss: 0.4298 - val_Precision: 0.6641 - val_Recall: 0.6421 - val_acc: 0.7799 - val_loss: 0.4574\n",
      "Epoch 25/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6904 - Recall: 0.6552 - acc: 0.7891 - loss: 0.4333 - val_Precision: 0.6412 - val_Recall: 0.6669 - val_acc: 0.7723 - val_loss: 0.4660\n",
      "Epoch 26/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6895 - Recall: 0.6843 - acc: 0.7859 - loss: 0.4360 - val_Precision: 0.6927 - val_Recall: 0.6062 - val_acc: 0.7863 - val_loss: 0.4565\n",
      "Epoch 27/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6999 - Recall: 0.6723 - acc: 0.7927 - loss: 0.4288 - val_Precision: 0.6868 - val_Recall: 0.5807 - val_acc: 0.7794 - val_loss: 0.4615\n",
      "Epoch 28/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7038 - Recall: 0.6376 - acc: 0.7888 - loss: 0.4336 - val_Precision: 0.6548 - val_Recall: 0.6828 - val_acc: 0.7816 - val_loss: 0.4660\n",
      "Epoch 29/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7023 - Recall: 0.6737 - acc: 0.7939 - loss: 0.4270 - val_Precision: 0.6778 - val_Recall: 0.5993 - val_acc: 0.7790 - val_loss: 0.4639\n",
      "Epoch 30/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6896 - Recall: 0.6736 - acc: 0.7890 - loss: 0.4309 - val_Precision: 0.6552 - val_Recall: 0.6697 - val_acc: 0.7799 - val_loss: 0.4729\n",
      "Epoch 31/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7067 - Recall: 0.6806 - acc: 0.8000 - loss: 0.4157 - val_Precision: 0.6574 - val_Recall: 0.6510 - val_acc: 0.7781 - val_loss: 0.4609\n",
      "Epoch 32/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6946 - Recall: 0.6671 - acc: 0.7880 - loss: 0.4365 - val_Precision: 0.6627 - val_Recall: 0.6490 - val_acc: 0.7803 - val_loss: 0.4621\n",
      "Epoch 33/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6989 - Recall: 0.6998 - acc: 0.7950 - loss: 0.4185 - val_Precision: 0.6723 - val_Recall: 0.6028 - val_acc: 0.7772 - val_loss: 0.4618\n",
      "Epoch 34/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7132 - Recall: 0.6459 - acc: 0.7957 - loss: 0.4189 - val_Precision: 0.6496 - val_Recall: 0.6469 - val_acc: 0.7736 - val_loss: 0.4697\n",
      "Epoch 35/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7105 - Recall: 0.6474 - acc: 0.7949 - loss: 0.4226 - val_Precision: 0.6697 - val_Recall: 0.6572 - val_acc: 0.7850 - val_loss: 0.4609\n",
      "Epoch 36/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6908 - Recall: 0.6836 - acc: 0.7895 - loss: 0.4257 - val_Precision: 0.6766 - val_Recall: 0.6276 - val_acc: 0.7832 - val_loss: 0.4651\n",
      "Epoch 37/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7119 - Recall: 0.6839 - acc: 0.8004 - loss: 0.4129 - val_Precision: 0.6779 - val_Recall: 0.6083 - val_acc: 0.7805 - val_loss: 0.4630\n",
      "Epoch 38/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7138 - Recall: 0.6563 - acc: 0.7955 - loss: 0.4235 - val_Precision: 0.6694 - val_Recall: 0.6269 - val_acc: 0.7799 - val_loss: 0.4662\n",
      "Epoch 39/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7038 - Recall: 0.6778 - acc: 0.7929 - loss: 0.4208 - val_Precision: 0.6901 - val_Recall: 0.5683 - val_acc: 0.7785 - val_loss: 0.4744\n",
      "Epoch 40/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7057 - Recall: 0.6639 - acc: 0.7932 - loss: 0.4193 - val_Precision: 0.6741 - val_Recall: 0.5821 - val_acc: 0.7745 - val_loss: 0.4765\n",
      "Epoch 41/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7116 - Recall: 0.6675 - acc: 0.7983 - loss: 0.4229 - val_Precision: 0.6657 - val_Recall: 0.6221 - val_acc: 0.7774 - val_loss: 0.4664\n",
      "Epoch 42/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7178 - Recall: 0.6666 - acc: 0.8008 - loss: 0.4137 - val_Precision: 0.6568 - val_Recall: 0.6255 - val_acc: 0.7738 - val_loss: 0.4729\n",
      "Epoch 43/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7207 - Recall: 0.6685 - acc: 0.7994 - loss: 0.4153 - val_Precision: 0.6459 - val_Recall: 0.6593 - val_acc: 0.7736 - val_loss: 0.4733\n",
      "Epoch 44/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7088 - Recall: 0.6840 - acc: 0.8021 - loss: 0.4044 - val_Precision: 0.6345 - val_Recall: 0.6717 - val_acc: 0.7694 - val_loss: 0.4758\n",
      "Epoch 45/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7075 - Recall: 0.6941 - acc: 0.7937 - loss: 0.4224 - val_Precision: 0.6829 - val_Recall: 0.5600 - val_acc: 0.7743 - val_loss: 0.4738\n",
      "Epoch 46/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7338 - Recall: 0.6553 - acc: 0.8034 - loss: 0.4100 - val_Precision: 0.6669 - val_Recall: 0.6324 - val_acc: 0.7796 - val_loss: 0.4683\n",
      "Epoch 47/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7263 - Recall: 0.6732 - acc: 0.8024 - loss: 0.4033 - val_Precision: 0.6745 - val_Recall: 0.6131 - val_acc: 0.7799 - val_loss: 0.4697\n",
      "Epoch 48/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7274 - Recall: 0.6818 - acc: 0.8062 - loss: 0.4064 - val_Precision: 0.6423 - val_Recall: 0.6538 - val_acc: 0.7710 - val_loss: 0.4801\n",
      "Epoch 49/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7125 - Recall: 0.6907 - acc: 0.7996 - loss: 0.4111 - val_Precision: 0.6697 - val_Recall: 0.6041 - val_acc: 0.7763 - val_loss: 0.4757\n",
      "Epoch 50/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7467 - Recall: 0.6785 - acc: 0.8127 - loss: 0.3999 - val_Precision: 0.6798 - val_Recall: 0.5945 - val_acc: 0.7790 - val_loss: 0.4695\n",
      "Epoch 51/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7184 - Recall: 0.6631 - acc: 0.8024 - loss: 0.4019 - val_Precision: 0.6566 - val_Recall: 0.6290 - val_acc: 0.7743 - val_loss: 0.4760\n",
      "Epoch 52/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7181 - Recall: 0.6719 - acc: 0.8022 - loss: 0.4080 - val_Precision: 0.6453 - val_Recall: 0.6724 - val_acc: 0.7752 - val_loss: 0.4780\n",
      "Epoch 53/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7011 - Recall: 0.7023 - acc: 0.8025 - loss: 0.4009 - val_Precision: 0.6473 - val_Recall: 0.6697 - val_acc: 0.7759 - val_loss: 0.4876\n",
      "Epoch 54/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7435 - Recall: 0.7018 - acc: 0.8153 - loss: 0.3862 - val_Precision: 0.6381 - val_Recall: 0.6566 - val_acc: 0.7692 - val_loss: 0.4893\n",
      "Epoch 55/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7064 - Recall: 0.6912 - acc: 0.7996 - loss: 0.4046 - val_Precision: 0.6594 - val_Recall: 0.6221 - val_acc: 0.7745 - val_loss: 0.4798\n",
      "Epoch 56/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7102 - Recall: 0.6835 - acc: 0.8004 - loss: 0.4044 - val_Precision: 0.6601 - val_Recall: 0.6697 - val_acc: 0.7823 - val_loss: 0.4747\n",
      "Epoch 57/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7158 - Recall: 0.6966 - acc: 0.8088 - loss: 0.3948 - val_Precision: 0.6589 - val_Recall: 0.6276 - val_acc: 0.7752 - val_loss: 0.4798\n",
      "Epoch 58/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7310 - Recall: 0.6919 - acc: 0.8097 - loss: 0.3939 - val_Precision: 0.6628 - val_Recall: 0.5855 - val_acc: 0.7703 - val_loss: 0.4831\n",
      "Epoch 59/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7306 - Recall: 0.6950 - acc: 0.8092 - loss: 0.3905 - val_Precision: 0.6475 - val_Recall: 0.6131 - val_acc: 0.7676 - val_loss: 0.4894\n",
      "Epoch 60/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - Precision: 0.7272 - Recall: 0.6927 - acc: 0.8148 - loss: 0.3825 - val_Precision: 0.6472 - val_Recall: 0.6200 - val_acc: 0.7685 - val_loss: 0.4880\n",
      "Epoch 61/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7146 - Recall: 0.6869 - acc: 0.8062 - loss: 0.3944 - val_Precision: 0.6589 - val_Recall: 0.6048 - val_acc: 0.7716 - val_loss: 0.4996\n",
      "Epoch 62/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7279 - Recall: 0.6971 - acc: 0.8105 - loss: 0.3884 - val_Precision: 0.6641 - val_Recall: 0.5986 - val_acc: 0.7730 - val_loss: 0.4921\n",
      "Epoch 63/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7323 - Recall: 0.6726 - acc: 0.8044 - loss: 0.3992 - val_Precision: 0.6608 - val_Recall: 0.6434 - val_acc: 0.7785 - val_loss: 0.4953\n",
      "Epoch 64/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7326 - Recall: 0.7001 - acc: 0.8148 - loss: 0.3886 - val_Precision: 0.6314 - val_Recall: 0.6510 - val_acc: 0.7650 - val_loss: 0.4973\n",
      "Epoch 65/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7369 - Recall: 0.7050 - acc: 0.8141 - loss: 0.3893 - val_Precision: 0.6560 - val_Recall: 0.5814 - val_acc: 0.7667 - val_loss: 0.4938\n",
      "Epoch 66/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7403 - Recall: 0.6715 - acc: 0.8126 - loss: 0.3898 - val_Precision: 0.6523 - val_Recall: 0.6352 - val_acc: 0.7732 - val_loss: 0.4888\n",
      "Epoch 67/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7229 - Recall: 0.6903 - acc: 0.8101 - loss: 0.3783 - val_Precision: 0.6460 - val_Recall: 0.6483 - val_acc: 0.7721 - val_loss: 0.4953\n",
      "Epoch 68/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7348 - Recall: 0.7054 - acc: 0.8135 - loss: 0.3776 - val_Precision: 0.6608 - val_Recall: 0.6007 - val_acc: 0.7718 - val_loss: 0.4986\n",
      "Epoch 69/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7347 - Recall: 0.6962 - acc: 0.8131 - loss: 0.3936 - val_Precision: 0.6793 - val_Recall: 0.5669 - val_acc: 0.7741 - val_loss: 0.4996\n",
      "Epoch 70/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7387 - Recall: 0.7012 - acc: 0.8145 - loss: 0.3832 - val_Precision: 0.6509 - val_Recall: 0.6262 - val_acc: 0.7712 - val_loss: 0.5051\n",
      "Epoch 71/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7318 - Recall: 0.7025 - acc: 0.8097 - loss: 0.3858 - val_Precision: 0.6778 - val_Recall: 0.5455 - val_acc: 0.7698 - val_loss: 0.5025\n",
      "Epoch 72/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7340 - Recall: 0.6851 - acc: 0.8085 - loss: 0.3797 - val_Precision: 0.6501 - val_Recall: 0.6497 - val_acc: 0.7743 - val_loss: 0.5097\n",
      "Epoch 73/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7208 - Recall: 0.7017 - acc: 0.8136 - loss: 0.3794 - val_Precision: 0.6308 - val_Recall: 0.6434 - val_acc: 0.7636 - val_loss: 0.5051\n",
      "Epoch 74/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7253 - Recall: 0.7144 - acc: 0.8166 - loss: 0.3763 - val_Precision: 0.6486 - val_Recall: 0.6441 - val_acc: 0.7727 - val_loss: 0.5155\n",
      "Epoch 75/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7253 - Recall: 0.6997 - acc: 0.8079 - loss: 0.3812 - val_Precision: 0.6540 - val_Recall: 0.6297 - val_acc: 0.7732 - val_loss: 0.5072\n",
      "Epoch 76/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7505 - Recall: 0.7175 - acc: 0.8208 - loss: 0.3756 - val_Precision: 0.6476 - val_Recall: 0.6262 - val_acc: 0.7696 - val_loss: 0.5123\n",
      "Epoch 77/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7378 - Recall: 0.7156 - acc: 0.8172 - loss: 0.3814 - val_Precision: 0.6283 - val_Recall: 0.6400 - val_acc: 0.7618 - val_loss: 0.5126\n",
      "Epoch 78/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7353 - Recall: 0.7114 - acc: 0.8167 - loss: 0.3776 - val_Precision: 0.6664 - val_Recall: 0.5814 - val_acc: 0.7712 - val_loss: 0.5079\n",
      "Epoch 79/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7433 - Recall: 0.6956 - acc: 0.8216 - loss: 0.3644 - val_Precision: 0.6368 - val_Recall: 0.6117 - val_acc: 0.7623 - val_loss: 0.5102\n",
      "Epoch 80/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - Precision: 0.7472 - Recall: 0.7102 - acc: 0.8229 - loss: 0.3693 - val_Precision: 0.6487 - val_Recall: 0.6241 - val_acc: 0.7698 - val_loss: 0.5174\n",
      "Epoch 81/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7537 - Recall: 0.6941 - acc: 0.8200 - loss: 0.3663 - val_Precision: 0.6403 - val_Recall: 0.5979 - val_acc: 0.7621 - val_loss: 0.5176\n",
      "Epoch 82/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7437 - Recall: 0.7030 - acc: 0.8193 - loss: 0.3645 - val_Precision: 0.6422 - val_Recall: 0.6324 - val_acc: 0.7678 - val_loss: 0.5198\n",
      "Epoch 83/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7403 - Recall: 0.7154 - acc: 0.8182 - loss: 0.3737 - val_Precision: 0.6546 - val_Recall: 0.5972 - val_acc: 0.7685 - val_loss: 0.5072\n",
      "Epoch 84/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7432 - Recall: 0.6974 - acc: 0.8191 - loss: 0.3593 - val_Precision: 0.6451 - val_Recall: 0.6407 - val_acc: 0.7705 - val_loss: 0.5188\n",
      "Epoch 85/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7436 - Recall: 0.7238 - acc: 0.8203 - loss: 0.3681 - val_Precision: 0.6545 - val_Recall: 0.5959 - val_acc: 0.7683 - val_loss: 0.5171\n",
      "Epoch 86/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7477 - Recall: 0.7135 - acc: 0.8232 - loss: 0.3682 - val_Precision: 0.6527 - val_Recall: 0.6000 - val_acc: 0.7681 - val_loss: 0.5256\n",
      "Epoch 87/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7405 - Recall: 0.6927 - acc: 0.8190 - loss: 0.3634 - val_Precision: 0.6389 - val_Recall: 0.6297 - val_acc: 0.7658 - val_loss: 0.5251\n",
      "Epoch 88/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7314 - Recall: 0.7181 - acc: 0.8178 - loss: 0.3617 - val_Precision: 0.6489 - val_Recall: 0.6117 - val_acc: 0.7681 - val_loss: 0.5232\n",
      "Epoch 89/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.7433 - Recall: 0.6990 - acc: 0.8181 - loss: 0.3618 - val_Precision: 0.6409 - val_Recall: 0.6228 - val_acc: 0.7658 - val_loss: 0.5239\n",
      "Epoch 90/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7431 - Recall: 0.7218 - acc: 0.8234 - loss: 0.3613 - val_Precision: 0.6150 - val_Recall: 0.6621 - val_acc: 0.7574 - val_loss: 0.5369\n",
      "Epoch 91/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7386 - Recall: 0.7343 - acc: 0.8263 - loss: 0.3678 - val_Precision: 0.6423 - val_Recall: 0.6552 - val_acc: 0.7712 - val_loss: 0.5289\n",
      "Epoch 92/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7374 - Recall: 0.7257 - acc: 0.8190 - loss: 0.3649 - val_Precision: 0.6400 - val_Recall: 0.6241 - val_acc: 0.7656 - val_loss: 0.5362\n",
      "Epoch 93/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7552 - Recall: 0.7277 - acc: 0.8258 - loss: 0.3563 - val_Precision: 0.6301 - val_Recall: 0.6214 - val_acc: 0.7603 - val_loss: 0.5421\n",
      "Epoch 94/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7559 - Recall: 0.7475 - acc: 0.8340 - loss: 0.3512 - val_Precision: 0.6529 - val_Recall: 0.5903 - val_acc: 0.7667 - val_loss: 0.5378\n",
      "Epoch 95/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7414 - Recall: 0.7153 - acc: 0.8174 - loss: 0.3654 - val_Precision: 0.6269 - val_Recall: 0.6628 - val_acc: 0.7641 - val_loss: 0.5385\n",
      "Epoch 96/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7317 - Recall: 0.7286 - acc: 0.8178 - loss: 0.3636 - val_Precision: 0.6492 - val_Recall: 0.6076 - val_acc: 0.7676 - val_loss: 0.5387\n",
      "Epoch 97/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7531 - Recall: 0.7259 - acc: 0.8246 - loss: 0.3593 - val_Precision: 0.6398 - val_Recall: 0.6234 - val_acc: 0.7654 - val_loss: 0.5380\n",
      "Epoch 98/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7538 - Recall: 0.7203 - acc: 0.8257 - loss: 0.3567 - val_Precision: 0.6333 - val_Recall: 0.6372 - val_acc: 0.7641 - val_loss: 0.5432\n",
      "Epoch 99/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7451 - Recall: 0.7448 - acc: 0.8288 - loss: 0.3494 - val_Precision: 0.6290 - val_Recall: 0.6172 - val_acc: 0.7592 - val_loss: 0.5455\n",
      "Epoch 100/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.7453 - Recall: 0.7387 - acc: 0.8316 - loss: 0.3506 - val_Precision: 0.6277 - val_Recall: 0.6372 - val_acc: 0.7612 - val_loss: 0.5464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/03 17:42:26 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: Cannot log input example or model signature for input with type <class 'pandas.core.frame.DataFrame'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n",
      "2025/05/03 17:42:26 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/05/03 17:42:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'DNN-model' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'DNN-model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - Precision: 0.6178 - Recall: 0.6213 - acc: 0.7516 - loss: 0.5785  \n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='DNN'):#mlflow\n",
    "    mlflow.tensorflow.autolog()#mlflow    \n",
    "\n",
    "    n_input = X_train.shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, input_shape=(n_input,), activation='relu'))\n",
    "    model.add(Dropout(0.1))  # 增加 Dropout 率，避免過擬合\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.1))  # Dropout 率可根據需要進行調整\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.1))  # Dropout 率可根據需要進行調整\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    # 模型optimizer 和 learning rate\n",
    "\n",
    "\n",
    "    initial_lr = 0.001\n",
    "    from tensorflow.keras.optimizers import schedules\n",
    "    lr_schedule = schedules.ExponentialDecay(\n",
    "        initial_learning_rate=initial_lr,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True)\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    optimizer = Adam(learning_rate=lr_schedule)\n",
    "    model.summary()\n",
    "\n",
    "    mlflow.log_param(\"loss\", 'bce') #mlflow\n",
    "    model.compile(loss='bce', optimizer=optimizer, metrics=['acc', 'Recall', 'Precision'])\n",
    "\n",
    "    # EarlyStopping: 根據 val_loss 停止訓練\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "    # ModelCheckpoint: 儲存最佳模型\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "    checkpoint = ModelCheckpoint('./models_temp/DNN_best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128, verbose=1)\n",
    "\n",
    "    train_loss, train_acc, train_recall, train_precision = model.evaluate(X_train, y_train, verbose=0)\n",
    "    test_loss, test_acc, test_recall, test_precision = model.evaluate(X_test, y_test, verbose=0)\n",
    "    mlflow.log_metric(\"Train score\", train_acc)#mlflow\n",
    "    mlflow.log_metric(\"Test score\", test_acc)#mlflow\n",
    "    #註冊模型\n",
    "    run_id = mlflow.active_run().info.run_id#mlflow\n",
    "    result = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run_id}/model\",  # 你要用 mlflow.log_model 存的位置\n",
    "        name=\"DNN-model\"              # 註冊後的 model name\n",
    "    )\n",
    "\n",
    "    \n",
    "    model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea275db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,920</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m)        │         \u001b[38;5;34m56\u001b[0m │ input_layer_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m1,920\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │     \u001b[38;5;34m66,048\u001b[0m │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,665</span> (330.72 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,665\u001b[0m (330.72 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,637</span> (330.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,637\u001b[0m (330.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28</span> (112.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m28\u001b[0m (112.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/03 17:42:33 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'pandas.core.frame.DataFrame'>. Dataset logging skipped.\n",
      "2025/05/03 17:42:33 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'DataFrame' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m75/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.6285 - Recall: 0.5388 - acc: 0.7340 - loss: 0.5300\n",
      "Epoch 1: val_loss improved from inf to 0.47534, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 14ms/step - Precision: 0.6309 - Recall: 0.5439 - acc: 0.7364 - loss: 0.5265 - val_Precision: 0.6659 - val_Recall: 0.5786 - val_acc: 0.7705 - val_loss: 0.4753\n",
      "Epoch 2/200\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.6843 - Recall: 0.6246 - acc: 0.7809 - loss: 0.4630\n",
      "Epoch 2: val_loss improved from 0.47534 to 0.46719, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.6843 - Recall: 0.6240 - acc: 0.7807 - loss: 0.4633 - val_Precision: 0.6620 - val_Recall: 0.5848 - val_acc: 0.7698 - val_loss: 0.4672\n",
      "Epoch 3/200\n",
      "\u001b[1m77/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.6664 - Recall: 0.6238 - acc: 0.7681 - loss: 0.4748\n",
      "Epoch 3: val_loss improved from 0.46719 to 0.46379, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6669 - Recall: 0.6234 - acc: 0.7683 - loss: 0.4745 - val_Precision: 0.6687 - val_Recall: 0.5917 - val_acc: 0.7738 - val_loss: 0.4638\n",
      "Epoch 4/200\n",
      "\u001b[1m74/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6837 - Recall: 0.6100 - acc: 0.7728 - loss: 0.4714\n",
      "Epoch 4: val_loss did not improve from 0.46379\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - Precision: 0.6837 - Recall: 0.6106 - acc: 0.7731 - loss: 0.4706 - val_Precision: 0.6696 - val_Recall: 0.5869 - val_acc: 0.7734 - val_loss: 0.4658\n",
      "Epoch 5/200\n",
      "\u001b[1m78/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6835 - Recall: 0.5899 - acc: 0.7715 - loss: 0.4630\n",
      "Epoch 5: val_loss did not improve from 0.46379\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6835 - Recall: 0.5902 - acc: 0.7715 - loss: 0.4631 - val_Precision: 0.6778 - val_Recall: 0.5862 - val_acc: 0.7767 - val_loss: 0.4660\n",
      "Epoch 6/200\n",
      "\u001b[1m74/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6873 - Recall: 0.5928 - acc: 0.7738 - loss: 0.4663\n",
      "Epoch 6: val_loss did not improve from 0.46379\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6874 - Recall: 0.5939 - acc: 0.7740 - loss: 0.4660 - val_Precision: 0.6489 - val_Recall: 0.6462 - val_acc: 0.7732 - val_loss: 0.4692\n",
      "Epoch 7/200\n",
      "\u001b[1m80/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6959 - Recall: 0.6320 - acc: 0.7858 - loss: 0.4529\n",
      "Epoch 7: val_loss improved from 0.46379 to 0.45996, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6956 - Recall: 0.6313 - acc: 0.7855 - loss: 0.4532 - val_Precision: 0.6950 - val_Recall: 0.5297 - val_acc: 0.7734 - val_loss: 0.4600\n",
      "Epoch 8/200\n",
      "\u001b[1m80/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6965 - Recall: 0.5977 - acc: 0.7806 - loss: 0.4534\n",
      "Epoch 8: val_loss did not improve from 0.45996\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6961 - Recall: 0.5978 - acc: 0.7804 - loss: 0.4537 - val_Precision: 0.6780 - val_Recall: 0.5503 - val_acc: 0.7707 - val_loss: 0.4620\n",
      "Epoch 9/200\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6777 - Recall: 0.5965 - acc: 0.7704 - loss: 0.4570\n",
      "Epoch 9: val_loss did not improve from 0.45996\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - Precision: 0.6778 - Recall: 0.5967 - acc: 0.7704 - loss: 0.4570 - val_Precision: 0.6947 - val_Recall: 0.5021 - val_acc: 0.7683 - val_loss: 0.4625\n",
      "Epoch 10/200\n",
      "\u001b[1m74/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6882 - Recall: 0.5817 - acc: 0.7765 - loss: 0.4516\n",
      "Epoch 10: val_loss did not improve from 0.45996\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6885 - Recall: 0.5843 - acc: 0.7765 - loss: 0.4522 - val_Precision: 0.6630 - val_Recall: 0.6297 - val_acc: 0.7774 - val_loss: 0.4616\n",
      "Epoch 11/200\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.6712 - Recall: 0.6361 - acc: 0.7757 - loss: 0.4582\n",
      "Epoch 11: val_loss did not improve from 0.45996\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6713 - Recall: 0.6358 - acc: 0.7757 - loss: 0.4583 - val_Precision: 0.6732 - val_Recall: 0.5966 - val_acc: 0.7765 - val_loss: 0.4617\n",
      "Epoch 12/200\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6882 - Recall: 0.6090 - acc: 0.7762 - loss: 0.4619\n",
      "Epoch 12: val_loss did not improve from 0.45996\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6883 - Recall: 0.6091 - acc: 0.7762 - loss: 0.4618 - val_Precision: 0.6725 - val_Recall: 0.5807 - val_acc: 0.7736 - val_loss: 0.4602\n",
      "Epoch 13/200\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6854 - Recall: 0.6444 - acc: 0.7768 - loss: 0.4568\n",
      "Epoch 13: val_loss improved from 0.45996 to 0.45822, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6853 - Recall: 0.6440 - acc: 0.7768 - loss: 0.4568 - val_Precision: 0.6847 - val_Recall: 0.5572 - val_acc: 0.7745 - val_loss: 0.4582\n",
      "Epoch 14/200\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6919 - Recall: 0.5859 - acc: 0.7780 - loss: 0.4614\n",
      "Epoch 14: val_loss did not improve from 0.45822\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6919 - Recall: 0.5861 - acc: 0.7780 - loss: 0.4613 - val_Precision: 0.6567 - val_Recall: 0.6503 - val_acc: 0.7776 - val_loss: 0.4650\n",
      "Epoch 15/200\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6838 - Recall: 0.6576 - acc: 0.7842 - loss: 0.4462\n",
      "Epoch 15: val_loss did not improve from 0.45822\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6838 - Recall: 0.6573 - acc: 0.7842 - loss: 0.4463 - val_Precision: 0.6740 - val_Recall: 0.5917 - val_acc: 0.7761 - val_loss: 0.4658\n",
      "Epoch 16/200\n",
      "\u001b[1m74/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.6919 - Recall: 0.6328 - acc: 0.7792 - loss: 0.4583\n",
      "Epoch 16: val_loss did not improve from 0.45822\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6915 - Recall: 0.6324 - acc: 0.7793 - loss: 0.4581 - val_Precision: 0.6458 - val_Recall: 0.6614 - val_acc: 0.7738 - val_loss: 0.4629\n",
      "Epoch 17/200\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6856 - Recall: 0.6241 - acc: 0.7797 - loss: 0.4559\n",
      "Epoch 17: val_loss improved from 0.45822 to 0.45613, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6856 - Recall: 0.6242 - acc: 0.7797 - loss: 0.4558 - val_Precision: 0.6802 - val_Recall: 0.6221 - val_acc: 0.7839 - val_loss: 0.4561\n",
      "Epoch 18/200\n",
      "\u001b[1m79/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6745 - Recall: 0.6050 - acc: 0.7683 - loss: 0.4600\n",
      "Epoch 18: val_loss did not improve from 0.45613\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6749 - Recall: 0.6054 - acc: 0.7686 - loss: 0.4599 - val_Precision: 0.6754 - val_Recall: 0.6069 - val_acc: 0.7792 - val_loss: 0.4578\n",
      "Epoch 19/200\n",
      "\u001b[1m80/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6919 - Recall: 0.6239 - acc: 0.7847 - loss: 0.4586\n",
      "Epoch 19: val_loss improved from 0.45613 to 0.45478, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6917 - Recall: 0.6244 - acc: 0.7846 - loss: 0.4584 - val_Precision: 0.6873 - val_Recall: 0.5897 - val_acc: 0.7812 - val_loss: 0.4548\n",
      "Epoch 20/200\n",
      "\u001b[1m78/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7059 - Recall: 0.6303 - acc: 0.7849 - loss: 0.4482\n",
      "Epoch 20: val_loss did not improve from 0.45478\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.7049 - Recall: 0.6296 - acc: 0.7845 - loss: 0.4484 - val_Precision: 0.7047 - val_Recall: 0.5069 - val_acc: 0.7725 - val_loss: 0.4570\n",
      "Epoch 21/200\n",
      "\u001b[1m74/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6946 - Recall: 0.6011 - acc: 0.7815 - loss: 0.4509\n",
      "Epoch 21: val_loss did not improve from 0.45478\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6948 - Recall: 0.6023 - acc: 0.7814 - loss: 0.4513 - val_Precision: 0.6548 - val_Recall: 0.6724 - val_acc: 0.7801 - val_loss: 0.4562\n",
      "Epoch 22/200\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6750 - Recall: 0.6239 - acc: 0.7775 - loss: 0.4496\n",
      "Epoch 22: val_loss did not improve from 0.45478\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6753 - Recall: 0.6238 - acc: 0.7775 - loss: 0.4497 - val_Precision: 0.6774 - val_Recall: 0.6255 - val_acc: 0.7832 - val_loss: 0.4582\n",
      "Epoch 23/200\n",
      "\u001b[1m74/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6880 - Recall: 0.6332 - acc: 0.7821 - loss: 0.4499\n",
      "Epoch 23: val_loss did not improve from 0.45478\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6881 - Recall: 0.6339 - acc: 0.7821 - loss: 0.4498 - val_Precision: 0.6876 - val_Recall: 0.5297 - val_acc: 0.7707 - val_loss: 0.4589\n",
      "Epoch 24/200\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7019 - Recall: 0.6039 - acc: 0.7792 - loss: 0.4520\n",
      "Epoch 24: val_loss did not improve from 0.45478\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.7017 - Recall: 0.6043 - acc: 0.7792 - loss: 0.4520 - val_Precision: 0.6789 - val_Recall: 0.5890 - val_acc: 0.7776 - val_loss: 0.4583\n",
      "Epoch 25/200\n",
      "\u001b[1m77/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6916 - Recall: 0.6086 - acc: 0.7717 - loss: 0.4592\n",
      "Epoch 25: val_loss did not improve from 0.45478\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6919 - Recall: 0.6090 - acc: 0.7723 - loss: 0.4585 - val_Precision: 0.6756 - val_Recall: 0.6062 - val_acc: 0.7792 - val_loss: 0.4573\n",
      "Epoch 26/200\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6983 - Recall: 0.6469 - acc: 0.7867 - loss: 0.4431\n",
      "Epoch 26: val_loss improved from 0.45478 to 0.45431, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6981 - Recall: 0.6467 - acc: 0.7867 - loss: 0.4432 - val_Precision: 0.6643 - val_Recall: 0.6414 - val_acc: 0.7799 - val_loss: 0.4543\n",
      "Epoch 27/200\n",
      "\u001b[1m79/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6961 - Recall: 0.6400 - acc: 0.7858 - loss: 0.4485\n",
      "Epoch 27: val_loss did not improve from 0.45431\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6961 - Recall: 0.6397 - acc: 0.7857 - loss: 0.4486 - val_Precision: 0.6827 - val_Recall: 0.5759 - val_acc: 0.7770 - val_loss: 0.4596\n",
      "Epoch 28/200\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6926 - Recall: 0.6095 - acc: 0.7813 - loss: 0.4456\n",
      "Epoch 28: val_loss improved from 0.45431 to 0.45335, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6926 - Recall: 0.6098 - acc: 0.7814 - loss: 0.4456 - val_Precision: 0.6701 - val_Recall: 0.6331 - val_acc: 0.7812 - val_loss: 0.4533\n",
      "Epoch 29/200\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6965 - Recall: 0.6413 - acc: 0.7832 - loss: 0.4487\n",
      "Epoch 29: val_loss did not improve from 0.45335\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - Precision: 0.6965 - Recall: 0.6412 - acc: 0.7833 - loss: 0.4487 - val_Precision: 0.6705 - val_Recall: 0.6372 - val_acc: 0.7821 - val_loss: 0.4624\n",
      "Epoch 30/200\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7078 - Recall: 0.6371 - acc: 0.7862 - loss: 0.4519\n",
      "Epoch 30: val_loss did not improve from 0.45335\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.7077 - Recall: 0.6370 - acc: 0.7862 - loss: 0.4518 - val_Precision: 0.6616 - val_Recall: 0.6352 - val_acc: 0.7776 - val_loss: 0.4548\n",
      "Epoch 31/200\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6892 - Recall: 0.6370 - acc: 0.7818 - loss: 0.4501\n",
      "Epoch 31: val_loss did not improve from 0.45335\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6894 - Recall: 0.6369 - acc: 0.7819 - loss: 0.4500 - val_Precision: 0.6937 - val_Recall: 0.5779 - val_acc: 0.7816 - val_loss: 0.4559\n",
      "Epoch 32/200\n",
      "\u001b[1m80/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.7063 - Recall: 0.6260 - acc: 0.7858 - loss: 0.4469\n",
      "Epoch 32: val_loss did not improve from 0.45335\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.7061 - Recall: 0.6263 - acc: 0.7858 - loss: 0.4469 - val_Precision: 0.6947 - val_Recall: 0.5759 - val_acc: 0.7816 - val_loss: 0.4634\n",
      "Epoch 33/200\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6828 - Recall: 0.6052 - acc: 0.7788 - loss: 0.4541\n",
      "Epoch 33: val_loss did not improve from 0.45335\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6830 - Recall: 0.6055 - acc: 0.7789 - loss: 0.4540 - val_Precision: 0.6632 - val_Recall: 0.6138 - val_acc: 0.7750 - val_loss: 0.4629\n",
      "Epoch 34/200\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.7063 - Recall: 0.6091 - acc: 0.7863 - loss: 0.4455\n",
      "Epoch 34: val_loss did not improve from 0.45335\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.7061 - Recall: 0.6093 - acc: 0.7862 - loss: 0.4456 - val_Precision: 0.6894 - val_Recall: 0.5848 - val_acc: 0.7812 - val_loss: 0.4537\n",
      "Epoch 35/200\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.7046 - Recall: 0.6355 - acc: 0.7869 - loss: 0.4468\n",
      "Epoch 35: val_loss did not improve from 0.45335\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.7043 - Recall: 0.6353 - acc: 0.7868 - loss: 0.4468 - val_Precision: 0.6752 - val_Recall: 0.5993 - val_acc: 0.7779 - val_loss: 0.4547\n",
      "Epoch 36/200\n",
      "\u001b[1m76/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6957 - Recall: 0.6409 - acc: 0.7836 - loss: 0.4503\n",
      "Epoch 36: val_loss did not improve from 0.45335\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6957 - Recall: 0.6404 - acc: 0.7837 - loss: 0.4501 - val_Precision: 0.6637 - val_Recall: 0.6262 - val_acc: 0.7772 - val_loss: 0.4550\n",
      "Epoch 37/200\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6936 - Recall: 0.6321 - acc: 0.7834 - loss: 0.4479\n",
      "Epoch 37: val_loss did not improve from 0.45335\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6936 - Recall: 0.6321 - acc: 0.7834 - loss: 0.4479 - val_Precision: 0.6582 - val_Recall: 0.6455 - val_acc: 0.7776 - val_loss: 0.4583\n",
      "Epoch 38/200\n",
      "\u001b[1m80/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6960 - Recall: 0.6364 - acc: 0.7815 - loss: 0.4481\n",
      "Epoch 38: val_loss did not improve from 0.45335\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6960 - Recall: 0.6367 - acc: 0.7817 - loss: 0.4479 - val_Precision: 0.6755 - val_Recall: 0.6186 - val_acc: 0.7812 - val_loss: 0.4584\n",
      "Epoch 38: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/03 17:43:02 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: Cannot log input example or model signature for input with type <class 'pandas.core.frame.DataFrame'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n",
      "2025/05/03 17:43:02 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/05/03 17:43:07 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/141\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - Precision: 0.4000 - Recall: 0.5714 - acc: 0.7188 - loss: 0.6502"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'attention-model' already exists. Creating a new version of this model...\n",
      "Created version '3' of model 'attention-model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - Precision: 0.6618 - Recall: 0.6039 - acc: 0.7708 - loss: 0.4656\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, MultiHeadAttention, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#\n",
    "with mlflow.start_run(run_name='AttentionMechanisim'):#mlflow\n",
    "    mlflow.tensorflow.autolog()#mlflow    \n",
    "    n_input = X_train.shape[1]\n",
    "    # Model\n",
    "    # 定義模型\n",
    "    input_layer = Input(shape=(n_input,))\n",
    "    x = BatchNormalization()(input_layer)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    # Reshape 輸入，以便進行注意力機制（將它變成三維張量）\n",
    "    x = Reshape((1, 128))(x)  # 假設每個樣本有 128 個特徵，這樣就會有 1 個時間步\n",
    "    # 添加多頭注意力層\n",
    "    x_attention = MultiHeadAttention(num_heads=4, key_dim=32)(x, x)  # query, key 和 value 都是 x\n",
    "    x_attention = Dropout(0.1)(x_attention)\n",
    "    # 將注意力層的輸出展平\n",
    "    x_flattened = Flatten()(x_attention)\n",
    "    # 經過展平後的處理\n",
    "    x = Dense(128, activation='relu')(x_flattened)\n",
    "    x = Dropout(0.1)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "    # Model\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.summary()\n",
    "    # 模型optimizer 和 learning rate\n",
    "    initial_lr = 0.001\n",
    "    from tensorflow.keras.optimizers import schedules\n",
    "    lr_schedule = schedules.ExponentialDecay(\n",
    "        initial_learning_rate=initial_lr,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True)\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    model.compile(loss='bce', optimizer=optimizer, metrics=['acc', 'Recall', 'Precision'])\n",
    "    # EarlyStopping: 根據 val_loss 停止訓練\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "    # ModelCheckpoint: 儲存最佳模型\n",
    "    checkpoint = ModelCheckpoint('./models_temp/attention_best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=200, batch_size=128, verbose=1, callbacks=[early_stop, checkpoint])\n",
    "\n",
    "    train_loss, train_acc, train_recall, train_precision = model.evaluate(X_train, y_train, verbose=0)\n",
    "    test_loss, test_acc, test_recall, test_precision = model.evaluate(X_test, y_test, verbose=0)\n",
    "    mlflow.log_metric(\"Train score\", train_acc)#mlflow\n",
    "    mlflow.log_metric(\"Test score\", test_acc)#mlflow\n",
    "    #註冊模型\n",
    "    run_id = mlflow.active_run().info.run_id#mlflow\n",
    "    result = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run_id}/model\",  # 你要用 mlflow.log_model 存的位置\n",
    "        name=\"attention-model\"              # 註冊後的 model name\n",
    "    )\n",
    "\n",
    "    # 評估模型\n",
    "    model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97836e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
