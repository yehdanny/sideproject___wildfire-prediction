{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690abd71",
   "metadata": {},
   "source": [
    "# California Weather-Fire Dataset 分析報告 🔥🌤️\n",
    "\n",
    "## 1. 資料簡介 📚\n",
    "本資料集涵蓋1984年至2025年間的加州天氣與火災紀錄，目標為預測 **FIRE_START_DAY**（是否起火）之二元分類問題。\n",
    "\n",
    "## 2. 資料前處理 🧹\n",
    "- **日期轉換與欄位清理**：將日期資料轉換為適合分析的格式，刪除不必要欄位。\n",
    "- **缺失值處理**：採用刪除缺失值的方法確保資料完整性。\n",
    "- **數值特徵標準化**：對數值欄位進行標準化，提升模型收斂速度。\n",
    "- **類別欄位One-Hot編碼**：針對季節等類別欄位進行One-Hot編碼。\n",
    "\n",
    "## 3. 特徵工程 ⚙️\n",
    "- **時間特徵**：新增月份、星期幾、週末標記等時間相關特徵。\n",
    "- **滯後特徵**：計算過去3天的火災狀態，捕捉時間依賴關係。\n",
    "- **滾動統計**：針對風速、降水量等氣象變數計算3天的移動平均與標準差。\n",
    "\n",
    "## 4. 資料平衡 ⚖️\n",
    "使用 SMOTE 技術對少數類（火災發生）進行過採樣，平衡正負類樣本分布，避免模型偏向多數類。\n",
    "\n",
    "## 5. 模型建構 🏗️\n",
    "- 訓練三種主要模型：**XGBoost、LightGBM、RandomForest**。\n",
    "- 使用 **Optuna** 進行自動化超參數調優，找到XGBoost最佳參數組合。\n",
    "- 透過集成模型融合三者優勢，採用 xgb、lgbm、rf 的 VotingClassifier，達到最佳準確率約 **85%**。🎯\n",
    "\n",
    "## 6. 模型評估 📊\n",
    "- **集成模型（XGBoost + LightGBM + RandomForest）準確率：約 85%**，為本研究中表現最佳。🏅\n",
    "- 深度學習模型表現如下：\n",
    "  - LSTM Test Accuracy: 0.8006 🤖\n",
    "  - Double-layer LSTM (14-day window) Test Accuracy: 0.7885\n",
    "  - GRU Model Test Accuracy: 0.8025\n",
    "  - DNN Test Accuracy: 0.7719\n",
    "  - DNN (30-day window) Test Accuracy: 0.7768\n",
    "  - LSTM+Attention Test Accuracy: 0.7787\n",
    "- 提供詳細的精確率 (Precision)、召回率 (Recall)、F1分數 (F1-score) 報告，評估模型在不同類別的表現。\n",
    "- 透過特徵重要性視覺化，解析模型決策依據。🔍\n",
    "\n",
    "## 7. 結論與未來展望 🚀\n",
    "- 目前集成模型（XGBoost、LightGBM、RandomForest）已達最佳預測表現，準確率達85%，優於各類深度學習模型。💪\n",
    "- 未來仍建議持續嘗試深度序列模型（如LSTM、Transformer），並優化時間序列特徵工程，期望進一步提升模型效能與穩定性。✨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bcae7d",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "504ac6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Accuracy: 0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      2001\n",
      "           1       0.83      0.84      0.83      2001\n",
      "\n",
      "    accuracy                           0.83      4002\n",
      "   macro avg       0.83      0.83      0.83      4002\n",
      "weighted avg       0.83      0.83      0.83      4002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 讀取資料\n",
    "df = pd.read_csv(\"data/CA_Weather_Fire_Dataset_1984-2025.csv\")\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df = df.dropna()\n",
    "df['FIRE_START_DAY'] = df['FIRE_START_DAY'].astype(int)\n",
    "\n",
    "# One-hot 編碼季節\n",
    "df = pd.get_dummies(df, columns=['SEASON'], drop_first=True)\n",
    "\n",
    "# 時間特徵\n",
    "df['WEEKDAY'] = df['DATE'].dt.weekday\n",
    "df['IS_WEEKEND'] = df['WEEKDAY'].isin([5, 6]).astype(int)\n",
    "\n",
    "# 數值標準化\n",
    "features_to_scale = [\n",
    "    'PRECIPITATION', 'MAX_TEMP', 'MIN_TEMP', 'AVG_WIND_SPEED',\n",
    "    'TEMP_RANGE', 'WIND_TEMP_RATIO', 'LAGGED_PRECIPITATION',\n",
    "    'LAGGED_AVG_WIND_SPEED'\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "# 特徵與標籤\n",
    "X = df.drop(columns=['FIRE_START_DAY', 'DATE'])\n",
    "y = df['FIRE_START_DAY']\n",
    "\n",
    "# SMOTE 類別平衡\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# 分割資料\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# XGBoost 與參數搜尋\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(xgb, param_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 模型評估\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfd0f046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8004, number of negative: 8004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001326 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2263\n",
      "[LightGBM] [Info] Number of data points in the train set: 16008, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.8393303348325837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      2001\n",
      "           1       0.83      0.85      0.84      2001\n",
      "\n",
      "    accuracy                           0.84      4002\n",
      "   macro avg       0.84      0.84      0.84      4002\n",
      "weighted avg       0.84      0.84      0.84      4002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 讀取資料\n",
    "df = pd.read_csv(\"data/CA_Weather_Fire_Dataset_1984-2025.csv\")\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df.dropna(inplace=True)\n",
    "df['FIRE_START_DAY'] = df['FIRE_START_DAY'].astype(int)\n",
    "\n",
    "# 加入時間與滯後特徵\n",
    "df['MONTH'] = df['DATE'].dt.month\n",
    "df['WEEKDAY'] = df['DATE'].dt.weekday\n",
    "df['IS_WEEKEND'] = df['WEEKDAY'].isin([5, 6]).astype(int)\n",
    "df['FIRE_LAG_1'] = df['FIRE_START_DAY'].shift(1).fillna(0).astype(int)\n",
    "df['FIRE_LAG_2'] = df['FIRE_START_DAY'].shift(2).fillna(0).astype(int)\n",
    "df['FIRE_LAG_3'] = df['FIRE_START_DAY'].shift(3).fillna(0).astype(int)\n",
    "\n",
    "# One-hot 編碼季節\n",
    "df = pd.get_dummies(df, columns=['SEASON'], drop_first=True)\n",
    "\n",
    "# 特徵標準化\n",
    "features_to_scale = [\n",
    "    'PRECIPITATION', 'MAX_TEMP', 'MIN_TEMP', 'AVG_WIND_SPEED',\n",
    "    'TEMP_RANGE', 'WIND_TEMP_RATIO', 'LAGGED_PRECIPITATION',\n",
    "    'LAGGED_AVG_WIND_SPEED'\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "# 切分資料\n",
    "X = df.drop(columns=['FIRE_START_DAY', 'DATE'])\n",
    "y = df['FIRE_START_DAY']\n",
    "\n",
    "# SMOTE 平衡資料\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# 模型定義\n",
    "xgb = XGBClassifier(learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8, random_state=42)\n",
    "lgbm = LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42)\n",
    "\n",
    "# 集成模型（硬投票）\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('xgb', xgb), ('lgbm', lgbm), ('rf', rf)],\n",
    "    voting='hard'\n",
    ")\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# 評估\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51d01493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 用XGBoost計算特徵重要性\n",
    "xgb.fit(X_train, y_train)\n",
    "importances = xgb.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# 繪圖展示\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Feature Importances (XGBoost)\")\n",
    "plt.bar(range(len(importances)), importances[indices], align='center')\n",
    "plt.xticks(range(len(importances)), [features[i] for i in indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 篩選重要性大於某門檻的特徵（例如 0.01）\n",
    "selected_features = [features[i] for i in range(len(importances)) if importances[i] > 0.01]\n",
    "\n",
    "X_train_sel = X_train[selected_features]\n",
    "X_test_sel = X_test[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d1c2cf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\3990922073.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['ROLLING_MEAN_WIND'] = df['AVG_WIND_SPEED'].rolling(window).mean().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\3990922073.py:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['ROLLING_STD_WIND'] = df['AVG_WIND_SPEED'].rolling(window).std().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\3990922073.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['ROLLING_MEAN_PRECIP'] = df['PRECIPITATION'].rolling(window).mean().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\3990922073.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['ROLLING_STD_PRECIP'] = df['PRECIPITATION'].rolling(window).std().fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "# 在原df中加入rolling features，這裡以3天為例\n",
    "window = 3\n",
    "\n",
    "df['ROLLING_MEAN_WIND'] = df['AVG_WIND_SPEED'].rolling(window).mean().fillna(method='bfill')\n",
    "df['ROLLING_STD_WIND'] = df['AVG_WIND_SPEED'].rolling(window).std().fillna(method='bfill')\n",
    "\n",
    "df['ROLLING_MEAN_PRECIP'] = df['PRECIPITATION'].rolling(window).mean().fillna(method='bfill')\n",
    "df['ROLLING_STD_PRECIP'] = df['PRECIPITATION'].rolling(window).std().fillna(method='bfill')\n",
    "\n",
    "# 同時標準化新增欄位\n",
    "df[['ROLLING_MEAN_WIND','ROLLING_STD_WIND','ROLLING_MEAN_PRECIP','ROLLING_STD_PRECIP']] = scaler.fit_transform(\n",
    "    df[['ROLLING_MEAN_WIND','ROLLING_STD_WIND','ROLLING_MEAN_PRECIP','ROLLING_STD_PRECIP']]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6384d26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8004, number of negative: 8004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001204 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2263\n",
      "[LightGBM] [Info] Number of data points in the train set: 16008, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000557 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2242\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000941 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2234\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001054 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2242\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6404\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2248\n",
      "[LightGBM] [Info] Number of data points in the train set: 12807, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499961 -> initscore=-0.000156\n",
      "[LightGBM] [Info] Start training from score -0.000156\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6404, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001050 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2235\n",
      "[LightGBM] [Info] Number of data points in the train set: 12807, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000156\n",
      "[LightGBM] [Info] Start training from score 0.000156\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Stacking Model Accuracy: 0.842328835582209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      2001\n",
      "           1       0.84      0.85      0.84      2001\n",
      "\n",
      "    accuracy                           0.84      4002\n",
      "   macro avg       0.84      0.84      0.84      4002\n",
      "weighted avg       0.84      0.84      0.84      4002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('xgb', XGBClassifier(learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8, random_state=42)),\n",
    "    ('lgbm', LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42))\n",
    "]\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train_sel, y_train)\n",
    "y_pred_stack = stacking_clf.predict(X_test_sel)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Stacking Model Accuracy:\", accuracy_score(y_test, y_pred_stack))\n",
    "print(classification_report(y_test, y_pred_stack))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dfd54e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-05-16 20:16:16,065] A new study created in memory with name: no-name-8aad6dd1-8704-4474-82de-998cbb3310d8\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:16,639] Trial 0 finished with value: 0.8341454272863568 and parameters: {'n_estimators': 253, 'max_depth': 6, 'learning_rate': 0.15098640521838289, 'subsample': 0.8930144598276641, 'colsample_bytree': 0.772716072809532}. Best is trial 0 with value: 0.8341454272863568.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:16] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:17,155] Trial 1 finished with value: 0.8308970514742628 and parameters: {'n_estimators': 236, 'max_depth': 6, 'learning_rate': 0.11244904056019722, 'subsample': 0.7226273708714545, 'colsample_bytree': 0.7961680435099995}. Best is trial 0 with value: 0.8341454272863568.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:17,880] Trial 2 finished with value: 0.8341454272863569 and parameters: {'n_estimators': 226, 'max_depth': 8, 'learning_rate': 0.10738981771132734, 'subsample': 0.8712886406334666, 'colsample_bytree': 0.815751762392224}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:17] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:18] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:19,488] Trial 3 finished with value: 0.8262118940529736 and parameters: {'n_estimators': 292, 'max_depth': 10, 'learning_rate': 0.01744197107139813, 'subsample': 0.7932871957058288, 'colsample_bytree': 0.8194656767103112}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:19] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:20,083] Trial 4 finished with value: 0.8079710144927535 and parameters: {'n_estimators': 287, 'max_depth': 5, 'learning_rate': 0.020950882100819374, 'subsample': 0.8311276507536518, 'colsample_bytree': 0.7297517283199649}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:20,516] Trial 5 finished with value: 0.809720139930035 and parameters: {'n_estimators': 284, 'max_depth': 4, 'learning_rate': 0.030985440315677803, 'subsample': 0.7587211138154474, 'colsample_bytree': 0.7733600956606896}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:20,937] Trial 6 finished with value: 0.7971014492753623 and parameters: {'n_estimators': 155, 'max_depth': 6, 'learning_rate': 0.013809898020740265, 'subsample': 0.9565836350836368, 'colsample_bytree': 0.8195860238645768}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:20] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:21,553] Trial 7 finished with value: 0.8025987006496752 and parameters: {'n_estimators': 234, 'max_depth': 6, 'learning_rate': 0.013134072740180422, 'subsample': 0.8752427732319508, 'colsample_bytree': 0.9220392795268824}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:21] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:22,019] Trial 8 finished with value: 0.8312093953023488 and parameters: {'n_estimators': 249, 'max_depth': 5, 'learning_rate': 0.07096879195586955, 'subsample': 0.9214882518730237, 'colsample_bytree': 0.7789231351828032}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:22,287] Trial 9 finished with value: 0.7887306346826587 and parameters: {'n_estimators': 159, 'max_depth': 4, 'learning_rate': 0.013029509270966789, 'subsample': 0.8058726977445306, 'colsample_bytree': 0.6355330955606747}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:22,814] Trial 10 finished with value: 0.8248375812093953 and parameters: {'n_estimators': 109, 'max_depth': 9, 'learning_rate': 0.05849071496066109, 'subsample': 0.6592273314905268, 'colsample_bytree': 0.9561284993803068}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:22] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:23,468] Trial 11 finished with value: 0.833208395802099 and parameters: {'n_estimators': 198, 'max_depth': 8, 'learning_rate': 0.19898300821666073, 'subsample': 0.9991056688134641, 'colsample_bytree': 0.8822574977317107}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:23] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:24,112] Trial 12 finished with value: 0.8300849575212395 and parameters: {'n_estimators': 200, 'max_depth': 8, 'learning_rate': 0.195223342780124, 'subsample': 0.8927920564548605, 'colsample_bytree': 0.6974397982264844}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:24,948] Trial 13 finished with value: 0.8328335832083957 and parameters: {'n_estimators': 261, 'max_depth': 8, 'learning_rate': 0.10566117899464857, 'subsample': 0.8569367261857964, 'colsample_bytree': 0.8759207708801395}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:25,563] Trial 14 finished with value: 0.8297726136931534 and parameters: {'n_estimators': 206, 'max_depth': 7, 'learning_rate': 0.12307977387627081, 'subsample': 0.6021639309124172, 'colsample_bytree': 0.6826740991037196}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:25,910] Trial 15 finished with value: 0.8142178910544727 and parameters: {'n_estimators': 220, 'max_depth': 3, 'learning_rate': 0.08103812381410096, 'subsample': 0.9346271598408094, 'colsample_bytree': 0.8664212428103719}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:25] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:26,916] Trial 16 finished with value: 0.8328335832083958 and parameters: {'n_estimators': 178, 'max_depth': 10, 'learning_rate': 0.04219639797867336, 'subsample': 0.9828003326062953, 'colsample_bytree': 0.7320874380334795}. Best is trial 2 with value: 0.8341454272863569.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:26] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:27,643] Trial 17 finished with value: 0.8351449275362319 and parameters: {'n_estimators': 263, 'max_depth': 7, 'learning_rate': 0.14322239103354262, 'subsample': 0.907451024889661, 'colsample_bytree': 0.9955555089367639}. Best is trial 17 with value: 0.8351449275362319.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:27] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:28,419] Trial 18 finished with value: 0.8307721139430285 and parameters: {'n_estimators': 265, 'max_depth': 7, 'learning_rate': 0.04035434743430908, 'subsample': 0.7312842339369885, 'colsample_bytree': 0.9875948067302646}. Best is trial 17 with value: 0.8351449275362319.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:28,949] Trial 19 finished with value: 0.8327086456771614 and parameters: {'n_estimators': 128, 'max_depth': 9, 'learning_rate': 0.0837409685798263, 'subsample': 0.8369119125374185, 'colsample_bytree': 0.6091377622806983}. Best is trial 17 with value: 0.8351449275362319.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:28] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:29] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:30,013] Trial 20 finished with value: 0.8346451774112943 and parameters: {'n_estimators': 272, 'max_depth': 9, 'learning_rate': 0.05575641907522326, 'subsample': 0.9255337387528298, 'colsample_bytree': 0.9994701449332903}. Best is trial 17 with value: 0.8351449275362319.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:31,082] Trial 21 finished with value: 0.8363318340829585 and parameters: {'n_estimators': 275, 'max_depth': 9, 'learning_rate': 0.05614774261216492, 'subsample': 0.9302348250727788, 'colsample_bytree': 0.989848665195171}. Best is trial 21 with value: 0.8363318340829585.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:31] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:32,221] Trial 22 finished with value: 0.82896051974013 and parameters: {'n_estimators': 274, 'max_depth': 9, 'learning_rate': 0.028478215113721485, 'subsample': 0.9330235671230726, 'colsample_bytree': 0.9999741508734039}. Best is trial 21 with value: 0.8363318340829585.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:32] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:33,524] Trial 23 finished with value: 0.8368940529735133 and parameters: {'n_estimators': 271, 'max_depth': 10, 'learning_rate': 0.054690084309548186, 'subsample': 0.956014722860805, 'colsample_bytree': 0.9553008568021055}. Best is trial 23 with value: 0.8368940529735133.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:33] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:34,931] Trial 24 finished with value: 0.8346451774112943 and parameters: {'n_estimators': 296, 'max_depth': 10, 'learning_rate': 0.05663693114943939, 'subsample': 0.9790809985075856, 'colsample_bytree': 0.9432317486862671}. Best is trial 23 with value: 0.8368940529735133.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:34] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:35] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:36,233] Trial 25 finished with value: 0.8321464267866068 and parameters: {'n_estimators': 246, 'max_depth': 10, 'learning_rate': 0.03407560704365892, 'subsample': 0.9643180665910775, 'colsample_bytree': 0.918754048111862}. Best is trial 23 with value: 0.8368940529735133.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:36] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:36,983] Trial 26 finished with value: 0.8318965517241379 and parameters: {'n_estimators': 281, 'max_depth': 7, 'learning_rate': 0.14338124466039393, 'subsample': 0.9123586085951167, 'colsample_bytree': 0.9619002786657336}. Best is trial 23 with value: 0.8368940529735133.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:38,228] Trial 27 finished with value: 0.8301474262868566 and parameters: {'n_estimators': 300, 'max_depth': 9, 'learning_rate': 0.025115259443619836, 'subsample': 0.9534263466333435, 'colsample_bytree': 0.9093475867003674}. Best is trial 23 with value: 0.8368940529735133.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:39,636] Trial 28 finished with value: 0.8310219890054972 and parameters: {'n_estimators': 264, 'max_depth': 10, 'learning_rate': 0.04605122869841773, 'subsample': 0.9999408513808883, 'colsample_bytree': 0.9665208376851333}. Best is trial 23 with value: 0.8368940529735133.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:40,647] Trial 29 finished with value: 0.8335207396301848 and parameters: {'n_estimators': 250, 'max_depth': 8, 'learning_rate': 0.07182253384694891, 'subsample': 0.8902991032272993, 'colsample_bytree': 0.8504343537096793}. Best is trial 23 with value: 0.8368940529735133.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:42,197] Trial 30 finished with value: 0.8110944527736131 and parameters: {'n_estimators': 241, 'max_depth': 9, 'learning_rate': 0.010253684727640364, 'subsample': 0.9005238333365523, 'colsample_bytree': 0.936333329286044}. Best is trial 23 with value: 0.8368940529735133.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:43,520] Trial 31 finished with value: 0.8373938030984508 and parameters: {'n_estimators': 272, 'max_depth': 9, 'learning_rate': 0.05387748019747184, 'subsample': 0.9429421668202034, 'colsample_bytree': 0.9835582842961951}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:44,925] Trial 32 finished with value: 0.8360819590204898 and parameters: {'n_estimators': 263, 'max_depth': 10, 'learning_rate': 0.04742739149339533, 'subsample': 0.9457097703362218, 'colsample_bytree': 0.9680232222169308}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:46,096] Trial 33 finished with value: 0.8359570214892553 and parameters: {'n_estimators': 229, 'max_depth': 10, 'learning_rate': 0.049111864879144554, 'subsample': 0.9539368080947331, 'colsample_bytree': 0.9720259443776689}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:47,482] Trial 34 finished with value: 0.8354572713643179 and parameters: {'n_estimators': 276, 'max_depth': 10, 'learning_rate': 0.06332946211211682, 'subsample': 0.9390450866562232, 'colsample_bytree': 0.9100849923940517}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:48,455] Trial 35 finished with value: 0.8298975512243878 and parameters: {'n_estimators': 216, 'max_depth': 9, 'learning_rate': 0.035914164172781336, 'subsample': 0.8615421412959543, 'colsample_bytree': 0.9408990539600823}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:49,811] Trial 36 finished with value: 0.8345827086456771 and parameters: {'n_estimators': 287, 'max_depth': 10, 'learning_rate': 0.09813303227081145, 'subsample': 0.9688493207376369, 'colsample_bytree': 0.9779740526387662}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:50,859] Trial 37 finished with value: 0.8329585207396302 and parameters: {'n_estimators': 256, 'max_depth': 9, 'learning_rate': 0.047078121245778336, 'subsample': 0.8403331115651274, 'colsample_bytree': 0.8913765914839828}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:51,884] Trial 38 finished with value: 0.8285232383808095 and parameters: {'n_estimators': 290, 'max_depth': 8, 'learning_rate': 0.025719067938977016, 'subsample': 0.7731119250128606, 'colsample_bytree': 0.9491097679087054}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:53,126] Trial 39 finished with value: 0.8323963018490753 and parameters: {'n_estimators': 238, 'max_depth': 10, 'learning_rate': 0.03756163674606599, 'subsample': 0.8785912260271772, 'colsample_bytree': 0.8986330266075213}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:54,150] Trial 40 finished with value: 0.8366441779110444 and parameters: {'n_estimators': 273, 'max_depth': 9, 'learning_rate': 0.08492234887931213, 'subsample': 0.9455631143254034, 'colsample_bytree': 0.8358827261332088}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:55,170] Trial 41 finished with value: 0.8362693653173413 and parameters: {'n_estimators': 273, 'max_depth': 9, 'learning_rate': 0.06811342446125931, 'subsample': 0.9450196119699511, 'colsample_bytree': 0.826630984943189}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:56,181] Trial 42 finished with value: 0.8350199900049975 and parameters: {'n_estimators': 274, 'max_depth': 9, 'learning_rate': 0.08452847554962224, 'subsample': 0.9728083201606517, 'colsample_bytree': 0.8475352112638628}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:57,104] Trial 43 finished with value: 0.8358945527236381 and parameters: {'n_estimators': 284, 'max_depth': 8, 'learning_rate': 0.07114325421062984, 'subsample': 0.9162960805274034, 'colsample_bytree': 0.7919036811432265}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:58,068] Trial 44 finished with value: 0.836831584207896 and parameters: {'n_estimators': 252, 'max_depth': 9, 'learning_rate': 0.061876998316589576, 'subsample': 0.9894093045427296, 'colsample_bytree': 0.8335805656193412}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:16:58,858] Trial 45 finished with value: 0.8357071464267866 and parameters: {'n_estimators': 254, 'max_depth': 8, 'learning_rate': 0.05424789871990869, 'subsample': 0.9918339956277685, 'colsample_bytree': 0.7455323492346351}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:16:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:17:00,034] Trial 46 finished with value: 0.8327711144427786 and parameters: {'n_estimators': 292, 'max_depth': 9, 'learning_rate': 0.08689605430110368, 'subsample': 0.8103104359437314, 'colsample_bytree': 0.803045875238783}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:17:00,808] Trial 47 finished with value: 0.8368940529735133 and parameters: {'n_estimators': 247, 'max_depth': 8, 'learning_rate': 0.09688599780589605, 'subsample': 0.9703725582673719, 'colsample_bytree': 0.7609633464817577}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:17:01,532] Trial 48 finished with value: 0.8349575212393803 and parameters: {'n_estimators': 233, 'max_depth': 8, 'learning_rate': 0.11907272506916144, 'subsample': 0.9784041027428004, 'colsample_bytree': 0.7557071289175301}. Best is trial 31 with value: 0.8373938030984508.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:17:02,097] Trial 49 finished with value: 0.8363943028485757 and parameters: {'n_estimators': 218, 'max_depth': 7, 'learning_rate': 0.10094929854584207, 'subsample': 0.9642711216665515, 'colsample_bytree': 0.7073241809879891}. Best is trial 31 with value: 0.8373938030984508.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 272, 'max_depth': 9, 'learning_rate': 0.05387748019747184, 'subsample': 0.9429421668202034, 'colsample_bytree': 0.9835582842961951}\n",
      "Best CV accuracy: 0.8373938030984508\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'random_state': 42,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    model = XGBClassifier(**param)\n",
    "    score = cross_val_score(model, X_train_sel, y_train, cv=3, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best CV accuracy:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9e4efe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8004, number of negative: 8004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001288 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2263\n",
      "[LightGBM] [Info] Number of data points in the train set: 16008, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:17:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000949 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2242\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000471 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2234\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000560 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2242\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6404\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000927 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2248\n",
      "[LightGBM] [Info] Number of data points in the train set: 12807, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499961 -> initscore=-0.000156\n",
      "[LightGBM] [Info] Start training from score -0.000156\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6404, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000994 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2235\n",
      "[LightGBM] [Info] Number of data points in the train set: 12807, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000156\n",
      "[LightGBM] [Info] Start training from score 0.000156\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Stacking Model Accuracy: 0.8458270864567716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85      2001\n",
      "           1       0.84      0.85      0.85      2001\n",
      "\n",
      "    accuracy                           0.85      4002\n",
      "   macro avg       0.85      0.85      0.85      4002\n",
      "weighted avg       0.85      0.85      0.85      4002\n",
      "\n",
      "Stacking Model Test Accuracy: 0.8458\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "xgb_best = XGBClassifier(\n",
    "    n_estimators=263,\n",
    "    max_depth=9,\n",
    "    learning_rate=0.055,\n",
    "    subsample=0.91,\n",
    "    colsample_bytree=0.60,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42)\n",
    "\n",
    "estimators = [('xgb', xgb_best), ('lgbm', lgbm), ('rf', rf)]\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
    "\n",
    "stacking_clf.fit(X_train_sel, y_train)\n",
    "y_pred_stack = stacking_clf.predict(X_test_sel)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Stacking Model Accuracy:\", accuracy_score(y_test, y_pred_stack))\n",
    "print(classification_report(y_test, y_pred_stack))\n",
    "\n",
    "stack_acc = accuracy_score(y_test, y_pred_stack)\n",
    "print(f\"Stacking Model Test Accuracy: {stack_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518bcf5e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233127e",
   "metadata": {},
   "source": [
    "# LSTM 深度學習模型 來預測火災"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca1f268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_mean'] = df[col].rolling(window).mean().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_std'] = df[col].rolling(window).std().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_mean'] = df[col].rolling(window).mean().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_std'] = df[col].rolling(window).std().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_mean'] = df[col].rolling(window).mean().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_std'] = df[col].rolling(window).std().fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假設 df 是你的原始資料集，且已排序\n",
    "df = df.sort_values('DATE')\n",
    "\n",
    "# 建立滯後特徵，例如前3天火災狀態\n",
    "for lag in range(1, 4):\n",
    "    df[f'FIRE_START_DAY_lag_{lag}'] = df['FIRE_START_DAY'].shift(lag).fillna(0)\n",
    "\n",
    "# 建立滾動特徵 (3天平均與標準差)\n",
    "window = 3\n",
    "for col in ['AVG_WIND_SPEED', 'PRECIPITATION', 'TEMP_RANGE']:\n",
    "    df[f'{col}_rolling_mean'] = df[col].rolling(window).mean().fillna(method='bfill')\n",
    "    df[f'{col}_rolling_std'] = df[col].rolling(window).std().fillna(method='bfill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee4978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 篩選用到的特徵\n",
    "features = ['AVG_WIND_SPEED', 'PRECIPITATION', 'TEMP_RANGE',\n",
    "            'FIRE_START_DAY_lag_1', 'FIRE_START_DAY_lag_2', 'FIRE_START_DAY_lag_3',\n",
    "            'AVG_WIND_SPEED_rolling_mean', 'AVG_WIND_SPEED_rolling_std',\n",
    "            'PRECIPITATION_rolling_mean', 'PRECIPITATION_rolling_std',\n",
    "            'TEMP_RANGE_rolling_mean', 'TEMP_RANGE_rolling_std']\n",
    "\n",
    "data = df[features].values\n",
    "labels = df['FIRE_START_DAY'].values\n",
    "\n",
    "# 標準化特徵\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# 建立序列資料 (7天為一個序列)\n",
    "def create_sequences(data, labels, seq_length=7):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(labels[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(data, labels)\n",
    "\n",
    "# 切分訓練測試集 (80%訓練)\n",
    "split_idx = int(len(X)*0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6413314b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7586 - loss: 0.5119 - val_accuracy: 0.7658 - val_loss: 0.5300\n",
      "Epoch 2/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.4466 - val_accuracy: 0.7716 - val_loss: 0.5399\n",
      "Epoch 3/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7817 - loss: 0.4474 - val_accuracy: 0.7729 - val_loss: 0.5346\n",
      "Epoch 4/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4453 - val_accuracy: 0.7699 - val_loss: 0.5400\n",
      "Epoch 5/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.4385 - val_accuracy: 0.7670 - val_loss: 0.5341\n",
      "Epoch 6/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7929 - loss: 0.4358 - val_accuracy: 0.7537 - val_loss: 0.5322\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f17c5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.4908\n",
      "LSTM Test Accuracy: 0.7979\n"
     ]
    }
   ],
   "source": [
    "loss, LSTM_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"LSTM Test Accuracy: {LSTM_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23ad75",
   "metadata": {},
   "source": [
    "# 雙層 LSTM + 時間週期特徵 + 序列長度14天的版本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0480cff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7617 - loss: 0.4866 - val_accuracy: 0.7774 - val_loss: 0.5149\n",
      "Epoch 2/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7904 - loss: 0.4372 - val_accuracy: 0.7790 - val_loss: 0.5285\n",
      "Epoch 3/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7900 - loss: 0.4457 - val_accuracy: 0.7778 - val_loss: 0.5151\n",
      "Epoch 4/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7892 - loss: 0.4338 - val_accuracy: 0.7732 - val_loss: 0.5094\n",
      "Epoch 5/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8043 - loss: 0.4241 - val_accuracy: 0.7698 - val_loss: 0.5023\n",
      "Epoch 6/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7984 - loss: 0.4299 - val_accuracy: 0.7698 - val_loss: 0.5082\n",
      "Epoch 7/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7920 - loss: 0.4246 - val_accuracy: 0.7765 - val_loss: 0.5067\n",
      "Epoch 8/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8027 - loss: 0.4201 - val_accuracy: 0.7623 - val_loss: 0.5118\n",
      "Epoch 9/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7995 - loss: 0.4231 - val_accuracy: 0.7556 - val_loss: 0.5307\n",
      "Epoch 10/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8075 - loss: 0.4140 - val_accuracy: 0.7615 - val_loss: 0.5154\n",
      "Epoch 11/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8018 - loss: 0.4147 - val_accuracy: 0.7636 - val_loss: 0.5087\n",
      "Epoch 12/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8026 - loss: 0.4161 - val_accuracy: 0.7590 - val_loss: 0.5255\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.4667\n",
      "Double-layer LSTM (14-day window) Test Accuracy: 0.7935\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 假設 df 已有日期欄 DATE 和 target 欄 FIRE_START_DAY\n",
    "\n",
    "df = df.sort_values('DATE')\n",
    "\n",
    "# 週期性時間特徵 (day_of_year)\n",
    "df['day_of_year'] = df['DATE'].dt.dayofyear\n",
    "df['sin_day'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['cos_day'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "\n",
    "# 其他滯後及滾動特徵你之前已有，這邊直接選用：\n",
    "features = ['AVG_WIND_SPEED', 'PRECIPITATION', 'TEMP_RANGE',\n",
    "            'FIRE_START_DAY_lag_1', 'FIRE_START_DAY_lag_2', 'FIRE_START_DAY_lag_3',\n",
    "            'AVG_WIND_SPEED_rolling_mean', 'AVG_WIND_SPEED_rolling_std',\n",
    "            'PRECIPITATION_rolling_mean', 'PRECIPITATION_rolling_std',\n",
    "            'TEMP_RANGE_rolling_mean', 'TEMP_RANGE_rolling_std',\n",
    "            'sin_day', 'cos_day']\n",
    "\n",
    "# 準備資料\n",
    "data = df[features].values\n",
    "labels = df['FIRE_START_DAY'].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "def create_sequences(data, labels, seq_length=14):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(labels[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(data, labels, seq_length=14)\n",
    "\n",
    "split_idx = int(len(X)*0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# 模型架構：雙層 LSTM\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=100,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop])\n",
    "                    \n",
    "loss, DLLSTM_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Double-layer LSTM (14-day window) Test Accuracy: {DLLSTM_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a3cb1d",
   "metadata": {},
   "source": [
    "# GRU 模型版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88708653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7716 - loss: 0.4791 - val_accuracy: 0.7749 - val_loss: 0.5108\n",
      "Epoch 2/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7938 - loss: 0.4298 - val_accuracy: 0.7673 - val_loss: 0.5144\n",
      "Epoch 3/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7942 - loss: 0.4319 - val_accuracy: 0.7719 - val_loss: 0.5054\n",
      "Epoch 4/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7958 - loss: 0.4271 - val_accuracy: 0.7753 - val_loss: 0.5056\n",
      "Epoch 5/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7941 - loss: 0.4290 - val_accuracy: 0.7698 - val_loss: 0.5132\n",
      "Epoch 6/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7960 - loss: 0.4282 - val_accuracy: 0.7732 - val_loss: 0.5052\n",
      "Epoch 7/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7970 - loss: 0.4240 - val_accuracy: 0.7723 - val_loss: 0.5044\n",
      "Epoch 8/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7986 - loss: 0.4253 - val_accuracy: 0.7744 - val_loss: 0.5004\n",
      "Epoch 9/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8028 - loss: 0.4178 - val_accuracy: 0.7711 - val_loss: 0.5123\n",
      "Epoch 10/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8027 - loss: 0.4159 - val_accuracy: 0.7736 - val_loss: 0.5046\n",
      "Epoch 11/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8012 - loss: 0.4144 - val_accuracy: 0.7648 - val_loss: 0.5095\n",
      "Epoch 12/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8010 - loss: 0.4144 - val_accuracy: 0.7719 - val_loss: 0.5124\n",
      "Epoch 13/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8088 - loss: 0.4060 - val_accuracy: 0.7732 - val_loss: 0.5117\n",
      "Epoch 14/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8044 - loss: 0.4107 - val_accuracy: 0.7598 - val_loss: 0.5149\n",
      "Epoch 15/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8113 - loss: 0.3995 - val_accuracy: 0.7636 - val_loss: 0.5096\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.4694\n",
      "GRU Model Test Accuracy: 0.7992\n"
     ]
    }
   ],
   "source": [
    "model_gru = Sequential([\n",
    "    GRU(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    GRU(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_gru.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop_gru = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "history_gru = model_gru.fit(X_train, y_train,\n",
    "                            validation_split=0.2,\n",
    "                            epochs=100,\n",
    "                            batch_size=64,\n",
    "                            callbacks=[early_stop_gru])\n",
    "\n",
    "loss_gru, acc_gru = model_gru.evaluate(X_test, y_test)\n",
    "print(f\"GRU Model Test Accuracy: {acc_gru:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49a87332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHHCAYAAABXx+fLAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAad9JREFUeJzt3Qd0VNUWBuCf9AIJJIGEDqH3DlIUEKRXpXcQEaUpNmwgNiwIqKBYABWliA8EREB6k95LCJ3QkhBKAgkpJPPWPpcJqZgymXb/b62BuVPvTJK5e/bZ+5x8BoPBACIiIiIdcbD0DhARERGZGwMgIiIi0h0GQERERKQ7DICIiIhIdxgAERERke4wACIiIiLdYQBEREREusMAiIiIiHSHARARERHpDgMgIrJ5+fLlw3vvvZft+124cEHd96effsqT/SIi68UAiMhGnD9/HqNHj0bFihXh4eGhTlWrVsWoUaNw5MiRVLeVYEAO7MaTs7MzypQpg7Fjx+L27dvpHltuI4+dkT/++ENdv3nz5kfunwQRxufbvn17uutl1Z2SJUuq6zt16gRb9ffff6vXUKxYMSQlJVl6d4goh5xyekciMp+//voLvXv3hpOTE/r3749atWrBwcEBJ0+exNKlS/Htt9+qAKl06dKp7ieX58+fH9HR0diwYQO+/vprHDhwIMMAxVTc3NywYMECNGvWLNXlW7ZsweXLl+Hq6gpb9ttvv6lgUrJHGzduROvWrS29S0SUAwyAiKzc2bNn0adPHxXcSBBTtGjRVNd/+umn+Oabb1RAlFaPHj3g5+enzj///PPqcRYvXow9e/agYcOGebK/HTp0wJIlS/DVV1+pgM1IgqJ69eohIiICtkoCyeXLl2PKlCmYN2+eCoasNQCSffX09LT0bhBZLQ6BEVm5zz77TB3M5ICbNvgREmTI0JYML/2Xxx9/PDmoyit9+/bFjRs3sG7duuTL4uPj1VBav379MryPvL5XXnlFvQbJEFWqVAlTp05Vw2YpxcXF4eWXX0bhwoVRoEABdOnSRWWVMnLlyhUMGzYM/v7+6jGrVauGuXPn5uq1LVu2DPfu3UPPnj1VMCnZt9jY2HS3k8tkGFKGKyUjJj+3p59+OtX7LsNnX375JWrUqKFuI6+pXbt22Ldv33/WJ6WteTIOeZ44cUK9x4UKFUrOwMnw6JAhQxAYGKieJyAgQL0v8jPK6D179tln1fCevGdly5bFCy+8oH5+586dU88xffr0dPf7999/1XULFy7MxbtLZF7MABHZwPBX+fLl0ahRo1w/lhxUhRwg84oMDzVu3FgdDNu3b68uW716NSIjI1XQIJmhlCTIkUBm06ZN6uBbu3ZtrF27Fq+99po6IKc84A4fPhy//vqrOsg3adJEDUF17Ngx3T6EhYXhscceS65tkuBC9kEePyoqCi+99FKOXptkfFq2bKmCCHktEyZMwMqVK1VAZJSYmKhqnCRbJ7cZN24c7ty5owLCY8eOoVy5cup2si8S3Mh7JK/r/v372LZtG3bt2oX69evnaP9kPypUqICPP/44OXiU55XgZejQoWq/jx8/ju+//179L88l75G4evWqygpKjdiIESNQuXJl9f5L4BoTE6MCqKZNm6r3QILQtO+LBKRdu3bN0X4TWYSBiKxWZGSkHMUM3bp1S3fdrVu3DNevX08+xcTEJF83adIkdb/g4GB13YULFwxz5841uLu7GwoXLmyIjo5O9Vhy21GjRmW4D0uWLFHXb9q06ZH7Om/ePHW7vXv3GmbOnGkoUKBA8j717NnT0LJlS3W+dOnSho4dOybf788//1T3+/DDD1M9Xo8ePQz58uUznDlzRm0fOnRI3e7FF19Mdbt+/fqpy+U1Gz377LOGokWLGiIiIlLdtk+fPgZvb+/k/Tp//ry6r+z7fwkLCzM4OTkZfvjhh+TLmjRpYujatWuq28n7LI85bdq0dI+RlJSk/t+4caO6zdixYzO9zaP2Le3rNf68+/btm+62KX8vjBYuXKhuv3Xr1uTLBg0aZHBwcFA/v8z26bvvvlP3CwoKSr4uPj7e4OfnZxg8eHC6+xFZMw6BEVkxyVYIKWROq0WLFiqzYTzNmjUr3W1kKEmuk6yMDHtIJkkyIdJBlpd69eqlhookeyXZD/k/s+Ev6apydHRUw3gpyZCYHOtlf423E2lvlzabI/f53//+h86dO6vzUnNkPLVt21ZloqQQPLsWLVqk6qyeeeaZVMN9sn+3bt1KvkyeW+quxowZk+4xjNkWuY2cnzRpUqa3yYmRI0emu8zd3T3V0Jy8D5IdE8b3QYbj/vzzT/WeZZR9Mu6T/FxlGE0yPkaSrZPHHDBgQI73m8gSOARGZMVkWEHcvXs33XXfffedCi5kuCezg48caL28vHD9+nU19CSdYikPiNmRnQOzBF1SHCyFzzJ8IsNCUpCdkYsXL6qaE+NrNapSpUry9cb/JQAxDiGlDPJSktcqwzgyzCOnjISHhyO7ZOhNhoikdsZYP1OnTh1VHyNF3zJsJKTOR/YpZQF4WnIbec0+Pj4wJanZSevmzZuYPHmyCuDSvm4JBo3vmQTb1atXf+TjFyxYUAVJ8nP94IMP1GUSDBUvXhxPPvmkSV8LUV5jAERkxby9vVUBrdSOpGWsCTLW9WTkiSeeSO4CkwOXFNxKG/3+/ftTdY1JwatkbDIiAYyQb/7ZIRmf5557DqGhoarORQ6e5mCcm0eCwsGDB2d4m5o1a2brMU+fPo29e/eq81Jjk5YEAcYAyFQyCzglmMxMRsGtZG2kSFlqqqS+SrKJ8h5JwXVO5jEaNGiQCvjkMeX3acWKFXjxxRcz7EIksmYMgIisnBT5/vjjj7luXZcDnwy5SDHs77//rgp0jaTFPjg4OMP7GS9PO8fQf+nevbtqvZdCW2m9z4w87vr161U2K2UWSOY4Svm88r8csI0ZlrT7Z2TsEJNAwVQt6hLgyGSS8+fPV8N1KcmcSpJdCwkJQalSpVSGavfu3UhISFD3yYjcRoaOJDuTWRbIWKieduJKY0YsK2RoToqxJQM0ceLEVAFd2vdMMoUZBdppSeAkt5f3RIJwCZAHDhyY5X0ishYM2Yms3Ouvv65qdqSGR4a70krbKv4okv0pUaKEmjso7dw9EqhIZiglOfjKgU4yB9JBlN2ASyZilBZtyT5lRp5bgpWZM2emuly6vyQLYuwkM/6ftotsxowZqbYlQJE6HRn+y+iALsM92SXvgUwhIJNRylBeypNkVoSxBVyeW2pi0r6elD8ruY2cl8Aks9tIQCLZu61bt6a6XuZ8yipjsJb2dyTteybZm27duqmONmMbfkb7JGRoT2qfJIiWLjbJAmU3o0ZkDZgBIrJyMuQiNRdy0JHMh3EmaDkoSU2PXCcHMAls/otkJKQtWw7aa9asUd/mhbRzy7CGDJlJ1kZaoKUtWg5w165dU3MQ5URmQ1ApSXAkreVvv/22Gs6T1/bPP/+oCQelwNlY8yNBmLwHEgBI7Yq0wUt248yZM+ke85NPPlFt9ZKhkGE4WTJEsi1S9CvZJjmfVZLNkefIbKkQqX+pW7euCpLeeOMNNUT0yy+/YPz48SprJ4GTzHMkzytDRdIqLq9XsiYSzEk2xjgcJW3wcp3xuaQ9Xl6L/C/FyRIMnTp1Ksv7LkGU/ExlLinJSMm+ynsrvzdpSeu8XNe8eXM1nCc1WPKzl98LyXKlHMKU1yj7Lu9x2mCayGZYug2NiLJG2sFfeOEFQ/ny5Q1ubm6qpb1y5cqGkSNHqhbxlIxt0dICn1FrvbSCN2/ePNXlly9fNgwfPtxQvHhx1e7t4+Nj6NSpk2HXrl1Z2r+UbfCPkrYNXty5c8fw8ssvG4oVK2ZwdnY2VKhQwfD5558nt18b3bt3T7WO+/r6Gjw9PQ2dO3c2XLp0KV1buLFtXVr7S5YsqR4zICDA0KpVK8P333+ffJustMGPGTNG3ebs2bOZ3ua9995Ttzl8+HBy6/nbb79tKFu2bPJzS1t/yse4f/++eo3yM3RxcVHTE7Rv396wf//+5NvI40hLv/y8ZFqBXr16GcLDwzNtg8/o5y0/1+7duxsKFiyoHkemJLh69WqG79nFixdVO7zsi6urqyEwMFC9h3Fxceket1q1aqptXh6fyBblk38sHYQREZFtkQ44qV+SLByRLWINEBERZYvUCR06dEgNhRHZKmaAiIgoS6SoXArlv/jiC1XoLUtsZHd6BCJrwQwQERFliawLJtMoSEG1dL0x+CFbxgwQERER6Q4zQERERKQ7DICIiIhIdzgRYgZkQjKZBE6m08/NysxERERkPlLVI8vqyGLD/7U+HQOgDEjwU7JkSUvvBhEREeXApUuX/nN2fAZAGTAuyChvoEwlT0RERNYvKipKJTBSLqycGQZAGTAOe0nwwwCIiIjItmSlfIVF0ERERKQ7DICIiIhIdxgAERERke4wACIiIiLdYQBEREREusMAiIiIiHSHARARERHpDgMgIiIi0h0GQERERKQ7DICIiIhIdxgAERERke4wACIiIiLdYQBEREREZmMwGLAhKAxJSQZYEgMgIiIiMot78Yl45ffDePbnffh2y1lYkpNFn52IiIh0IeRGDJ7/dT+CrkXB0SEfXJ0sm4NhAERERER5alNwOF5adAiR9xLg6+mCmf3qonE5X1gSAyAiIiLKE1LnM2vTGUxbfwoGA1CrZEHMHlAXRb3dYWkMgIiIiMjkJNvzyu+HsD4oXG33a1QKkzpXhauTI6wBAyAiIiIyqeDQO3h+/j5cuBEDFycHfNi1Ono1KAlrwgCIiIjIjI5diVTZkSblfJEvXz7Ym5WHr+L1P47gXkIiihd0x7cD6qJmiYKwNgyAiIiIzOS33RcxcflxJCYZ0DjQFxM7V0WVol6wBwmJSfhk9UnM2X5ebTcr74ev+taBj6cLrBEDICIiIjMUA09ZHYQftmnBgUM+YOe5G+j41TZVGzP+qUpWGyhkxfU7cRi94AB2n7+ptl9oUQ6vtqmk2t2tFSdCJCIiyuPJ/174bX9y8PPKUxWx5bWW6FijKGQy5F93haDF55swb8d5lUWxNQdCbqHz19tV8OPp4qi6vN5oV9mqgx+RzyBzUlMqUVFR8Pb2RmRkJLy87CM1SURE5hceFYvhv+zDkcuRqhj48x410bV28eTrd527gckrT6jJAUX5IvkxsVNVPFGxMKydwWDAb7tDMHnlcSQkGlCusCe+G1hfvQZbOH4zAMoAAyAiIsqtk6FRGDZvL65Gxqrhre8H1kP9Mj7pbif1QIv3XsLUf4JxMzpeXda6ij/e6VgFZfw8YY1iExLx7p/HsGT/ZbXdrloApvaqhfyulq2sYQCUSwyAiIgoNzYHh2P0goO4G3cfgYU9MW9IA5T2fXQwI51hX204jZ//vYD7SQY4O+bDsGZlMbpleRRwc4a1uHwrBiN/3Y9jV6JULdNrbStjZPNAq+hoYwCUSwyAiIgop+bvuoj3VmidXo8F+uC7AfXh7ZH1AOZM+F188NcJbDl1XW375XfF6+0qoUfdEnCwcF3NttPXMXbhQdyKSUAhD2e1pEXT8n6wFgyAcokBEBERZZcEPFP+DsKPD9rAe9QrgY+711C1P9klh2ZZP+uDv4JwPiJaXVajuDfe61IV9UqnH0bLawaDQa3ePnVtsCrcln2R+X1KFPKANWEAlEsMgIiIKDti4u9j3KJDWHciTG2/1rYSXmxRLtfDQvH3k9SQmAyN3Ym7ry7rWrsYJrSvbLb1tO7EJuDVJYex9rj22nrXL4nJXavBzdk6lrRIiQFQLjEAIiKirAqTTq+f9+HoFa3T64uetdC5VjGTz7PzxT/BWLzvklpU1N3ZUc21M+KJwDwNRE6H3cHzv+7HuevRcHF0UIFP34alYK0YAOUSAyAiIsoKaV8f9tNeXHvQ6fXDoHp5OkQly2hI2/neC7fUtiw18XbHKmhfPcDkRcirj15TmZ/o+EQEeLmpIa86pQrBmjEAyiUGQERE9F+kRmf0bwdUgCBz4Mwb0hClfPO+JkYO2yuPXFP1RhJ4iUZlfTCpczVULZb7Y9b9xCR8vjYY3209p7alkFuKnaUY29oxAMolBkBERPQo83dewKQVx1VBsCxq+m3/etnq9DLVDNOzt5xVp7j7SaolvU/DUmqmad8cBis37sZhzMKD+PfsDbUtQ2yvt60EJ0fbWDiCAVAuMQAiIqLMOr0+WhWEuTu0Tq9e9Uvgw2456/QylSu376ls0F9HrqltLzcnvNS6IgY2Lg3nbAQuhy/dxgu/7lcTN3q4OOKzHjXRqaZpa5nyGgOgXGIAREREaUXHaZ1e64NM2+llKnvO31T1QcevastqyLDcxM7V0DwLy2os2hOiVqmPT0xCoJ8nZg+sh4r+BWBrGADlEgMgIiJK2+klxc4SXEi2Z1qvWlaZHZEM1ZJ9l1QNz40Hy2q0qlwE73SqirIZLKsRdz9RTdq4cM8ltf1UVX980asWvKxo5unsYACUSwyAiIjI6MTVKDz7s9bp5SudXoPro66Vd0PJshpfbziNn1IsqzG0aVmMfrJ8cnBz9fY9NeR1+HIkJIn1aptKeKF5OYvPNp0bDIByiQEQERGJTSdlTS+t00tWOZc1vUr6WNfsx49y9vpdfPjXCWwKNi6r4aKG7ooX9MC4RQdVlqighzO+7FMnS0Nl1o4BUC4xACIiIpmBWWpqpNOraXlffCOdXu7ONhvIfbDqhJrQMKWqRb3w3cB6NhXUmer4bdl164mIiKywjkYWI5XhI+PSDx92r56tjipr07JyEbVo6S87L+DL9dqyGs/ULYGPule3yiUtzIEBEBERUYpOL1ntfMPJcLX9RrvKGNk80Go6vXJDireHPx6oAp+LN2NQq4S3XbyunGIAREREBCA0MlYVO0unl6uTA6b3ro0ONYrC3hTydFEnvWMAREREunf8aiSe/WkfQqNiVaHwD4PqW/26V5Q7DICIiEjXNgSFqeUfYuITUaFIfsy1sU4vyhkGQEREpFvzdpxXBc/S6dWsvB9m9a9rs51elD0MgIiICHrv9OrbsCTe72rbnV6UPQyAiIhIV+4+6PTa+KDT6832ldWq53ruiNIjBkBERKQbB0Ju4a2lR3Ey9I7q9JrRuzba22GnF/03BkBERKSLxUw/XX0SSw9eUdvS6fXj4AaoXbKgpXeNLIQBEBER2a3YhETM2X4eszadUV1eoke9Eni9XSUUKeBm6d0jC2IAREREdkeWuVx7PBQfrgrC5Vv31GV1ShXEe52roRazPsQAiIiI7M3J0Ci8v/IE/j17Q237e7nizfZV0LV2MRY6UzIGQEREZBduRcdj2rpT+G33RTWvj6x99fwTgRjZvBw8XXm4o9T4G0FERDYtITEJv+26iOnrTyPyXoK6rEONAJX14YzOlBkGQEREZLO2nb6uhrtOh99V25UDCmBS52poXM7X0rtGVo4BEBGRjgqDt5y6jm2nI1CzhDeerFwEBdxsc9mHCxHRqsB5fVCY2i7k4YxX2lRCnwYl4cTZnCkLGAAREekg8Nlx5gamrQvGgZDbyZe7ODrg8Qp+aFc9AE9V9UdBDxfYwizOMzeewdzt5xGfmARHh3wY1Lg0XmpVEd4ethnMkWUwACIismO7zkngcwp7zt9U2zL7sQQ8Ry9H4lxENDacDFcnJ4d8athIrmtTNQCFC7jCmiQlGfC/A5fx2dpgXL8Tpy6T4G1ip6qo4F/A0rtHNiifQb4aUCpRUVHw9vZGZGQkvLy8LL07RETZtv/iTRX4SObHmO3p16gUXmxRDkW83FRW6FTYXaw+dg1rjoWqpSGMpFO8QRkftK8eoAKiot7uFn4ttzB55XEcuRyptsv4euDdTlXVEB7b2imnx2+LB0CzZs3C559/jtDQUNSqVQtff/01GjZsmOntZ8yYgW+//RYhISHw8/NDjx49MGXKFLi5ueX4MdNiAEREturQpdsq8Nl66rradnbMh94NSmJUy/KPDGTOXb+LNcdDVTBkDDSMZLkIYzBU2tcT5hIaGYtP15zEsgfLV+R3dcLYVuUxuEkZuDo5mm0/yHbYTAC0ePFiDBo0CLNnz0ajRo1UcLNkyRIEBwejSJEi6W6/YMECDBs2DHPnzkWTJk1w6tQpDBkyBH369MG0adNy9JgZYQBERLbm2JVITF93Sg1nCRnS6lm/hAp8ShTKXiv45VsxKhCS0/6QW0h5lKhS1EsFQ3LKq6EnWb7ix23nMGvTWdxLSFQZqZ71SuC1tpWtbmiOrIvNBEASoDRo0AAzZ85U20lJSShZsiTGjBmDCRMmpLv96NGjERQUhA0bNiRf9sorr2D37t3Yvn17jh4zIwyAiMhWBF2Lwoz1p7D2uNYN5ZAPeLpuCYx9sgJK+eZ+DpzwqFi1pMTqY6HYff4mEmWGwQfKFfZE++pFVWaoWjGvXA9HyeFIgq6P/n64fEW90oUwqXNV1CzB5SvItMdvixVBx8fHY//+/XjzzTeTL3NwcEDr1q2xc+fODO8jWZ9ff/0Ve/bsUUNa586dw99//42BAwfm+DFFXFycOqV8A4mIrNnpsDuYsf40Vh29prYl9uhaqxjGtqqAwML5TfY8Ui80sHEZdboZHY/1J8JU3dD2MxE4ez0aMzedUadSPh4qEJJT7RIF4SCRWDYDOanz2XVOK9Yu6u2GCe0ro0stLl9BecNiAVBERAQSExPh7++f6nLZPnnyZIb36devn7pfs2bN1DeF+/fvY+TIkXjrrbdy/JhCaogmT55sktdFRJSXpFbnyw2nseLw1eShqY41i+KlVhXyvBvKx9MFvRqUVKeo2ARsDApXwdDm4OsIuRmD77eeU6cAL7fkYEiKqaVVPTMSVH3xTzAW7glRy1dIl9rzzcthZPNAeLiwUZnyjk39dm3evBkff/wxvvnmGzXUdebMGYwbNw4ffPAB3n333Rw/rmSMxo8fnyoDJMNmRGRfZA4ZmT8mNCoWdUoWRP0yPqqjyBYyDBdvROOrDWew7OBlFSiIdtUC8NJTFVA5wPxD9V5uzuhWp7g6xcTfV0GQDJNtDApT7+9P/15QJ7/8LniqqlYzJG32zg8mKZTlK+bvvKiG76Ji7ycHcm+2r5ztmiUimwqApIPL0dERYWHauLWRbAcEBGR4HwlyZLhr+PDhartGjRqIjo7GiBEj8Pbbb+foMYWrq6s6EZF9kozxyiPX8NGqEwiL0oa7F+wOUf/LAbpuqUIqU1GvTCFUL+atFtG0FlKQLBP/Ldl/Obn+pnWVInipdUVUL+4NayCZmg41iqqTFDBvPx2hgiGZpTnibrzK7sjJ290Zrav4o27pgpi34wLOPFi+ompRL1Xn0yiQy1eQDgIgFxcX1KtXTxU0d+vWLblgWbal2DkjMTExqqYnJQl4jB9wOXlMIrL/WpmJy49j5zltPpzSvh54qoq/aheXdm85QP9zIkydhAzB1JLsUOlCqF+mEOqV8rHIDMPXIu+pwOf3fZeQkKgFPs0rFsb4pyqq/bNWbs6OaF3VX50ky7Pz7A0VDK07Earea5nMUE7GIbVX21RSbfqPGiYjsrshMBl2Gjx4MOrXr6+KmqVlXTI6Q4cOVddLO3vx4sVVjY7o3LmzanevU6dO8hCYZIXkcmMg9F+PSUT6EB13H19tOI0528/jfpJBBTbSEj7iiUB1kBZx9xNV+/jeC7ew78ItNXngrZgENWuyceZkUdE/P+qV9kkOiqTgN6+GzaTr6pvNZ1WGSpZ6EM3K++HlpyqofbAlMtz1RMXC6vRht+rYd+GmCoZkYsNGZX0wplUFlRUi0l0A1Lt3b1y/fh0TJ05UkxbWrl0ba9asSS5ilskOU2Z83nnnHfWhI/9fuXIFhQsXVsHPRx99lOXHJCL7Jtlg6Yz68K8gVYsiZNhFhlhK+qSuLZHJ9CSoUIFFc+2+sjyEHKi1gOiW2pYZk+UkwzhC5qKRYEhatKWOSFrAjbUtORVxNw6zN5/F/F0XEXdfC3walvVRGZ/H7GBoSDI8MsTFYS6yFhafCdoacR4gItskNSXvrTiuWrRFSR93vNe5GlpVyfkXoBt341QgtE9OF27i6JXI5CEpIzdnBzVbcn0JpsoUUjVFWc1sSBeUdE79/O8FNemfkMDqlacqqqJhWyjQJrIWNjMRorViAERkW6QLSTqk5mw/p4ITKWKWNa9GNi+XPNxlKlLkK7VD+y7exH7JEoXcwu2YhFS3kZilkn8BFcio4urShVCikHuqYCYyJgE/bj+nutKi47XAR2p7JOPzRAU/Bj5EOcAAKJcYABHZBuPMwR/8dQJXI7XhLlkgU7I+ppgFOaurlJ+9fvdBhkirI7pwIybd7fy9ZNhMC4Yi7yWowOdOnNb+LUNoEvhwcU+i3GEAlEsMgIhsY0LASSuOY9tpbbhLMiwS+Ej3kaVdvyPDZlodkQRGUmgthdhpVQ4ooNrZ21bzZ+BDpJelMIiIcjrcNWvTGVU3YxzukqEuGfIy9XBXTkmRdDu1RlZRtX0vPhGHL9/Waoku3ERMfCIGNS6jJgfM7pIRRGQaDICIyCZIsloW/JThriu3tYUyW1QqrLI+Zfw8Yc3cXRxVJ5c9dHMR2QsGQERk9c5HRKvuri2nrqvt4gXdVVv7U1U5dEREOcMAiIislgwdfbP5DL7bck5NCuji6KAmMpQJDSWrQkSUUwyAiMgqh7vWnQjD5JUPh7tkNuHJXaqhrJUPdxGRbWAARERWt+q5DHdtCtaGu4p5u2Fi56poWy2Aw11EZDIMgIjIKsgEg7IG1uwtZxF/PwnOjvnw3OOBGP1kebXaOBGRKfFThYgsbkNQGN5beRyXbmrDXY9X8MN7XaqhXOH8lt41IrJTDICIyGIu3YzB5JXHsT4oXG0X9XbDu52qqvlxONxFRHmJARARWWS4Szq7pMNLVj53csiH4Y8HYsyT5eHpyo8lIsp7/KQh0lngsffCTcQmJFlsH27HxOPrjWcQclNbL6tpeV/V3VW+SAGL7RMR6Q8DINKVf89E4EDILbSoVEQtQKmHYZaExCRsPx2BFYev4p/jockrj1uaLA4qw10daxTVxc+BiKwLAyDSjSX7LuGN/x2BrEk59Z9TKOnjjnbVAtR6TXVKFrSrNZlkhfI9F26qoGf10Wu4FZOQfJ20lft7u1ls3+RdliUhXmxZHvk53EVEFsLV4DPA1eDtz4/bzuHDVUHqvGR+zl6/m2oYKMDLTa3ILcFQw7I+cLTBYEj+lI9cjlRBz19HriIsKi75Or/8ruhUsyg61yqGuqUKMuNCRND78ZsBUAYYANkP+fWe+k8wZm06q7afe7ws3upQBfcSErEl+DpWHwvFxpPhuBt3P/k+vp4uaPMgGGpSzhfOjg6wZqfD7qigZ+Xhq7hwQ6urEQXcnFQ3VZdaxfFYoA+crPx1EBHlFgOgXGIAZB8Skwx4d/kxLNgdorZfb1cJLzQvly77EXc/ETvORGD10VCsCwrD7RTDRV5uTmhd1R/tqxdVc9O4OTtaTfv4yiNXseLQVZwMvZN8ubuzo9rfzjWLonmlwnB1so79JSIyBwZAucQAyPbJTMLjfz+Ev45cg8Q7H3WrgX6NSmWpYHj3uZtYfewa1h4PQ8Tdh8NIni6OaFm5iAqGWlQqbPZ27fA7sVh15JrK9hwMuZ18ucyY3LxiYTW81bqKP9vIiUi3ohgA5Q4DINsWE38fI389gK2nrqvgYEbvOuhYs2iOMkj7L97SgqFjobgaGZt8nauTgwo62tcIwJOV/eHt7oy8EBmTgDXHtaBn59kbqoBbSFDXONAXXWoVQ7vqASjo4ZInz09EZEsYAOUSAyDbJXPMDPtpLw6E3FbDQd8NrKdWEc8t+TM5fDlSBUNrjoXiYopaGwmympb3U/U2T1UNgI+nS64DOJkZWYa3tpwKR0Liwz/ROqUKonPNYqqguYiX5Tq5iIisEQOgXGIAZJvComIxaM4eBIfdURmZeUMboG6pQiZ/HvmTCbp2B2uOXVNF1KfD7yZfJ81jjcr6qsyQrF7un8UgRYbstpy6rjI960+EqSJto8oBBdTwlmR7Svp4mPz1EBHZCwZAucQAyPZcvBGNAXN2q8U0ixRwxfxnG6FSgHlmFj4Tfhdrj4eq7NCxK1HJl8swlQRgkhmSYaoShTzSDbHtOndDZXrkvlGxDzvRSvl4qICnS+1iqOjPGZKJiLKCAVAuMQCyLUHXojBo7h5cvxOH0r4e+PXZRhbLlEh3lgyRSUAjw3Ap1SjurQKhmiW8sSEoHKuOXlP7nHJm5E41i6lsT60S3pyrh4gomxgA5RIDINux78JNDP1pL+7E3ldDRb882xBFClhHbUxoZGxyZmjP+ZvJBcwpFfRwVl1lku2x1QkYiYisBQOgXGIAZBs2BYfjhV/3qxmd65cuhDlDGuRZN1ZuSTv9uhNhqmYoODRK6+CqXQzNyheGixMnKCQiMgUGQLnEAMj6LT90Ba/8fhj3kwxqTp5v+9eDuwsn/SMi0rOobBy/OWMa2Zz5uy5i4vJjkNC9a+1imNqzltUvV0FERNaFARDZDElWztx4Bl+sO6W2BzUujfc6V7OrVdyJiMg8GACRTUhKMqjV3OfuOK+2x7aqgJdbV2CnFBER5QgDILJ69xOT8Pr/jmDpgStqe1LnqhjatKyld4uIiGwYAyCyarEJiRi94CDWB4WpFvHPe9TE03VLWHq3iIjIxjEAIqt1JzYBw3/eh93nb6rFR2f1q4vWVf0tvVtERGQHGACR1c6bM2TeHrW0RAFXJ/w4uD4aBfpaereIiMhOMAAiq3Pl9j0M/HE3zkVEw9fTBT8Pa4jqxb0tvVtERGRHGACRVTkTfgcD5+zBtchYFC/ojvnPNkRg4fyW3i0iIrIzDIDIahy5fBuD5+7BrZgElC+SXwU/Rb3dLb1bRERkhxgAkVX490wEnvtlH6LjE9VK6POGNoSPp4uld4uIiOwUAyCyOFkxfcyCg4hPTELT8r74bmB95HflryYREeUdHmXIon7fdwkT/ncESQagXbUAfNm3NlyduKgpERHlLQZAZDE/bD2Hj/4OUud71y+Jj7pXhxMXNSUiIjNgAKQz5yOiEXUvAZ6ujvBwcYKnixM8XB3Nupq6LGr6+dpgfLP5rNp+/olATGhfmet6ERGR2TAA0lmtzchf98NgSH+di6ODCoQ8nB3h4SqB0YMAyTX1/x5pL3d5eHt3F8fkgEr+d3d2TLdSe2KSAe/8eQwL94So7TfaVcYLLcqZ5w0gIiJ6gAGQTpwOu4Pxiw+p4McvvwvuJxkQE5eoCo+F/B8fk4TbSDDp86YMmCQgkuc9E34XEhd91L0G+jYsZdLnIyIiygoGQDoQeS8BI+bvVy3mjQN91fw6xlqb+PtJuBefiOj4+4iJv4/ouETExMvpvrp9TFzq/+8ZL0++bYr/1fXaYxmzTNpjJSLi7sP9cXbMhy/71EGHGkUt9I4QEZHeMQCyc0lJBry8+JCq/ZGZlWf2q5Oq0NjFyUGdvD2cTVrjE5uQpAVVcQ+DKwmEouPuo0pRL5T29TTZ8xEREWUXAyA7N339KWw8Ga5WU/9uYD345nfN8+eUYmapB5ITuIoFERFZIfYc27E1x67h641n1PlPnqnBBUWJiIgeYABkx0XPr/x+WJ0f1rQsutcpYeldIiIishoMgHRQ9PxWh8qW3iUiIiKrwgBIZ0XPRERExADI7lii6JmIiMjWMACyIyx6JiIiyhoGQHaCRc9ERERZxwDIDrDomYiIKHsYANk4Fj0TERFlH4+UNo5Fz0RERNnHAMhOip4/faYmi56JiIiyiAGQHRQ9P9usLLrVKW7pXSIiIrIZFg+AZs2ahTJlysDNzQ2NGjXCnj17Mr1tixYt1EKbaU8dO3ZMvk1YWBiGDBmCYsWKwcPDA+3atcPp06dhz0XPb7Zn0TMREZHNBECLFy/G+PHjMWnSJBw4cAC1atVC27ZtER4enuHtly5dimvXriWfjh07BkdHR/Ts2VNdbzAY0K1bN5w7dw7Lly/HwYMHUbp0abRu3RrR0dGwl6LnlxYdZNEzERFRLlj0yDlt2jQ899xzGDp0KKpWrYrZs2errM3cuXMzvL2Pjw8CAgKST+vWrVO3NwZAkunZtWsXvv32WzRo0ACVKlVS5+/du4eFCxfCXoqeNwVfZ9EzERGRLQZA8fHx2L9/v8rOJO+Mg4Pa3rlzZ5YeY86cOejTpw88PT3VdlxcnPpfhtNSPqarqyu2b9+e6ePI/aKiolKdrBGLnomIiGw8AIqIiEBiYiL8/f1TXS7boaGh/3l/qRWSIbDhw4cnX1a5cmWUKlUKb775Jm7duqWCrE8//RSXL19WQ2aZmTJlCry9vZNPJUuWhLVh0TMREZHp2GzxiGR/atSogYYNGyZf5uzsrOqETp06pYbLZHhs06ZNaN++vcoEZUYCpsjIyOTTpUuXYK1Fz03KseiZiIgot5xgIX5+fqqAWbq2UpJtqe95FCloXrRoEd5///1019WrVw+HDh1SgYxkgAoXLqy6y+rXr5/p48kQmZysUWKaouev+7LomYiIKLcsdiR1cXFRwcqGDRuSL0tKSlLbjRs3fuR9lyxZoup2BgwYkOltZChLgh8pjN63bx+6du0KWzSDRc9ERET2kwES0gI/ePBglZ2RoawZM2ao7I50hYlBgwahePHiqkYn7fCXtLv7+vpmGBxJ4CO1QEePHsW4cePUbdu0aQNbw6JnIiIiOwyAevfujevXr2PixImq8Ll27dpYs2ZNcmF0SEhIutqd4OBg1dH1zz//ZPiYUuwsgZUMpRUtWlQFUe+++y5sDYueiYiI8k4+g8weSKlIG7wMoUkdkZeXl0WKnrvN2qHqfqTo+ZdhDVn3Q0REZMLjN4+qVl70PLNfXQY/REREJsYjq5WZvi510bOPp4uld4mIiMjuMACysqLnmZtY9ExERJTXGABZiVNhdzCeRc9ERERmwQDICkjR8/Pz9yOGMz0TERGZBQMgC2PRMxERkfnxSGthLHomIiIyPwZAFsSiZyIiIstgAGQhLHomIiKyHAZAFip6HvHLPhY9ExERWQgDIAsVPV+4EcOiZyIiIgvhkddCRc9uzix6JiIispkAqEyZMnj//ffVSu2UPSx6JiIistEA6KWXXsLSpUsRGBiIp556CosWLUJcXFze7J2dORl6J7nouWttFj0TERFZSj6DwWDIyR0PHDiAn376CQsXLkRiYiL69euHYcOGoW7durB1UVFR8Pb2RmRkJLy8vEz62NtOX0fjQF/W/RAREVnw+J3jAMgoISEB33zzDd544w11vkaNGhg7diyGDh2KfPnywRblZQBERERElj9+O+X0SSTYWbZsGebNm4d169bhsccew7PPPovLly/jrbfewvr167FgwYKcPjwRERFRnnHKydCXBD0y9OXg4IBBgwZh+vTpqFz54Vw23bt3R4MGDUy9r0RERESWCYAksJHi52+//RbdunWDs7NzutuULVsWffr0Mc0eEhEREVk6ADp37hxKly79yNt4enqqLBERERGRNcp2K1J4eDh2796d7nK5bN++fabaLyIiIiLrCYBGjRqFS5cupbv8ypUr6joiIiIiuwuATpw4keFcP3Xq1FHXEREREdldAOTq6oqwsLB0l1+7dg1OTjnuqiciIiKy3gCoTZs2ePPNN9UkQ0a3b99Wc/9IdxgRERGRtct2ymbq1Kl44oknVCeYDHuJQ4cOwd/fH/Pnz8+LfSQiIiKybABUvHhxHDlyBL/99hsOHz4Md3d3texF3759M5wTiIiIiMja5KhoR+b5GTFihOn3hoiIiMgMcly1LB1fISEhiI+PT3V5ly5dTLFfRERERNY1E7Ss9XX06FG12rtxMXnjyu+JiYmm30siIiIiS3aBjRs3Tq31JTNCe3h44Pjx49i6dSvq16+PzZs3m3LfiIiIiKwjA7Rz505s3LgRfn5+ajV4OTVr1gxTpkzB2LFjcfDgwbzZUyIiIiJLZYBkiKtAgQLqvARBV69eVeelLT44ONhU+0VERERkPRmg6tWrq/Z3GQZr1KgRPvvsM7i4uOD7779HYGBg3uwlERERkSUDoHfeeQfR0dHq/Pvvv49OnTrh8ccfh6+vLxYvXmzKfSMiIiLKE/kMxjauXLh58yYKFSqU3Alm66KiouDt7a2W+/Dy8rL07hAREZGJj9/ZqgFKSEhQC54eO3Ys1eU+Pj52E/wQERGR/ctWACRLXZQqVYpz/RAREZG+usDefvtttfK7DHsRERER6aIIeubMmThz5gyKFSumWt9lXbCUDhw4YMr9IyIiIrJ8ANStWzfT7wURERGRrXWB2Rt2gREREdmePOsCIyIiItLlEJis/fWolnd2iBEREZHdBUDLli1LNzeQLID6888/Y/LkyabcNyIiIiLrrgFasGCBWgpj+fLlsHWsASIiIrI9FqkBeuyxx7BhwwZTPRwRERFRnjFJAHTv3j189dVXKF68uCkejoiIiMi6aoDSLnoqI2h37tyBh4cHfv31V1PvHxEREZHlA6Dp06enCoCkK6xw4cJo1KiRCo6IiIiI7C4AGjJkSN7sCREREZG11gDNmzcPS5YsSXe5XCat8ERERER2FwBNmTIFfn5+6S4vUqQIPv74Y1PtFxEREZH1BEAhISEoW7ZsustlZXi5joiIiMjuAiDJ9Bw5ciTd5YcPH4avr6+p9ouIiIjIegKgvn37YuzYsdi0aZNa90tOGzduxLhx49CnT5+82UsiIiIiS3aBffDBB7hw4QJatWoFJyft7klJSRg0aBBrgIiIiMi+1wI7ffo0Dh06BHd3d9SoUUPVANkLrgVGRERk38fvbGeAjCpUqKBORERERHZfA/TMM8/g008/TXf5Z599hp49e5pqv4iIiIisJwDaunUrOnTokO7y9u3bq+uIiIiI7C4Aunv3LlxcXNJd7uzsrMbesmvWrFkoU6YM3Nzc1Hpie/bsyfS2LVq0UOuQpT117Ngx1f6NHj0aJUqUUPVJVatWxezZs7O9X0RERGS/sh0AScHz4sWL012+aNEiFWxkhzzO+PHjMWnSJBw4cAC1atVC27ZtER4enuHtly5dimvXriWfjh07BkdHx1RDb/J4a9asUSvTBwUF4aWXXlIB0YoVK7L7UomIiMhOZbsLbOXKlXj66afRr18/PPnkk+qyDRs2YMGCBfjjjz/QrVu3LD+WZHwaNGiAmTNnJrfTlyxZEmPGjMGECRP+8/4zZszAxIkTVTDk6empLqtevTp69+6Nd999N/l29erVU0N0H374YZb2i11gREREtic7x+9sZ4A6d+6MP//8E2fOnMGLL76IV155BVeuXFGTIZYvXz7LjxMfH4/9+/ejdevWD3fGwUFt79y5M0uPMWfOHDX5ojH4EU2aNFHZHtknie1kwsZTp06hTZs2mT5OXFycetNSnoiIiMh+ZTsAElJzs2PHDkRHR+PcuXPo1asXXn31VTWElVURERFqFml/f/9Ul8t2aGjof95faoVkCGz48OGpLv/666/VUJzUAEmtUrt27VSd0RNPPPHIBV4lYjSeJAtFRERE9itHAZCQjq/BgwejWLFi+OKLL9Rw2K5du2Aukv2ReqSGDRumC4BkPyQLJBkm2bdRo0Zh/fr1mT7Wm2++qdJlxtOlS5fM8AqIiIjIUrI1EaJkZn766ScVfMgwkWR+ZPhIhsSyWwDt5+enCpjDwsJSXS7bAQEBj7yvZJ6k6Pr9999Pdfm9e/fw1ltvYdmyZcmdYTVr1lQzVk+dOjXVcFtKrq6u6kRERET64JCd2p9KlSqpleCl+Pjq1asq25JTMjwlxclSQG0kRdCy3bhx40fed8mSJSrwGjBgQKrLExIS1ElqiVKSQEsem4iIiChbGaDVq1erVeBfeOEFky2BIS3rMoxWv359NZQlgZVkd4YOHaqulwVWixcvrmp0UpIMlHSb+fr6prpcKr6bN2+O1157Tc0BJOuTbdmyBb/88gumTZvGnzgRERFlLwDavn27Cjwka1OlShUMHDhQdWDlhrSrX79+XbWyy/Ba7dq11Rw+xsLokJCQdNmc4OBgtS///PNPho8pQ2NS09O/f3/cvHlTBUEfffQRRo4cmat9JSIiIh3PAyQZGpnAcO7cuaoTSzq5JLsybNgwFChQAPaA8wARERHZ9/E72wFQ2myMZIXmz5+P27dv46mnnrKLGZcZABEREdmePJ0IMSUpipZV4C9fvoyFCxfm5qGIiIiIzCZXGSB7xQwQERGR7TFbBoiIiIjIFjEAIiIiIt1hAERERES6wwCIiIiIdIcBEBEREekOAyAiIiLSHQZAREREpDsMgIiIiEh3GAARERGR7jAAIiIiIt1hAERERES6wwCIiIiIdIcBEBEREekOAyAiIiLSHQZAREREpDsMgIiIiEh3GAARERGR7jAAIiIiIt1hAERERES6wwCIiIiIdIcBEBEREekOAyAiIiLSHQZApC8Rp4HT6wCDwdJ7QkREFsQAiPRBAp5ds4FvmwC/9QD+/drSe0RERBbkZMknJzKLmJvAijHAyb8eXrZuIuBXEajUzpJ7RkREFsIMkDnduwX8/Rpw/ZSl90Q/QnYD3z2hBT+OLkD7z4F6QyUlBPzvWSDshKX3kIiILIAZIHNa/QZwZDEQcQoY+CeQL5+l98h+JSUB/34JbPgAMCQCPoFAz5+AorWAxATgxhngwjZgYW/guU2Ap5+l95iIiMyIGSBzavEm4OgKnNsMnPjT0ntjv+5e1+p81r+nBT81egLPb9WCH+HoDPT6BShUFrgdAvw+CLgfb+m9JiIiM2IAZE4+ZYFmL2vn174NxN219B7Zn3NbgNlNgbMbACd3oMtM4OkfANcCqW/n4QP0Wwy4egEXdwCrxrMzTA+SEoGTq4BTay29J0RkYQyAzK3ZS0DB0kDUFWDr55beG/uReB/Y+BHwS1fgbhhQuAowYhNQd2DmQ42FKwE95gH5HICD84Fd35p7r8lcEu4Be+cAX9cDFvUDFvQClj7PLyFEOsYAyNyc3YH2n2rnd85kQbQpRF0FfukCbP1MK26uOwh4biNQpMp/37dCa6DNR9r5f97W5ggi++oAlC8aM2poWb5b5wE3by3oPbII+L45EHrU0ntJRBbAAMgSKrUHKrYDku4Dq1/j0EtunPoHmN1MG8ZyyQ88Mwfo8jXg4pH1x3jsBaDOQMCQBPwxDLgenJd7TOYQeRlY8xYwvTqw8UMg+jrgXRJo9ynw8glgyCqgQDGtGP6HVsDeH/l3SKQz+QwG/tWnFRUVBW9vb0RGRsLLyytvnuTmeWBWIyAxTutOqtY9b57HXknR8sb3H05oGFBTex99y+X88eZ30wIpKY6WDJLUCZFtkWkN/v0KOLpE+4Ih/KsDTcdpf2NSAG8UfQP48wXg9IN6oCpdtODZvaBl9p2IzHr8ZgBkqQBIbJoCbPkE8CoOjNoDuObPu+eyJ7cuapmaK/u07YbPA20+AJxcc/e4ckD8oSVw+yJQ5nFg4LLUB0yyTvIRdvFfYMeXD4MZIT/Dpi8B5VtlXgcm9905S+sYTEoACpYCevwElKhntt0nIsscvzkEZkksiM6+E8uB2Y9rwY/UcvT+DejwWe6DH+Hpq3WGyVCazBEkk1by+4F1z/UUtBKY8xTwU4cHwU8+LZMzfCMw5C+txutR823JdU1GA8PWan+LMi3C3DZaZlEe3x5FnAH2zQXiYyy9J0QWxQyQJTNAIng1sLAP4OAEvLATKFwxb5/PViXEakXKUqshSjQEeszRvrGbWvAa7WciBdXtPwMaPW/656Ccux8HHF6kDXVJDY+Q+bVq9wWajM35MGhsJLBi7MM5uiq0Bbp9qwXG9iA6Atj8iRb8yPxY9YYAnb+09F4RmRSHwGwpABILegOn1gCBLThDdGbfWJcMAcIedOvIsMaT7+Tt8NSOr4B172rdQv3/0IZRyLIkQJGDt0xXIFMdCFdvoMGzQKORQAH/3D+HfBzunwesnqDV50mh9DM/AmWawqa/POz+Ftg2DYiLeni5fOkavU+bn4zITjAAsrUAiAXRmTu8GPjrZSAhGvDwA7p/pw1r5DX5s1g+Gjj0q3aQfW4D4FcBdtEWfuR3rd4soAZQuLJphg/zUtQ1YNc3wL55QPwd7TIJTBq/qGUx0k5yaQrSGr9kKHDjtBYEt3gLeHw84OAImyFDeMf+ADa8D0Reetgs0OZDYMcM4OxGoFY/oDvnvzKrWxeAs5uA/EWAyh0tvTd2hwGQrQVAKQui5YN99F4WRMdHA3+/rgUgxoJWmdHZq6h5h1p+7gJc2gX4lAOGr7ftzrCLO7UFYKXmLGUWwK8SEFBd65aSoEhO1rA2msyRJeu5SRAsBcpCAjYZ5pLlTZxc8vb5ZZJEqQM7vEDbLvuE9jtYIABW78J24J93gKsHtW1ptGg1EajRC3BwAC7vB358UgvupAHDHoJ7ayW/R/LzkNnpz2wAbp59eJ289zIhK5kMAyBbDIBkplrJAkkHkgzxPDUZuhV2XPv2HRGsfUA3nwA88aplvn3LumI/PAlEhgBlmwMD/md7nWGSCdgxXZspW2o/pM3fu4SW5Yi9nfF9ChR9EBA9CIr8a2i1Neb4GVzaA2yfAQSvenhZqcZaK7vU5cgB3JwOLQBWvQIkxACehYGnvwfKPQmrFHEaWDfp4XvnUgB4/GXgsRe1SVhTWtAHOLUaqP4M0GOuRXbXLskhVf62jAFPyK6HAbzI56h9wZUhXVkfssUES+6t3WEAZIsBUHLxbe8HBdH/6u+bgfwqHvgZWP0GcD8WyB+g1V+Ufdyy+xV6DJjTRhuGazAc6PgFbMbdcGDpCODcJm1bMgCdpmnDRvJ+y4SBYce01xh6RDt/81zGjyVrq/lXTZ0p8q9mmiEoCdJO/6MNzYTsfHh5pY5a4FOqESyejfpjqPb+SKeZrOnX8m3A0QlWWeAsB1kZHpQDbP7CGd/n2hHguwd/W/J5Iz9Lyvn7L8NaxqAnOjz19dKsUa4VUL61lkmU9ej+HKllX0ftZt2nCTEAstUAKGVBtGQbBi3Xzx9GbBSwchxwfKm2Xf4poPts6xiKESf/1taQks6wDlOBhs/B6skHsgQ/8mEswUvHqUDt/v/9OxV3R5tQUIrO5ZusBEfhJ7QMSEYko6QyRTUfZo1k1uWs/O7KBJRSpyJF59eDtMscnIFavbWhLmv6EiBZ2rVvaUGGKNlIm3m8YEnL7tPu2akLnCu21zLIWXnvfh+sdb1V7gT0+S3Pd9duJCZomUpjwHPtsPbZYOTsoQ3bS/OEBD6SPU359yDZn8/LA4nxWvevfLEgk2AAZMsBkB4Loq8c0L5dS3GgZL+kVqHxGPMPdfyX7dO1CfPk2/XApVrXnrUuDCv1ZFunah/KRapqi74WqZy7VdQlM6QCoqMPs0Z3rmZ8e5mjSYbNVKboQX2RrM1mLLiWIGv/z1pxs7EmSYZr6g/VhmvMWeuVXceXae3yEnC4FdRa5St3sHyBc9FaWoGzZBiyKvwk8M1j2u/JiM1AsTp5tss2Tz6bVcCzETi/9WFBvpH8vpd/Ugt4Sj32380FC/sCwX8DT7wOPPl2nu66nkQxALLhAEhPBdHyqyctzesmamPk3jIL71ygZANY7f4uG6ktoikHPlkuI6dzzuSVyCvA/4YDIf9q23UHA+0+yd7aaNmdPTtlpkgCo+snHy5DkZIquK4I+JYHzm/RvgWL/P7aemz1h2mBk60cDCVoNxYZN3pBy7qYo6NOCmrXvg1cO6Rte5V4UODcM2dfGiRLeGSxlnUd8IfJd9c+ipfXpx8a9vDVasEk4CnXMvvF8dKNufQ57e9BpiPQS7Y/jzEAsvUAKFVB9Djgqfdhd6Qde/ko7RuQkBR815mAeyFY/ZwqP3cCLu8FfCtonWHWsnaU1JDJ2lb3bmrZlM4zgBo9zL8f0j0nC8omZ4qOZlxwLR/8MsxVq4/1t+JnNny3YTKwc6a2XbQ20HMe4BOYhwXOEx/+zTyqwDk7bpwFZjbQaoeG/WP5eitrLV6WAF6GPSXokaGtgFq5y1LLsL8aBosDRm7XsqWUawyAbD0AsveCaPlg+UPasS8Dji5A24+14mJb+QZ0J0zrDJP9lw/DfkssWwyb0YFYMmnWlJ2SjxkZ6pIskdT6SCZIalWsbZgzx4HnSODeLS0o6fKl1lmVlwXOMlQo3ZGZFThn14oxwIFftOGzwSuhr+LljVrAI/+nK14u/bCOR94bNxMfDxb1B07+BTQbD7SeZNrH1qkoBkB2EADZY0G0/KrJgpVStyAf5PJNWeqcpHbB1kgHzdy2WmGwzELc/lMLDsUMA64eMP9QDD0k3XRq6PFBB5t0YMnQY24yM5IJliFiKXA21ptU6gC0nmz6JXNkDbSv6moZj0ErgMDmsFtSPyUzY8sQlHEY0cjZU+s6VR1brbTPqLz83D36hzY3lzQSjD1o+5/xVoABkL0EQPZWEC3z0Gz9LH07tq06sQL4faB2vtMM7Vu5RYtxv+HMsvZQfC4H6KNLtC8KkmVMLnD+KG+nhFj1KrD3B22YRxaHtdeDscwo/tdLD7dl6MkY8MhrN+eXB6kzkmGw+/eAEVuAYrXN99x2iqvB2wtZo0em3xdr3tL+WGzV5k8fBj/yQS6Tydly8COqdtHWJBN/vwqc32ae55XMgCwPIuujSfAjH9pSQ8Bp9S1LhkHl92HgMsCziDZ1wA8tgYO/adnPrJDfIbnPshFa8CMFzt2/B57bnPfzYT3+CuDkBlzarQ0J2aM7odpEkULqK185pf3tSNZUhrjMnTmVBpeKbbTzxilAyGwYAFk7+SOVcWhpNzYGELZGvhFv/lg7L226TUbbz7fLx18FqvfQup4kG5TZJIKmnJDvx9YP56KR2oEhqyw7Fw2lJh1BclCVaRJkiHT5i8Cy57XW/0f9XKUtWgrsZVhGaolaTQLG7NPmRDJHrZRMPSC1eGLjB1kP2myJLG0SFwkUq6u9v6ZYQDe3qj39MKNrj++5FWMAZO2khqD9g8Bn5yytu8aWSM2PfJgK+cBpMgZ2RQI56V6TD1QpgpXlBYzt3aZ2aCHwfQuts0qWZBiwVCuctLWlOfRADqwDlgFPvqsVLUubufzspHYsbRGuDD3JXDzS3SW3bfCcVg8i2d/c1BDlhCzDI3UwEoTJbMX2RF5P0ArtPe7ylfUsbFuhjfaeSx2WzIlGZsMAyBZUaqd1zEiWQb7B2Mq3BAnYpG1XyLIBxuE8eyMHqb4LtXmbZP0y6XCTiQNNRYY+Zf4h6TSS5TgkVS8ZBqlZIOslWRtZw04ydLIY6Y0zWvZuzw/aMKYUN39ZW6u7kaYAKXB+cZc2Y7epuruyS573sZHa+U0fa/VI9kBaziXQFE3HWlfLuczRJZ/xgsNgZsUAyFa0mwI4umoTyEmq1Nrt/k5bNkA0fwNo/jrsmkyCJkGQLDlxZt3DwC+3pG1cMgeHF2oLw7aUGpM/bWNFctKUbqwFrBXbaQ0NUi/2eQVt6gLp7pJpCwb/pf3+mLq7KyckS+vqDYQfB07YwGdNVkhBuZQRSLeVfB5ZG2ODy/E/7SfotAEMgGyxIFpmgbXmgui9c4DVrz+sUZEFGfVAOji6f6udlzl5ZF6VnJIsn7yPMt/QjdPa6uxykGz+mvWk7inrPHyAvouAtlO0tc4k8JEC56d/AJ7bZPkFf1OSyUgbj3o4K710t9kyWbNr74/aeZkc1NzDilkhi6S65NcK36/ss/Te6AYDIFsriC5UxroLomV9p1UPAjWZ5Vem6LeXguesfpMzBnx/jQcu7Mj+Y0gNkXR4yfsoGYMKbYGRO4AyTU2+u2RG8nfQ+EXg+S3a+mFS4Fyzl3VOBilLk0ggJMG3tOTbKpkkVKaKkGkJZCFga12/T4IyGQIVtpDhtxNW+JdHj/wjafep9RZES7uvrOguZHp+WcJDT8GPkaTYJRCSSeWkM0wWec2qK/uB2Y9rK3TLLOAyZYBkDjx983KPyZz8qwG1+1lnJsJIZjyWgmixWbJAKZaEsLUmDJl53MNP60C1ZhwGMzsGQLbGWguiDy/W1vaSb1oNR2jLW+gx+EnuDPtGW1k75saDzrCoR99Hfo4S1M5pq60BV7CUti6TTBlgjRkCsn8Nn9O6DeX38eCvsDmydpoxUy6zcsswpDWTpgZXLy3DL3MxUZ6zik/WWbNmoUyZMnBzc0OjRo2wZ8+eTG/bokUL5MuXL92pY8eHk8BldL2cPv/8c9gFayuIluncpUNJgh9Z0Vva9vUa/KTs7OizAMgfoH0DlVWfM+sMk4VhF/bRisYla1S1K/D8NqBEPXPvNdFDLp7a5Ihi6+faQsC2QjIoko1OjNfqayyxKHB2ySSMxslM2Q2mjwBo8eLFGD9+PCZNmoQDBw6gVq1aaNu2LcLD0yxK98DSpUtx7dq15NOxY8fg6OiInj17Jt8m5fVymjt3rgqAnnnGhAsUWpI1FURLALZ0BGBIAuoOAjp8weDHyKsY0HeBNruurOm2/r30t7n4LzC7mXa9BLUdvwB6/mw9K8yTvtUbqk3vIAvZHvgZNuPgfODiDsDZA+g4zXY+k4yTIp5YbtqpNMg6A6Bp06bhueeew9ChQ1G1alXMnj0bHh4eKmjJiI+PDwICApJP69atU7dPGQClvF5Oy5cvR8uWLREYGAi7YQ0F0UErtTlvZA4TKTDs9CWHa9IqXg/oOks7/+9XWp2UkA83+Vb9U0ft4OJbHnhugzYTr618WJP9c3bTOg+NM7rHx8Dq3QkD1r37cP6xQqVhM6RI280buBumfTmiPGXRo1V8fDz279+P1q1bP9whBwe1vXPng1WV/8OcOXPQp08feHp6Znh9WFgYVq1ahWeffTbTx4iLi1MLqKU8WT1LF0Sf/FvrVJLgp2ZvoMvXDH4yI+n3Jx5MCyCLMMoiqr8+DWz8UMuc1eyjLYRoTZOzERnVHqDVpEWHP2wnt2Zr3tA6KWV+pUYPJnW0FU4uQOXO2nlrKG+wcxY9YkVERCAxMRH+/qnXY5Ht0NDQ/7y/1ArJENjw4Q/Wr8nAzz//jAIFCuDppx+kFjMwZcoUtXqs8VSyZEkbLIh+1XwF0af+AX4fpD1v9We0gl/OTfNo0hpfpYtWkyCdYec2a+l5aYd++jttUUQiayQH5eYTtPPbpz96TTNLC16jBQ7G5S5kgVpbU/1BN5gs22HrczBZOZv+yi7Znxo1aqBhw4aZ3kaG0vr3768KrDPz5ptvIjIyMvl06dIl2Iz2n2g1Jue3mucbg6wSvXjAw2JdWanaFj9kzE2yY91nAwE1te0i1YARm7V2aCJrJ1leGaa9dxPYNRtWSQIz4xxkMpFj0VqwSWWbA+4+QPR14OJ2S++NXbNoAOTn56cKmGWYKiXZltqdR4mOjsaiRYseObS1bds2BAcHPzJDJFxdXeHl5ZXqZDOkDqjZy+YpiJasxaJ+2uR8lTsBz8xh8JPdrpohfwG9f9XqfQpXsvQeEWWN/J0bJ/j892tt4V9rI0PKUk8nn4m2PPu8LG5chcNgdh8Aubi4oF69etiwYUPyZUlJSWq7cePGj7zvkiVLVO3OgAEDHpkhkseXzjK7Zo6C6PPbtPls7sdqw2495nEV8pyQAkf5cLPmSfCIMutQKlIViIvU6g6tyeV92vqDotN0bRoKW2acFFHqBW11EkobYPEhMGmB/+GHH1StTlBQEF544QWV3ZGuMDFo0CA1RJVRcNOtWzf4+mY8Q64UMkuQ9F/ZH7sgB1OZeyevCqKlG2FBb+D+PaBCG6DXz1pdABHpaxi35YMFjnd9C0RHwCpIgGBc7kIaCso9CZtX5nFt9moZcpTyBrLPAKh3796YOnUqJk6ciNq1a+PQoUNYs2ZNcmF0SEiImssnJRnW2r59+yOHv2R4zGAwoG/fvtCFim3zpiA6ZDfwW08gIVr7YOk1X5uwi4j0R4a+pbYm/i6wYwasZrkLWbnew1ebgd5ehhyrdtHOcxgsz+QzSJRA6bJH0g0mBdE2VQ8ka07NaqQNU8kQVfXMO9+ynFb+pZu2cnXZJ4B+v3PohkjvpAt0QU/AyR0Ydwgo8Oh6zTx14yzwTWOtLlEaMmr1ht2QzM/PnQG3gsCrp5l1z4Pjt8UzQGTqgmjjDNFv5a5d9coBYP7TWvBTuhnQdzGDHyICKjwFlGioDYlvm2a5/ZDv7mq5izggsCVQsxfsSummgGcRIPa2tuwRmRwDILstiL4GbMlhQfS1w8D87lqxY6nGQL/Ftl9USESmITOVP/mOdn7/POC2haYNkQVaL2zTMlFS+GxvM6jL3Goy1Yg4xrXB8gIDIHucut5YEL3rm+wXRIceA37pqn3rkG95/Zdwkj4iSi2wuVaoKxN7bptq/ue/Gw788yAIk8JsWR/RHhnLGE6uAu7HWXpv7A4DIHstiK7UIfsF0eFBwC9dtDk+ZA2rAX8ArgXyem+JyBbJOlvGTMzNc+Z97jUTtC9pMrHoYy/CbpV8DChQVMvGn91o6b2xOwyA7FW7KSlmiM5C+lQyRVJwF3NDW0NnwFJtzhoiooyUbgyUb6190crpcHtOi7CP/Q/I52C7y11kZ+qBqt208+wGMzkGQLooiH770QXREWe04EemXpcFOQcuA9wLmm1XicjGs0BHFgPXT+X988lM98blLiTzU6wO7J5xUkRZgDoh1tJ7Y1cYAOm9IFraSH/uBNwN09anGrgc8PAx954SkS0qXheo1BEwJAGbp+T98236CIi8pK1Ob5yU0d6VaAB4Fdc6cs+st/Te2BUGQHoqiA4/mX7eoJ+7aAFS4crAoOWAZ8YzaxMRZcgYiMhQuzRR5JUr+4Hds1Msd+EJXZBhMGMWiMNgJsUASE8F0atfe1gQfTsE+KkzEHUZ8KsIDF4J5C9s6b0lIlsTUF1bJ0xs+jgPl7sYp2WaavTSao/0xBgABa8G4mMsvTd2gwGQHguiIy8DP3UCIkMAn3IPgp8ilt5LIrJVsvq6FCUHr9ImUTW1nTOBsKOAeyH7We4iO6Qr17uUtiTRmXWW3hu7wQBIjwXRUvB8+yJQqCww5C/LTmVPRLavcEWgZu+HdTqmJHWKmz/Rzkvwo8dMtUzyWI3dYKbGAEiPBdEyZ4cUEUrmx6uYpfeMiOxB89cBByetUDdkl2keU4bs/3pZW9+wbHOglk4Wt37UpIin1gLx0ZbeG7vAAEhPBdEdpmppau+SwOC/gIIlLb1XRGQvfAKBOgO08xs/NM1jHl6orYMlQ/j2uNxFdsj8bPIlNiFGC4Io1xgA6W0Rw1F7gVG7gUKlLb03RGRvnngNcHTR1ug6l8sFPO9e1xZ1Fi0mAL7loGtqGOxBFigrk9vSf2IApDd+5fXTPkpE5uVdAqg39GEWKKvL8GRk7Zvasjz+NYDGo022i3bRDXZ63aMnt6UsYQBERESm8/h4bYX2y3tyPnHf6fXA0SUPlrv4EnB0NvVe2iaZqV86d6UmKniNpffG5jEAIiIi05Gu0obDtfMbP8h+FkgKfFe9rJ1vNFJrAaeHw2DGYmh2g+UaAyAiIjKtpi8BLvmBa4eBk39l774ymaJM1CrNGsa1xij9MJjMBxQbZem9sWkMgIiIyLQ8/YDHXngY0CQlZe1+Vw9qy/aIjtMA1/x5t4+2qkhVwK8SkBgPBP9t6b2xaQyAiIjI9KRw2c0bCD+Rta6lxPvAirHachfVnwEqtjHHXtpoNxjXBjMFBkBERGR67gWBxmO087JSvAQ4j7JrFhB6BHArCLR7MPMz/ccw2AatU45yhAEQERHljcdGAu4+wI0zwNHfM7/dzfPApina+TYfcm3C/1KksjYUlpQAnOQwWE4xACIiorzhWgBo9qCjS9bzuh//iOUu7gFlHn84mzQ9GofBco0BEBER5Z0Gw4H8/toCzId+TX/9kcXAuU2AoyvQ+Ut9L3eRkwBI3ruYm5beG5vEAIiIiPKOiwfw+Cva+S2fAwmxD6+LjgDWvPlwMVW9L3eRHX4VtFmyk+5nf6oBUhgAERFR3qo3BPAqAdy5Cuz/6eHla98G7t0EilQDmo6z5B7apuoPskDHuDZYTjAAIiKivOXkCjR/TTu/7QtttmfpYDqySPq6gS5fcbmL3AyDnd+qZdMoWxgAERFR3qvdHyhUBogOB3Z8pRU+i4YjgBL1Lb13tsknEChaGzAkAkErLL03NocBEBER5T3J8DSfoJ3f8olWFC3DYq3etfSe2TZ2g+WYU87vSkRElA01ewHbpwERp7TtjlO1Vvk8lpiYiISEBNilCp2BXT8C1y8CN64Anr6wZ87OznB0dDTJYzEAIiIi83BwBFpPBhb104KhSu3z9OkMBgNCQ0Nx+/Zt2LUnZgKJccClK4Cr/S+QWrBgQQQEBCBfLqdMYABERETmU7kDMD7ILLM9G4OfIkWKwMPDI9cHTKsVXUCrrXL20Oqs7JTBYEBMTAzCw8PVdtGiRXP1eAyAiIjIvLxyd+DK6rCXMfjx9bXvYSE4FQHirgOGe4CzA+DoAnvl7u6u/pcgSH62uRkOYxE0ERHZHWPNj2R+7J6TC+DsqZ2/Fwl75/HgZ5rbui4GQEREZLfsdtgrLfeC2v86WB0+n4l+pgyAiIiI7CUASojOcNHZMmXKYMaMGebfLyvGAIiIiMiKshuPOr333nsZ31HqflweDIPFpu9627t3L0aMGJHHe29bWARNRERkJa5du5Z8fvHixZg4cSKCg4OTL8ufP3+qrigp9nZyenAodyukLTMiw2BpuuwKFy4Mq3I/FnBys+guMANERERkJWR+G+PJ29tbZX2M2ydPnkSBAgWwevVq1KtXD66urti+fTvOnj2Lrl27wr9cdeSv0BQNnnoa69f+/cghsHz58uHHH39E9+7dVVFxhQoVsGKFGZbTMBiAu2FAeBAQcxOWxACIiIh0Qc0jE3/fIid5blOZMGECPvnkEwQFBaFmzZq4e/cuOnTogA0bNuDgxuVo16IJOnd7BiEhIY98nMmTJ6NXr144cuSIun///v1x82YeBiWGJOB2CBB1VdtOiIElcQiMiIh04V5CIqpOXGuR5z7xflt4uJjmkPv+++/jqaeeSt728fFBrVq1tI1of3zwuh+Wrd2iMjqjR4/O9HGGDBmCvn37qvMff/wxvvrqK+zZswft2rWDySUmALfOa0N0wqs44GnZYTkGQERERDakfv36qbYlAyTF0atWrVI1RPcT4nEvNg4hF84/8nFq1qyZfN7T0xNeXl7JsyybVMI94OY5IDEeyOeozVbt5gVLYwBERES64O7sqDIxlnpuU5FgJaVXX30V69atw9SpU1G+fHm43wtDj6GjEB9z5z8XFk1J6oKSkpJgUrGRwK0L2vCXdKr5lAOcLVv8bMQAiIiIdEEO8KYahrImO3bsUMNZUtAs7oYVwIXLV4HEWMvtlMGgrU9mrPdxyQ8UKgs4Ws/7zyJoIiIiGyYdXEuXLsWhQ4dw+PBh9Bs+BklJBiDxvtZubm6GNMXOHr6AbzmrCn4EAyAiIiIbNm3aNBQqVAhNmjRB586d0bZdO9StWU278l76SRHzVGICcOMMcO9BN5lXCcC7JJDP+sKNfAZT9ubZiaioKDX/QmRkpCoKIyIi2xIbG4vz58+jbNmycHOzjpoTs4q+AUSGAE7uQJHK5nnOBPMUOz/qZ5ud47d15aOIiIgo99y8gch8wP17QEJs3hcex6YsdnYFfAKtptg5M9aXkyIiIqLckXob1wKZrg1m8pmdJfMjwY8UO/tVtPrgRzAAIiIisucV4mVtMB0XO2fGNvaSiIiIsj8MBhkGi9Xqc5zd83Bm5xKAp5/MNQBbwQwQERGRPXJIMQxmym6whHtAxCkt+JFiZ5ncMH9hmwp+BAMgIiIie+VeSPs/9pZWr2OKYueIU1qnlxQ7S72PFSxrkRMcAiMiIrL7YbA4bSgsp8NgBuuf2Tm7mAEiIiKyVw6ODzM0OS2GNth2sXNmGAARERHZMzdjN9jt7A+DJSYAEbYxs3N22f4rICIiomQtWrTASy+9lLxdpmpdzPhhAZAYpxUwZ7JQ7J9//plxsXNC1oudM3wcK8UAiIiIyErIWl7t2rXL8Lpt27apAOPIkSPZesy9e/dixLNDszcpYuyji53fe+891K5dO93drl27hvbt28MWMAAiIiKyEs8++yzWrVuHy5cvp7tu3rx5qF+/PmrWrJmtxyxcuDA8fIs+rAN61DCYwQDcyfnMzgEBAXB1dYUtYABERERkJTp16qQClp9++inV5Xfv3sWSJUvQrVs39O3bF8WLF4eHhwdq1KiBhQsXPvIxy5Qpgxmz52l1O4nxOH3iCJ544gm1kGjVqlVVwJWq2PnOVbzx0Zeo+MQz8ChVC4EVKuLdd99FQkKCupns2+TJk3H48GGVkZKTcX/TDoEdPXoUTz75JNzd3eHr64sRI0ao12I0ZMgQ9ZqmTp2KokWLqtuMGjUq+bnsOgCaNWuW+uHID6JRo0bYs2fPI8c1jW92ylPHjh1T3S4oKAhdunRRK8J6enqiQYMGCAkJMcOrISIiqyXZDZm8zxKnLBYfOzk5YdCgQSqgMKS4jwQ/iYmJGDBgAOrVq4dVq1bh2LFjKqAYOHDgI4+digQ/rl5ISkrC0716w8XFBbt378bs2bPxxhtvaLeJCk0udi7gWxQ//TwfJ06cwJdffokffvgB06dPV9f17t0br7zyCqpVq6aGvOQkl6UVHR2Ntm3bolChQmoYTl7D+vXrMXr06FS327RpE86ePav+//nnn9VrTxsA5gWL9rAtXrwY48ePVz8ACX5mzJih3qzg4GAUKVIk3e2XLl2K+Pj45O0bN26gVq1a6NmzZ/Jl8iY2a9ZMpRElQvXy8sLx48dVgEVERDqWEAN8XMwyz/3WVcDFM0s3HTZsGD7//HNs2bJFffE3Dn8988wzKF26NF599dXk244ZMwZr167F77//joYNGz76gd0LYf3a1Th56izW/rMBxYoXVxd//P4ktO/cDUiM1YqdC5XBO+9PSb6bJCnkORctWoTXX39dZXPy58+vgjUZ8srMggULEBsbi19++UUlI8TMmTNVndOnn34Kf39/dZkESHK5o6MjKleurJIaGzZswHPPPQe7DYCmTZumXuDQoVpxlgRCEtXOnTsXEyZMSHd7Hx+fVNvyw5AUYMoA6O2330aHDh3w2WefJV9Wrly5PH0dREREpiJBQJMmTdSxUAKgM2fOqALo999/X2WBPv74YxXwXLlyRSUF4uLi1LHwP7l6IejMBZQs5o9ihY2t8ZFoXMFXO+/gnFzvIwmKr776SiUVZMjq/v37KqGQHTIaI0kKY/AjmjZtqrJQkugwBkCSSZLgx0iGwmToLK9ZLACSH9r+/fvx5ptvJl/m4OCA1q1bY+fOnVl6jDlz5qBPnz7Jb668qRJASYQqmaSDBw+ibNmy6jlkjJGIiHTM2UPLxFjqubNBRjEkuyNlIpL9kS/yzZs3V5kTGZKSEROp/5Hjn7S8pxwdyZSDA+Dk/rAYOu6uqvdRtT/Cq5gKfuQY3L9/fzWKIsdSKSeRhMMXX3yBvODs7JxqW0pb5HhutzVAERERKpI1RoBGsh0aGvqf95fxThn/HD58ePJl4eHhKlL95JNPVBvhP//8g+7du+Ppp59WqcTMSPQcFRWV6kRERHZG5q+RYShLnLK5UGivXr1UUkCGkWQISYbFJDDYsWMHunbtqmqBJLsSGBiIU6dOZflxq1SvjUtXw3Dt3Akt+AGw63jIw1mjAfz7779qqE1GVKTrrEKFCrh48WKqx5EaIjmGP/K5qlRRhdJSC2Qk+y+vq1KlSrA0ixdB55RkfyT6TTnmaYwY5Zfj5ZdfVnMUyFCaVNXL8FpmpkyZoiJc46lkyZJmeQ1EREQZkRobKSyWEQwpMpZuKSHBiHRtSZAiQ0zPP/88wsLCsvy4rTt0RsXAUhj80iQcPn4K245exttTZqS6jTyHNA5J1keGwGQobNmyZaluI3VB58+fx6FDh1RCQxIJaUkWSepvBw8erBIWUuQsWS0p2k6b/NBVAOTn56fG/NL+4GT7UUVVQqJJ+cFIijDtY0pRlrT1pY1CH9UFJr9gkZGRyadLly7l6DURERGZihzjbt26pYahihXTirffeecd1K1bV10m9UFyvMxOiYeDoxOWLfwF9+Li0bDTIAwf+yo++uijVLeRLmpJIki3liQSJNiSNviUpCBbRlpatmyp2vYzasWXuiQp0L5586bqxu7RowdatWqlCp6tQT5Dyj47M5POL8ngfP3118kZnFKlSqk3PaMiaCNpjxs5cqQqAJM5A1KSwjEZK50/f37yZTIMJlXrkkrMChkCk0yQBEPZLfoiIiLLk+4jyVBIHSi7gPXzs43KxvHbol1g0gIvqTEZY5RASIq6JLtj7AqTuRBksicZoko7/CURb9rgR7z22msqbSiTPElkumbNGqxcuRKbN2822+siIiIi62bRAEgClevXr2PixImq8FlSbRKwGMcGZdhKiqVSkta57du3qwLnjEi2R+p9JGgaO3asKrT63//+p+YGIiIiIrL4EJi14hAYEZFt4xCY/Yo10RCYzXaBEREREeUUAyAiIiLSHQZARERkt1jlYX8MJvqZMgAiIiK7Y1xeISYmxtK7QiZm/JmmXULDprrAiIiI8oJMtFuwYEG1RJJxUj5ZSoJsO/MTExOjfqbys025gGpOMAAiIiK7ZFxVwBgEkX0oWLDgf64YkRUMgIiIyC5Jxqdo0aIoUqQIEhISLL07ZAIy7JXbzI8RAyAiIrJrcsA01UGT7AeLoImIiEh3GAARERGR7jAAIiIiIt1hDdAjJlmSNUWIiIjINhiP21mZLJEBUAbu3Lmj/i9ZsqSld4WIiIhycByXRVEfhavBZyApKQlXr15FgQIFTD5xlkSnElhdunRJlyvN8/Xr+/ULvb8Hen/9Qu/vAV9/VJ69fglpJPgpVqwYHBweXeXDDFAG5E0rUaJEnj6H/ND1+ItvxNev79cv9P4e6P31C72/B3z9Xnny+v8r82PEImgiIiLSHQZAREREpDsMgMzM1dUVkyZNUv/rEV+/vl+/0Pt7oPfXL/T+HvD1u1rF62cRNBEREekOM0BERESkOwyAiIiISHcYABEREZHuMAAiIiIi3WEAZEazZs1CmTJl4ObmhkaNGmHPnj3QiylTpqBBgwZqdu0iRYqgW7duCA4Ohl598sknapbxl156CXpx5coVDBgwAL6+vnB3d0eNGjWwb98+6EViYiLeffddlC1bVr3+cuXK4YMPPsjSmkW2aOvWrejcubOakVd+1//8889U18vrnjhxIooWLarej9atW+P06dPQy3uQkJCAN954Q/0deHp6qtsMGjRIrUKgl9+BlEaOHKluM2PGDJgLAyAzWbx4McaPH69a/w4cOIBatWqhbdu2CA8Phx5s2bIFo0aNwq5du7Bu3Tr1x9+mTRtER0dDb/bu3YvvvvsONWvWhF7cunULTZs2hbOzM1avXo0TJ07giy++QKFChaAXn376Kb799lvMnDkTQUFBavuzzz7D119/DXskf9vyOSdf/DIir/2rr77C7NmzsXv3bhUEyGdibGws9PAexMTEqGOBBMXy/9KlS9WXwi5dukAvvwNGy5YtU8cGCZTMStrgKe81bNjQMGrUqOTtxMREQ7FixQxTpkwx6FF4eLh87TVs2bLFoCd37twxVKhQwbBu3TpD8+bNDePGjTPowRtvvGFo1qyZQc86duxoGDZsWKrLnn76aUP//v0N9k7+1pctW5a8nZSUZAgICDB8/vnnyZfdvn3b4Orqali4cKFBD+9BRvbs2aNud/HiRYNeXv/ly5cNxYsXNxw7dsxQunRpw/Tp0822T8wAmUF8fDz279+vUrwp1xuT7Z07d0KPIiMj1f8+Pj7QE8mCdezYMdXvgh6sWLEC9evXR8+ePdUQaJ06dfDDDz9AT5o0aYINGzbg1KlTavvw4cPYvn072rdvD705f/48QkNDU/0dyPpNUhqg189E4+eiDAMVLFgQell4fODAgXjttddQrVo1sz8/F0M1g4iICDX+7+/vn+py2T558iT0Rn7ppfZFhkSqV68OvVi0aJFKdcsQmN6cO3dODf/IMPBbb72l3oOxY8fCxcUFgwcPhh5MmDBBrYJduXJlODo6qs+Ejz76CP3794feSPAjMvpMNF6nNzL0JzVBffv21c0CqZ9++imcnJzUZ4ElMAAii2RBjh07pr796sWlS5cwbtw4Vf8kRfB6DHolA/Txxx+rbckAye+A1H/oJQD6/fff8dtvv2HBggXq2+6hQ4fUFwGpe9DLe0AZk5rIXr16qcJw+aKgB/v378eXX36pvhRK1ssSOARmBn5+fuobX1hYWKrLZTsgIAB6Mnr0aPz111/YtGkTSpQoAb2QP3YpeK9bt676xiMnKQyXIlA5L9kAeyadPlWrVk11WZUqVRASEgK9kDS/ZIH69OmjOn8k9f/yyy+rDkm9MX7u8TPxYfBz8eJF9QVJL9mfbdu2qc/EUqVKJX8mynvwyiuvqG5pc2AAZAaS5q9Xr54a/0/5jVi2GzduDD2QbzYS/Ei1/8aNG1UrsJ60atUKR48eVd/6jSfJiMjwh5yXANmeyXBn2mkPpBamdOnS0Avp+pHav5Tk5y6fBXojf/8S6KT8TJThQekG08tnYsrgR9r/169fr6aI0IuBAwfiyJEjqT4TJRsqXxTWrl1rln3gEJiZSO2DpLnloNewYUM114G0CA4dOhR6GfaS1P/y5cvVXEDGcX4pfJQ5QOydvOa09U7S9isfeHqog5JMhxQByxCYfODLHFjff/+9OumFzIciNT/yjVeGwA4ePIhp06Zh2LBhsEd3797FmTNnUhU+y0FOGh/kPZDhvw8//BAVKlRQAZG0g8sBUOYI08N7IFnRHj16qCEgyYpLFtj4uSjXyxdne/8d8E0T8Mk0GRIYV6pUyTw7aLZ+MzJ8/fXXhlKlShlcXFxUW/yuXbsMeiG/ahmd5s2bZ9ArPbXBi5UrVxqqV6+uWp0rV65s+P777w16EhUVpX7e8hng5uZmCAwMNLz99tuGuLg4gz3atGlThn/zgwcPTm6Ff/fddw3+/v7qd6JVq1aG4OBgg17eg/Pnz2f6uSj308PvQFrmboPPJ/+YJ9QiIiIisg6sASIiIiLdYQBEREREusMAiIiIiHSHARARERHpDgMgIiIi0h0GQERERKQ7DICIiIhIdxgAERFlgSzY+Oeff1p6N4jIRBgAEZHVGzJkiApA0p7atWtn6V0jIhvFtcCIyCZIsDNv3rxUl7m6ulpsf4jItjEDREQ2QYIdWSgx5alQoULqOskGffvtt2jfvr1aXDcwMBB//PFHqvsfPXoUTz75pLpeFmEcMWKEWqwxpblz56qFSuW5ZLHK0aNHp7o+IiIC3bt3h4eHh1rEc8WKFWZ45USUFxgAEZFdkNXEn3nmGRw+fBj9+/dHnz59EBQUpK6Ljo5G27ZtVcC0d+9eLFmyBOvXr08V4EgANWrUKBUYSbAkwU358uVTPcfkyZPVavZHjhxBhw4d1PPcvHnT7K+ViEzAbMuuEhHlkKwe7ejoaPD09Ex1+uijj9T18lE2cuTIVPdp1KiR4YUXXlDnZeX5QoUKGe7evZt8/apVqwwODg6G0NBQtV2sWDG1Ontm5Dneeeed5G15LLls9erVJn+9RJT3WANERDahZcuWKkuTko+PT/L5xo0bp7pOtg8dOqTOSyaoVq1a8PT0TL6+adOmSEpKQnBwsBpCu3r1Klq1avXIfahZs2byeXksLy8vhIeH5/q1EZH5MQAiIpsgAUfaISlTkbqgrHB2dk61LYGTBFFEZHtYA0REdmHXrl3ptqtUqaLOy/9SGyS1QEY7duyAg4MDKlWqhAIFCqBMmTLYsGGD2febiCyDGSAisglxcXEIDQ1NdZmTkxP8/PzUeSlsrl+/Ppo1a4bffvsNe/bswZw5c9R1Uqw8adIkDB48GO+99x6uX7+OMWPGYODAgfD391e3kctHjhyJIkWKqG6yO3fuqCBJbkdE9ocBEBHZhDVr1qjW9JQke3Py5MnkDq1FixbhxRdfVLdbuHAhqlatqq6TtvW1a9di3LhxaNCggdqWjrFp06YlP5YER7GxsZg+fTpeffVVFVj16NHDzK+SiMwln1RCm+3ZiIjygNTiLFu2DN26dbP0rhCRjWANEBEREekOAyAiIiLSHdYAEZHN40g+EWUXM0BERESkOwyAiIiISHcYABEREZHuMAAiIiIi3WEARERERLrDAIiIiIh0hwEQERER6Q4DICIiItIdBkBERESkO/8HXMRqCl+Ch6gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history, title=\"Model Accuracy\"):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history, \"Double-layer LSTM Accuracy\")\n",
    "plot_history(history_gru, \"GRU Model Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6eb65c",
   "metadata": {},
   "source": [
    "# 資料強化流程建議"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d5b0a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: FIRE_START_DAY\n",
      "0.0    8622\n",
      "1.0    4739\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: FIRE_START_DAY\n",
      "0.0    8622\n",
      "1.0    8622\n",
      "Name: count, dtype: int64\n",
      "   PRECIPITATION  MAX_TEMP  MIN_TEMP  AVG_WIND_SPEED      YEAR  TEMP_RANGE  \\\n",
      "0      -0.175419 -1.362289 -1.821029       -0.309930 -1.701295    0.573966   \n",
      "1      -0.175419 -0.747352 -1.821029       -0.962694 -1.701295    1.296399   \n",
      "2      -0.175419 -0.132414 -1.367257       -1.743681 -1.701295    1.477008   \n",
      "3      -0.175419  0.482523 -0.913485       -0.700423 -1.701295    1.657616   \n",
      "4      -0.175419  1.251194 -0.005941        0.733328 -1.701295    1.477008   \n",
      "\n",
      "   WIND_TEMP_RATIO     MONTH  LAGGED_PRECIPITATION  LAGGED_AVG_WIND_SPEED  \\\n",
      "0         0.191170 -1.706283              0.904297              -1.163044   \n",
      "1        -0.686593 -1.706283             -0.364397              -1.285376   \n",
      "2        -1.581287 -1.706283             -0.364397              -1.431738   \n",
      "3        -0.801322 -1.706283             -0.364397              -1.382587   \n",
      "4         0.167635 -1.706283             -0.364397              -0.111204   \n",
      "\n",
      "   ...  PRECIPITATION_diff_14  FIRE_START_DAY_lag_21  TEMP_RANGE_diff_21  \\\n",
      "0  ...               0.000417              -0.742282           -1.566080   \n",
      "1  ...               0.000417              -0.742282           -0.569626   \n",
      "2  ...               0.000417              -0.742282           -0.142575   \n",
      "3  ...               0.000417              -0.742282           -1.139028   \n",
      "4  ...               0.000417              -0.742282           -0.427276   \n",
      "\n",
      "   AVG_WIND_SPEED_diff_21  PRECIPITATION_diff_21     month  sin_month  \\\n",
      "0                0.989667               0.000413 -1.706283    0.78528   \n",
      "1                0.000602               0.000413 -1.706283    0.78528   \n",
      "2               -0.550518               0.000413 -1.706283    0.78528   \n",
      "3                0.659979               0.000413 -1.706283    0.78528   \n",
      "4                1.653965               0.000413 -1.706283    0.78528   \n",
      "\n",
      "   cos_month  FIRE_START_DAY       DATE  \n",
      "0   1.296286             0.0 1984-01-22  \n",
      "1   1.296286             0.0 1984-01-23  \n",
      "2   1.296286             0.0 1984-01-24  \n",
      "3   1.296286             0.0 1984-01-25  \n",
      "4   1.296286             1.0 1984-01-27  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 讀取資料\n",
    "#df = pd.read_csv(\"data/CA_Weather_Fire_Dataset_1984-2025.csv\")\n",
    "\n",
    "\n",
    "# 讀取資料，假設df已載入且有DATE欄位(datetime型態)\n",
    "df = df.sort_values('DATE')\n",
    "\n",
    "# 1. 缺失值補齊 (用中位數)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "num_cols = df.select_dtypes(include=np.number).columns\n",
    "df[num_cols] = imputer.fit_transform(df[num_cols])\n",
    "\n",
    "# 2. 異常值檢測 - 以Z-score法為例\n",
    "from scipy import stats\n",
    "z_scores = np.abs(stats.zscore(df[num_cols]))\n",
    "df = df[(z_scores < 3).all(axis=1)]  # 去除Z-score超過3的異常列\n",
    "\n",
    "# 3. 類別不平衡 (假設目標欄為'FIRE_START_DAY')\n",
    "X = df.drop(columns=['FIRE_START_DAY', 'DATE'])\n",
    "y = df['FIRE_START_DAY']\n",
    "\n",
    "print('Before SMOTE:', y.value_counts())\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "print('After SMOTE:', pd.Series(y_res).value_counts())\n",
    "\n",
    "# 4. 特徵工程 - 滯後特徵 & 差分\n",
    "for lag in [7, 14, 21]:\n",
    "    df[f'FIRE_START_DAY_lag_{lag}'] = df['FIRE_START_DAY'].shift(lag)\n",
    "    for col in ['TEMP_RANGE', 'AVG_WIND_SPEED', 'PRECIPITATION']:\n",
    "        df[f'{col}_diff_{lag}'] = df[col].diff(lag)\n",
    "\n",
    "# 5. 週期性時間特徵\n",
    "df['day_of_year'] = df['DATE'].dt.dayofyear\n",
    "df['sin_day'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['cos_day'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['month'] = df['DATE'].dt.month\n",
    "df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "# 6. 標準化 (先去除含NaN的滯後與差分列)\n",
    "df = df.dropna()\n",
    "features = df.drop(columns=['FIRE_START_DAY', 'DATE'])\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 將處理後資料轉回 DataFrame\n",
    "df_scaled = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "df_scaled['FIRE_START_DAY'] = df['FIRE_START_DAY'].values\n",
    "df_scaled['DATE'] = df['DATE'].values\n",
    "\n",
    "print(df_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598fd89b",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "684b7093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.5432 - val_accuracy: 0.7813 - val_loss: 0.4562\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7875 - loss: 0.4609 - val_accuracy: 0.7831 - val_loss: 0.4549\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7948 - loss: 0.4493 - val_accuracy: 0.7794 - val_loss: 0.4544\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7835 - loss: 0.4573 - val_accuracy: 0.7803 - val_loss: 0.4545\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7913 - loss: 0.4479 - val_accuracy: 0.7813 - val_loss: 0.4526\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7917 - loss: 0.4513 - val_accuracy: 0.7822 - val_loss: 0.4561\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7950 - loss: 0.4461 - val_accuracy: 0.7803 - val_loss: 0.4539\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8032 - loss: 0.4378 - val_accuracy: 0.7817 - val_loss: 0.4541\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7942 - loss: 0.4403 - val_accuracy: 0.7836 - val_loss: 0.4540\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7925 - loss: 0.4416 - val_accuracy: 0.7785 - val_loss: 0.4527\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8034 - loss: 0.4365 - val_accuracy: 0.7794 - val_loss: 0.4537\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8079 - loss: 0.4269 - val_accuracy: 0.7836 - val_loss: 0.4572\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7965 - loss: 0.4309 - val_accuracy: 0.7808 - val_loss: 0.4533\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.4265 - val_accuracy: 0.7808 - val_loss: 0.4543\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8023 - loss: 0.4312 - val_accuracy: 0.7850 - val_loss: 0.4553\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7691 - loss: 0.4811\n",
      "DNN Test Accuracy: 0.7646\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 假設 df_scaled 已完成前處理與標準化，並包含 'FIRE_START_DAY' 目標欄\n",
    "\n",
    "X = df_scaled.drop(columns=['FIRE_START_DAY', 'DATE']).values\n",
    "y = df_scaled['FIRE_START_DAY'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=100,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "loss, DNN_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'DNN Test Accuracy: {DNN_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236cd292",
   "metadata": {},
   "source": [
    "# DNN + 時間序列擴充：把時間窗拉長到30天以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7ffddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (13310, 30, 50)\n",
      "Output shape: (13310,)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6983 - loss: 1.3208 - val_accuracy: 0.7803 - val_loss: 1.0269\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7463 - loss: 1.0501 - val_accuracy: 0.7869 - val_loss: 0.9354\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.9426 - val_accuracy: 0.7887 - val_loss: 0.8753\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7687 - loss: 0.8690 - val_accuracy: 0.7897 - val_loss: 0.7993\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.7804 - val_accuracy: 0.7840 - val_loss: 0.7433\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.7297 - val_accuracy: 0.7887 - val_loss: 0.6843\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.6746 - val_accuracy: 0.7897 - val_loss: 0.6529\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7886 - loss: 0.6358 - val_accuracy: 0.7930 - val_loss: 0.6245\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.6001 - val_accuracy: 0.7906 - val_loss: 0.5900\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.5789 - val_accuracy: 0.7869 - val_loss: 0.5709\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 0.5580 - val_accuracy: 0.7878 - val_loss: 0.5586\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7870 - loss: 0.5463 - val_accuracy: 0.7859 - val_loss: 0.5468\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7941 - loss: 0.5434 - val_accuracy: 0.7892 - val_loss: 0.5425\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7953 - loss: 0.5268 - val_accuracy: 0.7948 - val_loss: 0.5339\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7867 - loss: 0.5217 - val_accuracy: 0.7878 - val_loss: 0.5283\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.5172 - val_accuracy: 0.7878 - val_loss: 0.5320\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.5225 - val_accuracy: 0.7887 - val_loss: 0.5293\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.5137 - val_accuracy: 0.7831 - val_loss: 0.5255\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.5044 - val_accuracy: 0.7925 - val_loss: 0.5198\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5050 - val_accuracy: 0.7901 - val_loss: 0.5167\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8014 - loss: 0.5013 - val_accuracy: 0.7911 - val_loss: 0.5150\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.5001 - val_accuracy: 0.7878 - val_loss: 0.5230\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.4958 - val_accuracy: 0.7930 - val_loss: 0.5157\n",
      "Epoch 24/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7916 - loss: 0.4962 - val_accuracy: 0.7911 - val_loss: 0.5340\n",
      "Epoch 25/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.4923 - val_accuracy: 0.7892 - val_loss: 0.5169\n",
      "Epoch 26/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4932 - val_accuracy: 0.7934 - val_loss: 0.5102\n",
      "Epoch 27/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 0.5022 - val_accuracy: 0.7920 - val_loss: 0.5217\n",
      "Epoch 28/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.4823 - val_accuracy: 0.7911 - val_loss: 0.5087\n",
      "Epoch 29/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.4820 - val_accuracy: 0.7864 - val_loss: 0.5208\n",
      "Epoch 30/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7922 - loss: 0.4986 - val_accuracy: 0.7892 - val_loss: 0.5159\n",
      "Epoch 31/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.4914 - val_accuracy: 0.7864 - val_loss: 0.5140\n",
      "Epoch 32/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7913 - loss: 0.4960 - val_accuracy: 0.7854 - val_loss: 0.5171\n",
      "Epoch 33/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.4968 - val_accuracy: 0.7887 - val_loss: 0.5139\n",
      "Epoch 34/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7965 - loss: 0.4951 - val_accuracy: 0.7765 - val_loss: 0.5220\n",
      "Epoch 35/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8025 - loss: 0.4950 - val_accuracy: 0.7869 - val_loss: 0.5281\n",
      "Epoch 36/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.4991 - val_accuracy: 0.7911 - val_loss: 0.5241\n",
      "Epoch 37/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.5028 - val_accuracy: 0.7817 - val_loss: 0.5320\n",
      "Epoch 38/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4827 - val_accuracy: 0.7892 - val_loss: 0.5196\n",
      "Epoch 39/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.4949 - val_accuracy: 0.7887 - val_loss: 0.5153\n",
      "Epoch 40/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.4881 - val_accuracy: 0.7826 - val_loss: 0.5137\n",
      "Epoch 41/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.4906 - val_accuracy: 0.7808 - val_loss: 0.5179\n",
      "Epoch 42/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 0.4949 - val_accuracy: 0.7948 - val_loss: 0.5055\n",
      "Epoch 43/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.4847 - val_accuracy: 0.7854 - val_loss: 0.5163\n",
      "Epoch 44/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7941 - loss: 0.4882 - val_accuracy: 0.7859 - val_loss: 0.5162\n",
      "Epoch 45/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.4991 - val_accuracy: 0.7873 - val_loss: 0.5326\n",
      "Epoch 46/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4839 - val_accuracy: 0.7878 - val_loss: 0.5194\n",
      "Epoch 47/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.4955 - val_accuracy: 0.7930 - val_loss: 0.5129\n",
      "Epoch 48/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4898 - val_accuracy: 0.7850 - val_loss: 0.5195\n",
      "Epoch 49/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.4891 - val_accuracy: 0.7845 - val_loss: 0.5189\n",
      "Epoch 50/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4966 - val_accuracy: 0.7831 - val_loss: 0.5349\n",
      "Epoch 51/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.5084 - val_accuracy: 0.7859 - val_loss: 0.5340\n",
      "Epoch 52/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4892 - val_accuracy: 0.7826 - val_loss: 0.5230\n",
      "Epoch 53/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8097 - loss: 0.4873 - val_accuracy: 0.7878 - val_loss: 0.5214\n",
      "Epoch 54/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4961 - val_accuracy: 0.7878 - val_loss: 0.5168\n",
      "Epoch 55/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.4889 - val_accuracy: 0.7859 - val_loss: 0.5285\n",
      "Epoch 56/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4913 - val_accuracy: 0.7925 - val_loss: 0.5211\n",
      "Epoch 57/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.4809 - val_accuracy: 0.7836 - val_loss: 0.5252\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7943 - loss: 0.5127  \n",
      "DNN (30-day window) Test Accuracy: 0.7866\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 假設df_scaled是前面標準化後的DataFrame，包含日期與標的FIRE_START_DAY\n",
    "\n",
    "# 只取特徵欄（不含日期與目標欄）\n",
    "feature_cols = [c for c in df_scaled.columns if c not in ['DATE', 'FIRE_START_DAY']]\n",
    "features = df_scaled[feature_cols].values\n",
    "labels = df_scaled['FIRE_START_DAY'].values\n",
    "\n",
    "window_size = 30\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# 用前30天資料預測當天（第30天）目標\n",
    "for i in range(window_size, len(features)):\n",
    "    X.append(features[i-window_size:i])  # 30天的特徵矩陣 (30, feature_num)\n",
    "    y.append(labels[i])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print('Input shape:', X.shape)  # (樣本數, 30, 特徵數)\n",
    "print('Output shape:', y.shape)\n",
    "\n",
    "# 分訓練/測試\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 簡單DNN模型 (Flatten + Dense)\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(window_size, X.shape[2])),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=100,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "loss, DNN30_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'DNN (30-day window) Test Accuracy: {DNN30_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3fc970",
   "metadata": {},
   "source": [
    "#  LSTM + Attention 模型架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b309333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m29,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention (\u001b[38;5;33mAttention\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m94\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,647</span> (123.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,647\u001b[0m (123.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,647</span> (123.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,647\u001b[0m (123.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7104 - loss: 0.5635 - val_accuracy: 0.7864 - val_loss: 0.4526\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7740 - loss: 0.4932 - val_accuracy: 0.7887 - val_loss: 0.4508\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7702 - loss: 0.4833 - val_accuracy: 0.7897 - val_loss: 0.4497\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7793 - loss: 0.4735 - val_accuracy: 0.7925 - val_loss: 0.4474\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7751 - loss: 0.4774 - val_accuracy: 0.7925 - val_loss: 0.4487\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7858 - loss: 0.4677 - val_accuracy: 0.7906 - val_loss: 0.4469\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7810 - loss: 0.4624 - val_accuracy: 0.7958 - val_loss: 0.4450\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7900 - loss: 0.4570 - val_accuracy: 0.7939 - val_loss: 0.4500\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7838 - loss: 0.4574 - val_accuracy: 0.7920 - val_loss: 0.4457\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7888 - loss: 0.4532 - val_accuracy: 0.7897 - val_loss: 0.4453\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7982 - loss: 0.4455 - val_accuracy: 0.7915 - val_loss: 0.4482\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7860 - loss: 0.4471 - val_accuracy: 0.7915 - val_loss: 0.4495\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7916 - loss: 0.4404 - val_accuracy: 0.7906 - val_loss: 0.4471\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7863 - loss: 0.4448 - val_accuracy: 0.7934 - val_loss: 0.4534\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7931 - loss: 0.4341 - val_accuracy: 0.7953 - val_loss: 0.4535\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7965 - loss: 0.4420 - val_accuracy: 0.7859 - val_loss: 0.4590\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7911 - loss: 0.4282 - val_accuracy: 0.7831 - val_loss: 0.4580\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7967 - loss: 0.4313 - val_accuracy: 0.7892 - val_loss: 0.4589\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7931 - loss: 0.4314 - val_accuracy: 0.7845 - val_loss: 0.4553\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7950 - loss: 0.4240 - val_accuracy: 0.7822 - val_loss: 0.4715\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8027 - loss: 0.4165 - val_accuracy: 0.7831 - val_loss: 0.4749\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7962 - loss: 0.4203 - val_accuracy: 0.7887 - val_loss: 0.4681\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.4538\n",
      "LSTM+Attention Test Accuracy: 0.7799\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Attention Layer 自訂義\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\")\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)  # (batch_size, time_steps, 1)\n",
    "        e = K.squeeze(e, axis=-1)  # (batch_size, time_steps)\n",
    "        alpha = K.softmax(e)  # 注意力權重\n",
    "        alpha = K.expand_dims(alpha, axis=-1)  # (batch_size, time_steps, 1)\n",
    "        context = x * alpha  # 權重乘以輸入序列\n",
    "        context = K.sum(context, axis=1)  # 對時間軸加權求和 (batch_size, features)\n",
    "        return context\n",
    "\n",
    "# 建立模型\n",
    "input_shape = (window_size, X.shape[2])\n",
    "inputs = Input(shape=input_shape)\n",
    "x = LSTM(64, return_sequences=True)(inputs)\n",
    "x = Attention()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 訓練\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=100,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "# 測試\n",
    "loss, LSTM_Attention_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'LSTM+Attention Test Accuracy: {LSTM_Attention_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181adfb8",
   "metadata": {},
   "source": [
    "# 視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "82e54828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 模型名稱\n",
    "models = [\n",
    "    \"Essenble (Stacking)\",\n",
    "    \"LSTM\",\n",
    "    \"Double-layer LSTM (14-day)\",\n",
    "    \"GRU\",\n",
    "    \"DNN\",\n",
    "    \"DNN (30-day)\",\n",
    "    \"LSTM + Attention\"\n",
    "]\n",
    "\n",
    "# 對應準確率\n",
    "accuracies = [\n",
    "    stack_acc,\n",
    "    LSTM_accuracy,\n",
    "    DLLSTM_accuracy,\n",
    "    acc_gru,\n",
    "    DNN_accuracy,\n",
    "    DNN30_accuracy,\n",
    "    LSTM_Attention_accuracy\n",
    "]\n",
    "models = models[::-1]\n",
    "accuracies = accuracies[::-1]\n",
    "\n",
    "# 繪製橫向長條圖\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(models, accuracies, color='skyblue')\n",
    "plt.xlabel('Test Accuracy')\n",
    "plt.title('comparison of Different Models')\n",
    "plt.xlim(0.5, 0.9)\n",
    "\n",
    "# 在長條圖上標記數值\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(acc + 0.001, bar.get_y() + bar.get_height()/2, f\"{acc*100:.1f}%\", va='center')\n",
    "\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f65903b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
