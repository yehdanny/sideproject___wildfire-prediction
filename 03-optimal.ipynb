{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690abd71",
   "metadata": {},
   "source": [
    "# California Weather-Fire Dataset 分析報告 🔥🌤️\n",
    "\n",
    "## 1. 資料簡介 📚\n",
    "本資料集涵蓋1984年至2025年間的加州天氣與火災紀錄，目標為預測 **FIRE_START_DAY**（是否起火）之二元分類問題。\n",
    "\n",
    "## 2. 資料前處理 🧹\n",
    "- **日期轉換與欄位清理**：將日期資料轉換為適合分析的格式，刪除不必要欄位。\n",
    "- **缺失值處理**：採用刪除缺失值的方法確保資料完整性。\n",
    "- **數值特徵標準化**：對數值欄位進行標準化，提升模型收斂速度。\n",
    "- **類別欄位One-Hot編碼**：針對季節等類別欄位進行One-Hot編碼。\n",
    "\n",
    "## 3. 特徵工程 ⚙️\n",
    "- **時間特徵**：新增月份、星期幾、週末標記等時間相關特徵。\n",
    "- **滯後特徵**：計算過去3天的火災狀態，捕捉時間依賴關係。\n",
    "- **滾動統計**：針對風速、降水量等氣象變數計算3天的移動平均與標準差。\n",
    "\n",
    "## 4. 資料平衡 ⚖️\n",
    "使用 SMOTE 技術對少數類（火災發生）進行過採樣，平衡正負類樣本分布，避免模型偏向多數類。\n",
    "\n",
    "## 5. 模型建構 🏗️\n",
    "- 訓練三種主要模型：**XGBoost、LightGBM、RandomForest**。\n",
    "- 使用 **Optuna** 進行自動化超參數調優，找到XGBoost最佳參數組合。\n",
    "- 透過集成模型融合三者優勢，採用 xgb、lgbm、rf 的 VotingClassifier，達到最佳準確率約 **85%**。🎯\n",
    "\n",
    "## 6. 模型評估 📊\n",
    "- **集成模型（XGBoost + LightGBM + RandomForest）準確率：約 85%**，為本研究中表現最佳。🏅\n",
    "- 深度學習模型表現如下：\n",
    "  - LSTM Test Accuracy: 0.8006 🤖\n",
    "  - Double-layer LSTM (14-day window) Test Accuracy: 0.7885\n",
    "  - GRU Model Test Accuracy: 0.8025\n",
    "  - DNN Test Accuracy: 0.7719\n",
    "  - DNN (30-day window) Test Accuracy: 0.7768\n",
    "  - LSTM+Attention Test Accuracy: 0.7787\n",
    "- 提供詳細的精確率 (Precision)、召回率 (Recall)、F1分數 (F1-score) 報告，評估模型在不同類別的表現。\n",
    "- 透過特徵重要性視覺化，解析模型決策依據。🔍\n",
    "\n",
    "## 7. 結論與未來展望 🚀\n",
    "- 目前集成模型（XGBoost、LightGBM、RandomForest）已達最佳預測表現，準確率達85%，優於各類深度學習模型。💪\n",
    "- 未來仍建議持續嘗試深度序列模型（如LSTM、Transformer），並優化時間序列特徵工程，期望進一步提升模型效能與穩定性。✨\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27bcae7d",
   "metadata": {},
   "source": [
    "# XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "504ac6c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 200, 'subsample': 0.8}\n",
      "Accuracy: 0.8333333333333334\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.82      0.83      2001\n",
      "           1       0.83      0.84      0.83      2001\n",
      "\n",
      "    accuracy                           0.83      4002\n",
      "   macro avg       0.83      0.83      0.83      4002\n",
      "weighted avg       0.83      0.83      0.83      4002\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:24] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 讀取資料\n",
    "df = pd.read_csv(\"data/CA_Weather_Fire_Dataset_1984-2025.csv\")\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df = df.dropna()\n",
    "df['FIRE_START_DAY'] = df['FIRE_START_DAY'].astype(int)\n",
    "\n",
    "# One-hot 編碼季節\n",
    "df = pd.get_dummies(df, columns=['SEASON'], drop_first=True)\n",
    "\n",
    "# 時間特徵\n",
    "df['WEEKDAY'] = df['DATE'].dt.weekday\n",
    "df['IS_WEEKEND'] = df['WEEKDAY'].isin([5, 6]).astype(int)\n",
    "\n",
    "# 數值標準化\n",
    "features_to_scale = [\n",
    "    'PRECIPITATION', 'MAX_TEMP', 'MIN_TEMP', 'AVG_WIND_SPEED',\n",
    "    'TEMP_RANGE', 'WIND_TEMP_RATIO', 'LAGGED_PRECIPITATION',\n",
    "    'LAGGED_AVG_WIND_SPEED'\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "# 特徵與標籤\n",
    "X = df.drop(columns=['FIRE_START_DAY', 'DATE'])\n",
    "y = df['FIRE_START_DAY']\n",
    "\n",
    "# SMOTE 類別平衡\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# 分割資料\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# XGBoost 與參數搜尋\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 6, 8],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "grid = GridSearchCV(xgb, param_grid, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# 模型評估\n",
    "best_model = grid.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "print(\"Best Parameters:\", grid.best_params_)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfd0f046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8004, number of negative: 8004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001273 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2263\n",
      "[LightGBM] [Info] Number of data points in the train set: 16008, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Accuracy: 0.8393303348325837\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      2001\n",
      "           1       0.83      0.85      0.84      2001\n",
      "\n",
      "    accuracy                           0.84      4002\n",
      "   macro avg       0.84      0.84      0.84      4002\n",
      "weighted avg       0.84      0.84      0.84      4002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 讀取資料\n",
    "df = pd.read_csv(\"data/CA_Weather_Fire_Dataset_1984-2025.csv\")\n",
    "df['DATE'] = pd.to_datetime(df['DATE'])\n",
    "df.dropna(inplace=True)\n",
    "df['FIRE_START_DAY'] = df['FIRE_START_DAY'].astype(int)\n",
    "\n",
    "# 加入時間與滯後特徵\n",
    "df['MONTH'] = df['DATE'].dt.month\n",
    "df['WEEKDAY'] = df['DATE'].dt.weekday\n",
    "df['IS_WEEKEND'] = df['WEEKDAY'].isin([5, 6]).astype(int)\n",
    "df['FIRE_LAG_1'] = df['FIRE_START_DAY'].shift(1).fillna(0).astype(int)\n",
    "df['FIRE_LAG_2'] = df['FIRE_START_DAY'].shift(2).fillna(0).astype(int)\n",
    "df['FIRE_LAG_3'] = df['FIRE_START_DAY'].shift(3).fillna(0).astype(int)\n",
    "\n",
    "# One-hot 編碼季節\n",
    "df = pd.get_dummies(df, columns=['SEASON'], drop_first=True)\n",
    "\n",
    "# 特徵標準化\n",
    "features_to_scale = [\n",
    "    'PRECIPITATION', 'MAX_TEMP', 'MIN_TEMP', 'AVG_WIND_SPEED',\n",
    "    'TEMP_RANGE', 'WIND_TEMP_RATIO', 'LAGGED_PRECIPITATION',\n",
    "    'LAGGED_AVG_WIND_SPEED'\n",
    "]\n",
    "scaler = StandardScaler()\n",
    "df[features_to_scale] = scaler.fit_transform(df[features_to_scale])\n",
    "\n",
    "# 切分資料\n",
    "X = df.drop(columns=['FIRE_START_DAY', 'DATE'])\n",
    "y = df['FIRE_START_DAY']\n",
    "\n",
    "# SMOTE 平衡資料\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled\n",
    ")\n",
    "\n",
    "# 模型定義\n",
    "xgb = XGBClassifier(learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8, random_state=42)\n",
    "lgbm = LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42)\n",
    "\n",
    "# 集成模型（硬投票）\n",
    "ensemble_model = VotingClassifier(\n",
    "    estimators=[('xgb', xgb), ('lgbm', lgbm), ('rf', rf)],\n",
    "    voting='hard'\n",
    ")\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# 評估\n",
    "y_pred = ensemble_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d01493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 用XGBoost計算特徵重要性\n",
    "xgb.fit(X_train, y_train)\n",
    "importances = xgb.feature_importances_\n",
    "features = X_train.columns\n",
    "\n",
    "# 繪圖展示\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Feature Importances (XGBoost)\")\n",
    "plt.bar(range(len(importances)), importances[indices], align='center')\n",
    "plt.xticks(range(len(importances)), [features[i] for i in indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 篩選重要性大於某門檻的特徵（例如 0.01）\n",
    "selected_features = [features[i] for i in range(len(importances)) if importances[i] > 0.01]\n",
    "\n",
    "X_train_sel = X_train[selected_features]\n",
    "X_test_sel = X_test[selected_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c2cf16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\3990922073.py:4: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['ROLLING_MEAN_WIND'] = df['AVG_WIND_SPEED'].rolling(window).mean().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\3990922073.py:5: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['ROLLING_STD_WIND'] = df['AVG_WIND_SPEED'].rolling(window).std().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\3990922073.py:7: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['ROLLING_MEAN_PRECIP'] = df['PRECIPITATION'].rolling(window).mean().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\3990922073.py:8: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df['ROLLING_STD_PRECIP'] = df['PRECIPITATION'].rolling(window).std().fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "# 在原df中加入rolling features，這裡以3天為例\n",
    "window = 3\n",
    "\n",
    "df['ROLLING_MEAN_WIND'] = df['AVG_WIND_SPEED'].rolling(window).mean().fillna(method='bfill')\n",
    "df['ROLLING_STD_WIND'] = df['AVG_WIND_SPEED'].rolling(window).std().fillna(method='bfill')\n",
    "\n",
    "df['ROLLING_MEAN_PRECIP'] = df['PRECIPITATION'].rolling(window).mean().fillna(method='bfill')\n",
    "df['ROLLING_STD_PRECIP'] = df['PRECIPITATION'].rolling(window).std().fillna(method='bfill')\n",
    "\n",
    "# 同時標準化新增欄位\n",
    "df[['ROLLING_MEAN_WIND','ROLLING_STD_WIND','ROLLING_MEAN_PRECIP','ROLLING_STD_PRECIP']] = scaler.fit_transform(\n",
    "    df[['ROLLING_MEAN_WIND','ROLLING_STD_WIND','ROLLING_MEAN_PRECIP','ROLLING_STD_PRECIP']]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6384d26a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8004, number of negative: 8004\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001192 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2263\n",
      "[LightGBM] [Info] Number of data points in the train set: 16008, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001091 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2242\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000540 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2234\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001073 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2242\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6404\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2248\n",
      "[LightGBM] [Info] Number of data points in the train set: 12807, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499961 -> initscore=-0.000156\n",
      "[LightGBM] [Info] Start training from score -0.000156\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6404, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001058 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2235\n",
      "[LightGBM] [Info] Number of data points in the train set: 12807, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000156\n",
      "[LightGBM] [Info] Start training from score 0.000156\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Stacking Model Accuracy: 0.842328835582209\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84      2001\n",
      "           1       0.84      0.85      0.84      2001\n",
      "\n",
      "    accuracy                           0.84      4002\n",
      "   macro avg       0.84      0.84      0.84      4002\n",
      "weighted avg       0.84      0.84      0.84      4002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "estimators = [\n",
    "    ('xgb', XGBClassifier(learning_rate=0.1, max_depth=6, n_estimators=200, subsample=0.8, random_state=42)),\n",
    "    ('lgbm', LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42)),\n",
    "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42))\n",
    "]\n",
    "\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=LogisticRegression(),\n",
    "    cv=5\n",
    ")\n",
    "\n",
    "stacking_clf.fit(X_train_sel, y_train)\n",
    "y_pred_stack = stacking_clf.predict(X_test_sel)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Stacking Model Accuracy:\", accuracy_score(y_test, y_pred_stack))\n",
    "print(classification_report(y_test, y_pred_stack))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfd54e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[I 2025-05-16 20:05:37,838] A new study created in memory with name: no-name-7c790ad0-d3b4-4647-99c3-2a6fd541afdd\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:37] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:38,664] Trial 0 finished with value: 0.8328335832083957 and parameters: {'n_estimators': 234, 'max_depth': 8, 'learning_rate': 0.11848102234645796, 'subsample': 0.7958342432693127, 'colsample_bytree': 0.8652738235067132}. Best is trial 0 with value: 0.8328335832083957.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:38] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:39,099] Trial 1 finished with value: 0.8321464267866068 and parameters: {'n_estimators': 279, 'max_depth': 4, 'learning_rate': 0.15483141016680668, 'subsample': 0.7253430503232876, 'colsample_bytree': 0.6615156167944228}. Best is trial 0 with value: 0.8328335832083957.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:39,823] Trial 2 finished with value: 0.8370814592703648 and parameters: {'n_estimators': 147, 'max_depth': 9, 'learning_rate': 0.10407331492557823, 'subsample': 0.9672953533234545, 'colsample_bytree': 0.7717554238700458}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:39] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:40,049] Trial 3 finished with value: 0.7896051974012993 and parameters: {'n_estimators': 100, 'max_depth': 5, 'learning_rate': 0.012345461271379312, 'subsample': 0.9447755969809104, 'colsample_bytree': 0.6104599997829497}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:41,303] Trial 4 finished with value: 0.8134057971014492 and parameters: {'n_estimators': 240, 'max_depth': 9, 'learning_rate': 0.01073218126427632, 'subsample': 0.6814055044972329, 'colsample_bytree': 0.9727846270681422}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:41,726] Trial 5 finished with value: 0.804160419790105 and parameters: {'n_estimators': 227, 'max_depth': 5, 'learning_rate': 0.020651731779178, 'subsample': 0.6294361744676855, 'colsample_bytree': 0.665526120855856}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:41] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:42,916] Trial 6 finished with value: 0.8225262368815592 and parameters: {'n_estimators': 212, 'max_depth': 10, 'learning_rate': 0.016728458767636144, 'subsample': 0.8864845721135489, 'colsample_bytree': 0.657521835353131}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:42] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:43,289] Trial 7 finished with value: 0.8302723638180908 and parameters: {'n_estimators': 171, 'max_depth': 6, 'learning_rate': 0.09586791472807984, 'subsample': 0.6852352442253373, 'colsample_bytree': 0.6142503425819571}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:43,547] Trial 8 finished with value: 0.8184657671164418 and parameters: {'n_estimators': 120, 'max_depth': 5, 'learning_rate': 0.07691990131123523, 'subsample': 0.8162408117614692, 'colsample_bytree': 0.826598598829322}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:43,894] Trial 9 finished with value: 0.8125937031484258 and parameters: {'n_estimators': 113, 'max_depth': 7, 'learning_rate': 0.03997195761145266, 'subsample': 0.6667425779041923, 'colsample_bytree': 0.7613688500894984}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:43] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:44,657] Trial 10 finished with value: 0.8322713643178411 and parameters: {'n_estimators': 161, 'max_depth': 10, 'learning_rate': 0.04987264100078858, 'subsample': 0.9934521616505998, 'colsample_bytree': 0.7502372720161554}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:44] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:45,272] Trial 11 finished with value: 0.8293978010994504 and parameters: {'n_estimators': 181, 'max_depth': 8, 'learning_rate': 0.17642122296236187, 'subsample': 0.7994321892003774, 'colsample_bytree': 0.8761967436288007}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:45] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:46,114] Trial 12 finished with value: 0.8310219890054973 and parameters: {'n_estimators': 260, 'max_depth': 8, 'learning_rate': 0.11596588577508424, 'subsample': 0.8186954210137987, 'colsample_bytree': 0.8982798540344831}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:46,620] Trial 13 finished with value: 0.8282733633183409 and parameters: {'n_estimators': 147, 'max_depth': 8, 'learning_rate': 0.05893609478318747, 'subsample': 0.8990794950954227, 'colsample_bytree': 0.8210117558528304}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:46] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:47,508] Trial 14 finished with value: 0.8310219890054973 and parameters: {'n_estimators': 205, 'max_depth': 9, 'learning_rate': 0.12026494887325587, 'subsample': 0.7516582296215051, 'colsample_bytree': 0.9386745345848412}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:47] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:48,270] Trial 15 finished with value: 0.8284607696151923 and parameters: {'n_estimators': 295, 'max_depth': 7, 'learning_rate': 0.035579367146278865, 'subsample': 0.8813779531126668, 'colsample_bytree': 0.7360237135659158}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:48,820] Trial 16 finished with value: 0.8323338330834583 and parameters: {'n_estimators': 140, 'max_depth': 9, 'learning_rate': 0.19867376214078744, 'subsample': 0.9994307105046569, 'colsample_bytree': 0.8425551022631425}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:49,694] Trial 17 finished with value: 0.8350199900049975 and parameters: {'n_estimators': 189, 'max_depth': 10, 'learning_rate': 0.07030816803189602, 'subsample': 0.8515193801410564, 'colsample_bytree': 0.780652188612416}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:49] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:50,765] Trial 18 finished with value: 0.8297101449275363 and parameters: {'n_estimators': 188, 'max_depth': 10, 'learning_rate': 0.029274392891145213, 'subsample': 0.9395925641260721, 'colsample_bytree': 0.7847134654724188}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:50] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:50,978] Trial 19 finished with value: 0.8010994502748625 and parameters: {'n_estimators': 143, 'max_depth': 3, 'learning_rate': 0.0698606801008188, 'subsample': 0.8543814289887118, 'colsample_bytree': 0.7038875793593559}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:51,606] Trial 20 finished with value: 0.8363943028485757 and parameters: {'n_estimators': 160, 'max_depth': 9, 'learning_rate': 0.08755417493761135, 'subsample': 0.9419572325473685, 'colsample_bytree': 0.8011776780377368}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:51] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:52,232] Trial 21 finished with value: 0.8351449275362318 and parameters: {'n_estimators': 159, 'max_depth': 9, 'learning_rate': 0.08074945290954996, 'subsample': 0.931398905769453, 'colsample_bytree': 0.7985245062325663}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:52,849] Trial 22 finished with value: 0.8355822088955521 and parameters: {'n_estimators': 159, 'max_depth': 9, 'learning_rate': 0.093014779862464, 'subsample': 0.946744509196108, 'colsample_bytree': 0.7137607156103652}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:52] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:53,228] Trial 23 finished with value: 0.8321464267866068 and parameters: {'n_estimators': 131, 'max_depth': 7, 'learning_rate': 0.09591657561615333, 'subsample': 0.9726727248874482, 'colsample_bytree': 0.7126164932083401}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:53,901] Trial 24 finished with value: 0.8322088955522239 and parameters: {'n_estimators': 161, 'max_depth': 9, 'learning_rate': 0.14678343696548501, 'subsample': 0.9174058243435729, 'colsample_bytree': 0.6965948608398397}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:53] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:54,353] Trial 25 finished with value: 0.8239630184907546 and parameters: {'n_estimators': 121, 'max_depth': 8, 'learning_rate': 0.053412811271408366, 'subsample': 0.9641682014970681, 'colsample_bytree': 0.7285359403842064}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:54,777] Trial 26 finished with value: 0.8344577711144429 and parameters: {'n_estimators': 172, 'max_depth': 6, 'learning_rate': 0.10007913997282551, 'subsample': 0.9610198287605608, 'colsample_bytree': 0.753529402704638}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:55,394] Trial 27 finished with value: 0.8329585207396302 and parameters: {'n_estimators': 147, 'max_depth': 9, 'learning_rate': 0.14148127053358783, 'subsample': 0.9144404038545557, 'colsample_bytree': 0.8038310825337815}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:56,041] Trial 28 finished with value: 0.8291479260369815 and parameters: {'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.05799697590089835, 'subsample': 0.8554567053638272, 'colsample_bytree': 0.6876748873115964}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:56,676] Trial 29 finished with value: 0.8332708645677162 and parameters: {'n_estimators': 219, 'max_depth': 7, 'learning_rate': 0.11608541812338484, 'subsample': 0.7651632103585166, 'colsample_bytree': 0.8504883065474816}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:56] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:57,390] Trial 30 finished with value: 0.8350824587706146 and parameters: {'n_estimators': 197, 'max_depth': 8, 'learning_rate': 0.08561891056673844, 'subsample': 0.9840042748564595, 'colsample_bytree': 0.9095115655199049}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:58,047] Trial 31 finished with value: 0.8331459270364817 and parameters: {'n_estimators': 162, 'max_depth': 9, 'learning_rate': 0.07986855477245422, 'subsample': 0.9327219306913488, 'colsample_bytree': 0.7959486471528021}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:58,679] Trial 32 finished with value: 0.8350824587706147 and parameters: {'n_estimators': 157, 'max_depth': 9, 'learning_rate': 0.06740618928233989, 'subsample': 0.9525711884012065, 'colsample_bytree': 0.7657774654658682}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:58] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:59,145] Trial 33 finished with value: 0.8325212393803098 and parameters: {'n_estimators': 133, 'max_depth': 8, 'learning_rate': 0.13077044002756746, 'subsample': 0.9203083389139174, 'colsample_bytree': 0.8125601140840781}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:05:59,820] Trial 34 finished with value: 0.8349575212393803 and parameters: {'n_estimators': 175, 'max_depth': 9, 'learning_rate': 0.0933672246367591, 'subsample': 0.8761441396789117, 'colsample_bytree': 0.7287820823246535}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:05:59] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:00,576] Trial 35 finished with value: 0.8363318340829585 and parameters: {'n_estimators': 151, 'max_depth': 10, 'learning_rate': 0.10616603135912302, 'subsample': 0.953848658390533, 'colsample_bytree': 0.8739379738505333}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:00] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:01,211] Trial 36 finished with value: 0.8320839580209896 and parameters: {'n_estimators': 131, 'max_depth': 10, 'learning_rate': 0.16563994853322167, 'subsample': 0.9733017060177234, 'colsample_bytree': 0.8732334892077692}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:01] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:01,992] Trial 37 finished with value: 0.8347701149425287 and parameters: {'n_estimators': 151, 'max_depth': 10, 'learning_rate': 0.10399413612848543, 'subsample': 0.9024644593988645, 'colsample_bytree': 0.985133271274043}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:02] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:03,287] Trial 38 finished with value: 0.8280859570214892 and parameters: {'n_estimators': 244, 'max_depth': 10, 'learning_rate': 0.023143434808174636, 'subsample': 0.9479118428062492, 'colsample_bytree': 0.6358304076872648}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:03,526] Trial 39 finished with value: 0.8213393303348325 and parameters: {'n_estimators': 118, 'max_depth': 4, 'learning_rate': 0.13340677806552442, 'subsample': 0.832276224233558, 'colsample_bytree': 0.9493103195278478}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:03,839] Trial 40 finished with value: 0.809095452273863 and parameters: {'n_estimators': 108, 'max_depth': 6, 'learning_rate': 0.04637980856455206, 'subsample': 0.60031795988798, 'colsample_bytree': 0.8408240362326672}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:03] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:04,507] Trial 41 finished with value: 0.8347076461769115 and parameters: {'n_estimators': 168, 'max_depth': 9, 'learning_rate': 0.0817118503959179, 'subsample': 0.9328740235339857, 'colsample_bytree': 0.7798774107428318}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:05,171] Trial 42 finished with value: 0.8355197401299349 and parameters: {'n_estimators': 178, 'max_depth': 9, 'learning_rate': 0.10801159208809527, 'subsample': 0.9854058311676495, 'colsample_bytree': 0.6646981640485504}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:05,740] Trial 43 finished with value: 0.8353323338330835 and parameters: {'n_estimators': 184, 'max_depth': 8, 'learning_rate': 0.10938368781871584, 'subsample': 0.9850644978771863, 'colsample_bytree': 0.6758657420619325}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:05] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:06,580] Trial 44 finished with value: 0.8323963018490755 and parameters: {'n_estimators': 196, 'max_depth': 10, 'learning_rate': 0.15984214875838856, 'subsample': 0.960137714404057, 'colsample_bytree': 0.642736332461165}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:06] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:07,273] Trial 45 finished with value: 0.8339580209895052 and parameters: {'n_estimators': 178, 'max_depth': 9, 'learning_rate': 0.12599642902958716, 'subsample': 0.9997453075002026, 'colsample_bytree': 0.6547180167259371}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:07] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:08,078] Trial 46 finished with value: 0.8324587706146928 and parameters: {'n_estimators': 152, 'max_depth': 10, 'learning_rate': 0.06303378990450743, 'subsample': 0.9009675544431126, 'colsample_bytree': 0.8892083713114783}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:08,549] Trial 47 finished with value: 0.8357071464267866 and parameters: {'n_estimators': 139, 'max_depth': 8, 'learning_rate': 0.19377764215005452, 'subsample': 0.9797874083190917, 'colsample_bytree': 0.7157486164404182}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:08] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:09,000] Trial 48 finished with value: 0.8322088955522239 and parameters: {'n_estimators': 126, 'max_depth': 8, 'learning_rate': 0.18645214432022134, 'subsample': 0.9491066206357471, 'colsample_bytree': 0.7394166982647946}. Best is trial 2 with value: 0.8370814592703648.\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:9: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:10: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\2168806235.py:11: FutureWarning: suggest_uniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float instead.\n",
      "  'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[I 2025-05-16 20:06:09,457] Trial 49 finished with value: 0.8283983008495751 and parameters: {'n_estimators': 137, 'max_depth': 7, 'learning_rate': 0.15019929677262278, 'subsample': 0.7131165613394004, 'colsample_bytree': 0.7187989346696947}. Best is trial 2 with value: 0.8370814592703648.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'n_estimators': 147, 'max_depth': 9, 'learning_rate': 0.10407331492557823, 'subsample': 0.9672953533234545, 'colsample_bytree': 0.7717554238700458}\n",
      "Best CV accuracy: 0.8370814592703648\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 300),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.2),\n",
    "        'subsample': trial.suggest_uniform('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.6, 1.0),\n",
    "        'random_state': 42,\n",
    "        'use_label_encoder': False,\n",
    "        'eval_metric': 'logloss'\n",
    "    }\n",
    "    model = XGBClassifier(**param)\n",
    "    score = cross_val_score(model, X_train_sel, y_train, cv=3, scoring='accuracy').mean()\n",
    "    return score\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)\n",
    "\n",
    "print(\"Best params:\", study.best_params)\n",
    "print(\"Best CV accuracy:\", study.best_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e4efe6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:09] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 8004, number of negative: 8004\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000571 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2263\n",
      "[LightGBM] [Info] Number of data points in the train set: 16008, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:11] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [20:06:12] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000965 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2242\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001055 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 2234\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000503 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2242\n",
      "[LightGBM] [Info] Number of data points in the train set: 12806, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6403, number of negative: 6404\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000545 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2248\n",
      "[LightGBM] [Info] Number of data points in the train set: 12807, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499961 -> initscore=-0.000156\n",
      "[LightGBM] [Info] Start training from score -0.000156\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Info] Number of positive: 6404, number of negative: 6403\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2235\n",
      "[LightGBM] [Info] Number of data points in the train set: 12807, number of used features: 19\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500039 -> initscore=0.000156\n",
      "[LightGBM] [Info] Start training from score 0.000156\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
      "Stacking Model Accuracy: 0.8458270864567716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.85      2001\n",
      "           1       0.84      0.85      0.85      2001\n",
      "\n",
      "    accuracy                           0.85      4002\n",
      "   macro avg       0.85      0.85      0.85      4002\n",
      "weighted avg       0.85      0.85      0.85      4002\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "xgb_best = XGBClassifier(\n",
    "    n_estimators=263,\n",
    "    max_depth=9,\n",
    "    learning_rate=0.055,\n",
    "    subsample=0.91,\n",
    "    colsample_bytree=0.60,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=200, max_depth=6, learning_rate=0.1, random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=200, max_depth=6, random_state=42)\n",
    "\n",
    "estimators = [('xgb', xgb_best), ('lgbm', lgbm), ('rf', rf)]\n",
    "stacking_clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
    "\n",
    "stacking_clf.fit(X_train_sel, y_train)\n",
    "y_pred_stack = stacking_clf.predict(X_test_sel)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Stacking Model Accuracy:\", accuracy_score(y_test, y_pred_stack))\n",
    "print(classification_report(y_test, y_pred_stack))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518bcf5e",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c233127e",
   "metadata": {},
   "source": [
    "# LSTM 深度學習模型 來預測火災"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dca1f268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_mean'] = df[col].rolling(window).mean().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_std'] = df[col].rolling(window).std().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_mean'] = df[col].rolling(window).mean().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_std'] = df[col].rolling(window).std().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:14: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_mean'] = df[col].rolling(window).mean().fillna(method='bfill')\n",
      "C:\\Users\\ygz08\\AppData\\Local\\Temp\\ipykernel_12900\\1359092184.py:15: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df[f'{col}_rolling_std'] = df[col].rolling(window).std().fillna(method='bfill')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 假設 df 是你的原始資料集，且已排序\n",
    "df = df.sort_values('DATE')\n",
    "\n",
    "# 建立滯後特徵，例如前3天火災狀態\n",
    "for lag in range(1, 4):\n",
    "    df[f'FIRE_START_DAY_lag_{lag}'] = df['FIRE_START_DAY'].shift(lag).fillna(0)\n",
    "\n",
    "# 建立滾動特徵 (3天平均與標準差)\n",
    "window = 3\n",
    "for col in ['AVG_WIND_SPEED', 'PRECIPITATION', 'TEMP_RANGE']:\n",
    "    df[f'{col}_rolling_mean'] = df[col].rolling(window).mean().fillna(method='bfill')\n",
    "    df[f'{col}_rolling_std'] = df[col].rolling(window).std().fillna(method='bfill')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ee4978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 篩選用到的特徵\n",
    "features = ['AVG_WIND_SPEED', 'PRECIPITATION', 'TEMP_RANGE',\n",
    "            'FIRE_START_DAY_lag_1', 'FIRE_START_DAY_lag_2', 'FIRE_START_DAY_lag_3',\n",
    "            'AVG_WIND_SPEED_rolling_mean', 'AVG_WIND_SPEED_rolling_std',\n",
    "            'PRECIPITATION_rolling_mean', 'PRECIPITATION_rolling_std',\n",
    "            'TEMP_RANGE_rolling_mean', 'TEMP_RANGE_rolling_std']\n",
    "\n",
    "data = df[features].values\n",
    "labels = df['FIRE_START_DAY'].values\n",
    "\n",
    "# 標準化特徵\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "# 建立序列資料 (7天為一個序列)\n",
    "def create_sequences(data, labels, seq_length=7):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(labels[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(data, labels)\n",
    "\n",
    "# 切分訓練測試集 (80%訓練)\n",
    "split_idx = int(len(X)*0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6413314b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step - accuracy: 0.7586 - loss: 0.5119 - val_accuracy: 0.7658 - val_loss: 0.5300\n",
      "Epoch 2/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7849 - loss: 0.4466 - val_accuracy: 0.7716 - val_loss: 0.5399\n",
      "Epoch 3/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7817 - loss: 0.4474 - val_accuracy: 0.7729 - val_loss: 0.5346\n",
      "Epoch 4/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7903 - loss: 0.4453 - val_accuracy: 0.7699 - val_loss: 0.5400\n",
      "Epoch 5/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7880 - loss: 0.4385 - val_accuracy: 0.7670 - val_loss: 0.5341\n",
      "Epoch 6/50\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7929 - loss: 0.4358 - val_accuracy: 0.7537 - val_loss: 0.5322\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True),\n",
    "    Dropout(0.2),\n",
    "    LSTM(32),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4f17c5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7910 - loss: 0.4908\n",
      "LSTM Test Accuracy: 0.7979\n"
     ]
    }
   ],
   "source": [
    "loss, LSTM_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"LSTM Test Accuracy: {LSTM_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f23ad75",
   "metadata": {},
   "source": [
    "# 雙層 LSTM + 時間週期特徵 + 序列長度14天的版本："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0480cff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.7617 - loss: 0.4866 - val_accuracy: 0.7774 - val_loss: 0.5149\n",
      "Epoch 2/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7904 - loss: 0.4372 - val_accuracy: 0.7790 - val_loss: 0.5285\n",
      "Epoch 3/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7900 - loss: 0.4457 - val_accuracy: 0.7778 - val_loss: 0.5151\n",
      "Epoch 4/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7892 - loss: 0.4338 - val_accuracy: 0.7732 - val_loss: 0.5094\n",
      "Epoch 5/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8043 - loss: 0.4241 - val_accuracy: 0.7698 - val_loss: 0.5023\n",
      "Epoch 6/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7984 - loss: 0.4299 - val_accuracy: 0.7698 - val_loss: 0.5082\n",
      "Epoch 7/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7920 - loss: 0.4246 - val_accuracy: 0.7765 - val_loss: 0.5067\n",
      "Epoch 8/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8027 - loss: 0.4201 - val_accuracy: 0.7623 - val_loss: 0.5118\n",
      "Epoch 9/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7995 - loss: 0.4231 - val_accuracy: 0.7556 - val_loss: 0.5307\n",
      "Epoch 10/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8075 - loss: 0.4140 - val_accuracy: 0.7615 - val_loss: 0.5154\n",
      "Epoch 11/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8018 - loss: 0.4147 - val_accuracy: 0.7636 - val_loss: 0.5087\n",
      "Epoch 12/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.8026 - loss: 0.4161 - val_accuracy: 0.7590 - val_loss: 0.5255\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7819 - loss: 0.4667\n",
      "Double-layer LSTM (14-day window) Test Accuracy: 0.7935\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 假設 df 已有日期欄 DATE 和 target 欄 FIRE_START_DAY\n",
    "\n",
    "df = df.sort_values('DATE')\n",
    "\n",
    "# 週期性時間特徵 (day_of_year)\n",
    "df['day_of_year'] = df['DATE'].dt.dayofyear\n",
    "df['sin_day'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['cos_day'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "\n",
    "# 其他滯後及滾動特徵你之前已有，這邊直接選用：\n",
    "features = ['AVG_WIND_SPEED', 'PRECIPITATION', 'TEMP_RANGE',\n",
    "            'FIRE_START_DAY_lag_1', 'FIRE_START_DAY_lag_2', 'FIRE_START_DAY_lag_3',\n",
    "            'AVG_WIND_SPEED_rolling_mean', 'AVG_WIND_SPEED_rolling_std',\n",
    "            'PRECIPITATION_rolling_mean', 'PRECIPITATION_rolling_std',\n",
    "            'TEMP_RANGE_rolling_mean', 'TEMP_RANGE_rolling_std',\n",
    "            'sin_day', 'cos_day']\n",
    "\n",
    "# 準備資料\n",
    "data = df[features].values\n",
    "labels = df['FIRE_START_DAY'].values\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data = scaler.fit_transform(data)\n",
    "\n",
    "def create_sequences(data, labels, seq_length=14):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(labels[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X, y = create_sequences(data, labels, seq_length=14)\n",
    "\n",
    "split_idx = int(len(X)*0.8)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "# 模型架構：雙層 LSTM\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "              loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=100,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop])\n",
    "                    \n",
    "loss, DLLSTM_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Double-layer LSTM (14-day window) Test Accuracy: {DLLSTM_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a3cb1d",
   "metadata": {},
   "source": [
    "# GRU 模型版本"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88708653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.7716 - loss: 0.4791 - val_accuracy: 0.7749 - val_loss: 0.5108\n",
      "Epoch 2/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7938 - loss: 0.4298 - val_accuracy: 0.7673 - val_loss: 0.5144\n",
      "Epoch 3/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7942 - loss: 0.4319 - val_accuracy: 0.7719 - val_loss: 0.5054\n",
      "Epoch 4/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7958 - loss: 0.4271 - val_accuracy: 0.7753 - val_loss: 0.5056\n",
      "Epoch 5/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7941 - loss: 0.4290 - val_accuracy: 0.7698 - val_loss: 0.5132\n",
      "Epoch 6/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7960 - loss: 0.4282 - val_accuracy: 0.7732 - val_loss: 0.5052\n",
      "Epoch 7/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7970 - loss: 0.4240 - val_accuracy: 0.7723 - val_loss: 0.5044\n",
      "Epoch 8/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7986 - loss: 0.4253 - val_accuracy: 0.7744 - val_loss: 0.5004\n",
      "Epoch 9/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8028 - loss: 0.4178 - val_accuracy: 0.7711 - val_loss: 0.5123\n",
      "Epoch 10/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8027 - loss: 0.4159 - val_accuracy: 0.7736 - val_loss: 0.5046\n",
      "Epoch 11/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8012 - loss: 0.4144 - val_accuracy: 0.7648 - val_loss: 0.5095\n",
      "Epoch 12/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8010 - loss: 0.4144 - val_accuracy: 0.7719 - val_loss: 0.5124\n",
      "Epoch 13/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8088 - loss: 0.4060 - val_accuracy: 0.7732 - val_loss: 0.5117\n",
      "Epoch 14/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8044 - loss: 0.4107 - val_accuracy: 0.7598 - val_loss: 0.5149\n",
      "Epoch 15/100\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.8113 - loss: 0.3995 - val_accuracy: 0.7636 - val_loss: 0.5096\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7901 - loss: 0.4694\n",
      "GRU Model Test Accuracy: 0.7992\n"
     ]
    }
   ],
   "source": [
    "model_gru = Sequential([\n",
    "    GRU(128, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])),\n",
    "    Dropout(0.3),\n",
    "    GRU(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_gru.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-3),\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop_gru = EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True)\n",
    "\n",
    "history_gru = model_gru.fit(X_train, y_train,\n",
    "                            validation_split=0.2,\n",
    "                            epochs=100,\n",
    "                            batch_size=64,\n",
    "                            callbacks=[early_stop_gru])\n",
    "\n",
    "loss_gru, acc_gru = model_gru.evaluate(X_test, y_test)\n",
    "print(f\"GRU Model Test Accuracy: {acc_gru:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49a87332",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_history(history, title=\"Model Accuracy\"):\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title(title)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history, \"Double-layer LSTM Accuracy\")\n",
    "plot_history(history_gru, \"GRU Model Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6eb65c",
   "metadata": {},
   "source": [
    "# 資料強化流程建議"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d5b0a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before SMOTE: FIRE_START_DAY\n",
      "0.0    8622\n",
      "1.0    4739\n",
      "Name: count, dtype: int64\n",
      "After SMOTE: FIRE_START_DAY\n",
      "0.0    8622\n",
      "1.0    8622\n",
      "Name: count, dtype: int64\n",
      "   PRECIPITATION  MAX_TEMP  MIN_TEMP  AVG_WIND_SPEED      YEAR  TEMP_RANGE  \\\n",
      "0      -0.175419 -1.362289 -1.821029       -0.309930 -1.701295    0.573966   \n",
      "1      -0.175419 -0.747352 -1.821029       -0.962694 -1.701295    1.296399   \n",
      "2      -0.175419 -0.132414 -1.367257       -1.743681 -1.701295    1.477008   \n",
      "3      -0.175419  0.482523 -0.913485       -0.700423 -1.701295    1.657616   \n",
      "4      -0.175419  1.251194 -0.005941        0.733328 -1.701295    1.477008   \n",
      "\n",
      "   WIND_TEMP_RATIO     MONTH  LAGGED_PRECIPITATION  LAGGED_AVG_WIND_SPEED  \\\n",
      "0         0.191170 -1.706283              0.904297              -1.163044   \n",
      "1        -0.686593 -1.706283             -0.364397              -1.285376   \n",
      "2        -1.581287 -1.706283             -0.364397              -1.431738   \n",
      "3        -0.801322 -1.706283             -0.364397              -1.382587   \n",
      "4         0.167635 -1.706283             -0.364397              -0.111204   \n",
      "\n",
      "   ...  PRECIPITATION_diff_14  FIRE_START_DAY_lag_21  TEMP_RANGE_diff_21  \\\n",
      "0  ...               0.000417              -0.742282           -1.566080   \n",
      "1  ...               0.000417              -0.742282           -0.569626   \n",
      "2  ...               0.000417              -0.742282           -0.142575   \n",
      "3  ...               0.000417              -0.742282           -1.139028   \n",
      "4  ...               0.000417              -0.742282           -0.427276   \n",
      "\n",
      "   AVG_WIND_SPEED_diff_21  PRECIPITATION_diff_21     month  sin_month  \\\n",
      "0                0.989667               0.000413 -1.706283    0.78528   \n",
      "1                0.000602               0.000413 -1.706283    0.78528   \n",
      "2               -0.550518               0.000413 -1.706283    0.78528   \n",
      "3                0.659979               0.000413 -1.706283    0.78528   \n",
      "4                1.653965               0.000413 -1.706283    0.78528   \n",
      "\n",
      "   cos_month  FIRE_START_DAY       DATE  \n",
      "0   1.296286             0.0 1984-01-22  \n",
      "1   1.296286             0.0 1984-01-23  \n",
      "2   1.296286             0.0 1984-01-24  \n",
      "3   1.296286             0.0 1984-01-25  \n",
      "4   1.296286             1.0 1984-01-27  \n",
      "\n",
      "[5 rows x 52 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# 讀取資料\n",
    "#df = pd.read_csv(\"data/CA_Weather_Fire_Dataset_1984-2025.csv\")\n",
    "\n",
    "\n",
    "# 讀取資料，假設df已載入且有DATE欄位(datetime型態)\n",
    "df = df.sort_values('DATE')\n",
    "\n",
    "# 1. 缺失值補齊 (用中位數)\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "num_cols = df.select_dtypes(include=np.number).columns\n",
    "df[num_cols] = imputer.fit_transform(df[num_cols])\n",
    "\n",
    "# 2. 異常值檢測 - 以Z-score法為例\n",
    "from scipy import stats\n",
    "z_scores = np.abs(stats.zscore(df[num_cols]))\n",
    "df = df[(z_scores < 3).all(axis=1)]  # 去除Z-score超過3的異常列\n",
    "\n",
    "# 3. 類別不平衡 (假設目標欄為'FIRE_START_DAY')\n",
    "X = df.drop(columns=['FIRE_START_DAY', 'DATE'])\n",
    "y = df['FIRE_START_DAY']\n",
    "\n",
    "print('Before SMOTE:', y.value_counts())\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "print('After SMOTE:', pd.Series(y_res).value_counts())\n",
    "\n",
    "# 4. 特徵工程 - 滯後特徵 & 差分\n",
    "for lag in [7, 14, 21]:\n",
    "    df[f'FIRE_START_DAY_lag_{lag}'] = df['FIRE_START_DAY'].shift(lag)\n",
    "    for col in ['TEMP_RANGE', 'AVG_WIND_SPEED', 'PRECIPITATION']:\n",
    "        df[f'{col}_diff_{lag}'] = df[col].diff(lag)\n",
    "\n",
    "# 5. 週期性時間特徵\n",
    "df['day_of_year'] = df['DATE'].dt.dayofyear\n",
    "df['sin_day'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['cos_day'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['month'] = df['DATE'].dt.month\n",
    "df['sin_month'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['cos_month'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "\n",
    "# 6. 標準化 (先去除含NaN的滯後與差分列)\n",
    "df = df.dropna()\n",
    "features = df.drop(columns=['FIRE_START_DAY', 'DATE'])\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# 將處理後資料轉回 DataFrame\n",
    "df_scaled = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "df_scaled['FIRE_START_DAY'] = df['FIRE_START_DAY'].values\n",
    "df_scaled['DATE'] = df['DATE'].values\n",
    "\n",
    "print(df_scaled.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598fd89b",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "684b7093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7225 - loss: 0.5432 - val_accuracy: 0.7813 - val_loss: 0.4562\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7875 - loss: 0.4609 - val_accuracy: 0.7831 - val_loss: 0.4549\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7948 - loss: 0.4493 - val_accuracy: 0.7794 - val_loss: 0.4544\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7835 - loss: 0.4573 - val_accuracy: 0.7803 - val_loss: 0.4545\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7913 - loss: 0.4479 - val_accuracy: 0.7813 - val_loss: 0.4526\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7917 - loss: 0.4513 - val_accuracy: 0.7822 - val_loss: 0.4561\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7950 - loss: 0.4461 - val_accuracy: 0.7803 - val_loss: 0.4539\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8032 - loss: 0.4378 - val_accuracy: 0.7817 - val_loss: 0.4541\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7942 - loss: 0.4403 - val_accuracy: 0.7836 - val_loss: 0.4540\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7925 - loss: 0.4416 - val_accuracy: 0.7785 - val_loss: 0.4527\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8034 - loss: 0.4365 - val_accuracy: 0.7794 - val_loss: 0.4537\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8079 - loss: 0.4269 - val_accuracy: 0.7836 - val_loss: 0.4572\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7965 - loss: 0.4309 - val_accuracy: 0.7808 - val_loss: 0.4533\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8083 - loss: 0.4265 - val_accuracy: 0.7808 - val_loss: 0.4543\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8023 - loss: 0.4312 - val_accuracy: 0.7850 - val_loss: 0.4553\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.7691 - loss: 0.4811\n",
      "DNN Test Accuracy: 0.7646\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 假設 df_scaled 已完成前處理與標準化，並包含 'FIRE_START_DAY' 目標欄\n",
    "\n",
    "X = df_scaled.drop(columns=['FIRE_START_DAY', 'DATE']).values\n",
    "y = df_scaled['FIRE_START_DAY'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=100,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "loss, DNN_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'DNN Test Accuracy: {DNN_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236cd292",
   "metadata": {},
   "source": [
    "# DNN + 時間序列擴充：把時間窗拉長到30天以上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7ffddb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (13310, 30, 50)\n",
      "Output shape: (13310,)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6983 - loss: 1.3208 - val_accuracy: 0.7803 - val_loss: 1.0269\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7463 - loss: 1.0501 - val_accuracy: 0.7869 - val_loss: 0.9354\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7721 - loss: 0.9426 - val_accuracy: 0.7887 - val_loss: 0.8753\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7687 - loss: 0.8690 - val_accuracy: 0.7897 - val_loss: 0.7993\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7831 - loss: 0.7804 - val_accuracy: 0.7840 - val_loss: 0.7433\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7833 - loss: 0.7297 - val_accuracy: 0.7887 - val_loss: 0.6843\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7865 - loss: 0.6746 - val_accuracy: 0.7897 - val_loss: 0.6529\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7886 - loss: 0.6358 - val_accuracy: 0.7930 - val_loss: 0.6245\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7884 - loss: 0.6001 - val_accuracy: 0.7906 - val_loss: 0.5900\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.5789 - val_accuracy: 0.7869 - val_loss: 0.5709\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7895 - loss: 0.5580 - val_accuracy: 0.7878 - val_loss: 0.5586\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7870 - loss: 0.5463 - val_accuracy: 0.7859 - val_loss: 0.5468\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7941 - loss: 0.5434 - val_accuracy: 0.7892 - val_loss: 0.5425\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7953 - loss: 0.5268 - val_accuracy: 0.7948 - val_loss: 0.5339\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7867 - loss: 0.5217 - val_accuracy: 0.7878 - val_loss: 0.5283\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.5172 - val_accuracy: 0.7878 - val_loss: 0.5320\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.5225 - val_accuracy: 0.7887 - val_loss: 0.5293\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7948 - loss: 0.5137 - val_accuracy: 0.7831 - val_loss: 0.5255\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.5044 - val_accuracy: 0.7925 - val_loss: 0.5198\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7925 - loss: 0.5050 - val_accuracy: 0.7901 - val_loss: 0.5167\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8014 - loss: 0.5013 - val_accuracy: 0.7911 - val_loss: 0.5150\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.5001 - val_accuracy: 0.7878 - val_loss: 0.5230\n",
      "Epoch 23/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.4958 - val_accuracy: 0.7930 - val_loss: 0.5157\n",
      "Epoch 24/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7916 - loss: 0.4962 - val_accuracy: 0.7911 - val_loss: 0.5340\n",
      "Epoch 25/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8037 - loss: 0.4923 - val_accuracy: 0.7892 - val_loss: 0.5169\n",
      "Epoch 26/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4932 - val_accuracy: 0.7934 - val_loss: 0.5102\n",
      "Epoch 27/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 0.5022 - val_accuracy: 0.7920 - val_loss: 0.5217\n",
      "Epoch 28/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.4823 - val_accuracy: 0.7911 - val_loss: 0.5087\n",
      "Epoch 29/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8019 - loss: 0.4820 - val_accuracy: 0.7864 - val_loss: 0.5208\n",
      "Epoch 30/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7922 - loss: 0.4986 - val_accuracy: 0.7892 - val_loss: 0.5159\n",
      "Epoch 31/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7946 - loss: 0.4914 - val_accuracy: 0.7864 - val_loss: 0.5140\n",
      "Epoch 32/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7913 - loss: 0.4960 - val_accuracy: 0.7854 - val_loss: 0.5171\n",
      "Epoch 33/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7968 - loss: 0.4968 - val_accuracy: 0.7887 - val_loss: 0.5139\n",
      "Epoch 34/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7965 - loss: 0.4951 - val_accuracy: 0.7765 - val_loss: 0.5220\n",
      "Epoch 35/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8025 - loss: 0.4950 - val_accuracy: 0.7869 - val_loss: 0.5281\n",
      "Epoch 36/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7944 - loss: 0.4991 - val_accuracy: 0.7911 - val_loss: 0.5241\n",
      "Epoch 37/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7940 - loss: 0.5028 - val_accuracy: 0.7817 - val_loss: 0.5320\n",
      "Epoch 38/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4827 - val_accuracy: 0.7892 - val_loss: 0.5196\n",
      "Epoch 39/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7967 - loss: 0.4949 - val_accuracy: 0.7887 - val_loss: 0.5153\n",
      "Epoch 40/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7961 - loss: 0.4881 - val_accuracy: 0.7826 - val_loss: 0.5137\n",
      "Epoch 41/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7994 - loss: 0.4906 - val_accuracy: 0.7808 - val_loss: 0.5179\n",
      "Epoch 42/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7993 - loss: 0.4949 - val_accuracy: 0.7948 - val_loss: 0.5055\n",
      "Epoch 43/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8054 - loss: 0.4847 - val_accuracy: 0.7854 - val_loss: 0.5163\n",
      "Epoch 44/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7941 - loss: 0.4882 - val_accuracy: 0.7859 - val_loss: 0.5162\n",
      "Epoch 45/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7958 - loss: 0.4991 - val_accuracy: 0.7873 - val_loss: 0.5326\n",
      "Epoch 46/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4839 - val_accuracy: 0.7878 - val_loss: 0.5194\n",
      "Epoch 47/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7873 - loss: 0.4955 - val_accuracy: 0.7930 - val_loss: 0.5129\n",
      "Epoch 48/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8017 - loss: 0.4898 - val_accuracy: 0.7850 - val_loss: 0.5195\n",
      "Epoch 49/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7963 - loss: 0.4891 - val_accuracy: 0.7845 - val_loss: 0.5189\n",
      "Epoch 50/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7987 - loss: 0.4966 - val_accuracy: 0.7831 - val_loss: 0.5349\n",
      "Epoch 51/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7943 - loss: 0.5084 - val_accuracy: 0.7859 - val_loss: 0.5340\n",
      "Epoch 52/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8006 - loss: 0.4892 - val_accuracy: 0.7826 - val_loss: 0.5230\n",
      "Epoch 53/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8097 - loss: 0.4873 - val_accuracy: 0.7878 - val_loss: 0.5214\n",
      "Epoch 54/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7947 - loss: 0.4961 - val_accuracy: 0.7878 - val_loss: 0.5168\n",
      "Epoch 55/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8026 - loss: 0.4889 - val_accuracy: 0.7859 - val_loss: 0.5285\n",
      "Epoch 56/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8034 - loss: 0.4913 - val_accuracy: 0.7925 - val_loss: 0.5211\n",
      "Epoch 57/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8091 - loss: 0.4809 - val_accuracy: 0.7836 - val_loss: 0.5252\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7943 - loss: 0.5127  \n",
      "DNN (30-day window) Test Accuracy: 0.7866\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 假設df_scaled是前面標準化後的DataFrame，包含日期與標的FIRE_START_DAY\n",
    "\n",
    "# 只取特徵欄（不含日期與目標欄）\n",
    "feature_cols = [c for c in df_scaled.columns if c not in ['DATE', 'FIRE_START_DAY']]\n",
    "features = df_scaled[feature_cols].values\n",
    "labels = df_scaled['FIRE_START_DAY'].values\n",
    "\n",
    "window_size = 30\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "# 用前30天資料預測當天（第30天）目標\n",
    "for i in range(window_size, len(features)):\n",
    "    X.append(features[i-window_size:i])  # 30天的特徵矩陣 (30, feature_num)\n",
    "    y.append(labels[i])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "print('Input shape:', X.shape)  # (樣本數, 30, 特徵數)\n",
    "print('Output shape:', y.shape)\n",
    "\n",
    "# 分訓練/測試\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 簡單DNN模型 (Flatten + Dense)\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(window_size, X.shape[2])),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=100,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "loss, DNN30_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'DNN (30-day window) Test Accuracy: {DNN30_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3fc970",
   "metadata": {},
   "source": [
    "#  LSTM + Attention 模型架構"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b309333a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Attention</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │            <span style=\"color: #00af00; text-decoration-color: #00af00\">94</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m50\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_4 (\u001b[38;5;33mLSTM\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m29,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ attention (\u001b[38;5;33mAttention\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │            \u001b[38;5;34m94\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,647</span> (123.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m31,647\u001b[0m (123.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">31,647</span> (123.62 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m31,647\u001b[0m (123.62 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7104 - loss: 0.5635 - val_accuracy: 0.7864 - val_loss: 0.4526\n",
      "Epoch 2/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7740 - loss: 0.4932 - val_accuracy: 0.7887 - val_loss: 0.4508\n",
      "Epoch 3/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7702 - loss: 0.4833 - val_accuracy: 0.7897 - val_loss: 0.4497\n",
      "Epoch 4/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7793 - loss: 0.4735 - val_accuracy: 0.7925 - val_loss: 0.4474\n",
      "Epoch 5/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7751 - loss: 0.4774 - val_accuracy: 0.7925 - val_loss: 0.4487\n",
      "Epoch 6/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7858 - loss: 0.4677 - val_accuracy: 0.7906 - val_loss: 0.4469\n",
      "Epoch 7/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7810 - loss: 0.4624 - val_accuracy: 0.7958 - val_loss: 0.4450\n",
      "Epoch 8/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7900 - loss: 0.4570 - val_accuracy: 0.7939 - val_loss: 0.4500\n",
      "Epoch 9/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7838 - loss: 0.4574 - val_accuracy: 0.7920 - val_loss: 0.4457\n",
      "Epoch 10/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7888 - loss: 0.4532 - val_accuracy: 0.7897 - val_loss: 0.4453\n",
      "Epoch 11/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7982 - loss: 0.4455 - val_accuracy: 0.7915 - val_loss: 0.4482\n",
      "Epoch 12/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7860 - loss: 0.4471 - val_accuracy: 0.7915 - val_loss: 0.4495\n",
      "Epoch 13/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7916 - loss: 0.4404 - val_accuracy: 0.7906 - val_loss: 0.4471\n",
      "Epoch 14/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7863 - loss: 0.4448 - val_accuracy: 0.7934 - val_loss: 0.4534\n",
      "Epoch 15/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7931 - loss: 0.4341 - val_accuracy: 0.7953 - val_loss: 0.4535\n",
      "Epoch 16/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7965 - loss: 0.4420 - val_accuracy: 0.7859 - val_loss: 0.4590\n",
      "Epoch 17/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7911 - loss: 0.4282 - val_accuracy: 0.7831 - val_loss: 0.4580\n",
      "Epoch 18/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7967 - loss: 0.4313 - val_accuracy: 0.7892 - val_loss: 0.4589\n",
      "Epoch 19/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7931 - loss: 0.4314 - val_accuracy: 0.7845 - val_loss: 0.4553\n",
      "Epoch 20/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7950 - loss: 0.4240 - val_accuracy: 0.7822 - val_loss: 0.4715\n",
      "Epoch 21/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8027 - loss: 0.4165 - val_accuracy: 0.7831 - val_loss: 0.4749\n",
      "Epoch 22/100\n",
      "\u001b[1m134/134\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7962 - loss: 0.4203 - val_accuracy: 0.7887 - val_loss: 0.4681\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7906 - loss: 0.4538\n",
      "LSTM+Attention Test Accuracy: 0.7799\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer, Input, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "# Attention Layer 自訂義\n",
    "class Attention(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
    "                                 initializer=\"normal\")\n",
    "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
    "                                 initializer=\"zeros\")\n",
    "        super(Attention, self).build(input_shape)\n",
    "\n",
    "    def call(self, x):\n",
    "        e = K.tanh(K.dot(x, self.W) + self.b)  # (batch_size, time_steps, 1)\n",
    "        e = K.squeeze(e, axis=-1)  # (batch_size, time_steps)\n",
    "        alpha = K.softmax(e)  # 注意力權重\n",
    "        alpha = K.expand_dims(alpha, axis=-1)  # (batch_size, time_steps, 1)\n",
    "        context = x * alpha  # 權重乘以輸入序列\n",
    "        context = K.sum(context, axis=1)  # 對時間軸加權求和 (batch_size, features)\n",
    "        return context\n",
    "\n",
    "# 建立模型\n",
    "input_shape = (window_size, X.shape[2])\n",
    "inputs = Input(shape=input_shape)\n",
    "x = LSTM(64, return_sequences=True)(inputs)\n",
    "x = Attention()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 訓練\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.2,\n",
    "                    epochs=100,\n",
    "                    batch_size=64,\n",
    "                    callbacks=[early_stop])\n",
    "\n",
    "# 測試\n",
    "loss, LSTM_Attention_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'LSTM+Attention Test Accuracy: {LSTM_Attention_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181adfb8",
   "metadata": {},
   "source": [
    "# 視覺化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "82e54828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 模型名稱\n",
    "models = [\n",
    "    \"LSTM\",\n",
    "    \"Double-layer LSTM (14-day)\",\n",
    "    \"GRU\",\n",
    "    \"DNN\",\n",
    "    \"DNN (30-day)\",\n",
    "    \"LSTM + Attention\"\n",
    "]\n",
    "\n",
    "# 對應準確率\n",
    "accuracies = [\n",
    "    LSTM_accuracy,\n",
    "    DLLSTM_accuracy,\n",
    "    acc_gru,\n",
    "    DNN_accuracy,\n",
    "    DNN30_accuracy,\n",
    "    LSTM_Attention_accuracy\n",
    "]\n",
    "models = models[::-1]\n",
    "accuracies = accuracies[::-1]\n",
    "\n",
    "# 繪製橫向長條圖\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.barh(models, accuracies, color='skyblue')\n",
    "plt.xlabel('Test Accuracy')\n",
    "plt.title('comparison of Different Models')\n",
    "plt.xlim(0.5, 0.9)\n",
    "\n",
    "# 在長條圖上標記數值\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(acc + 0.001, bar.get_y() + bar.get_height()/2, f\"{acc*100:.1f}%\", va='center')\n",
    "\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f65903b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
