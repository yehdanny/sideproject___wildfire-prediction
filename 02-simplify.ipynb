{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65f5aaf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRECIPITATION</th>\n",
       "      <th>MAX_TEMP</th>\n",
       "      <th>MIN_TEMP</th>\n",
       "      <th>AVG_WIND_SPEED</th>\n",
       "      <th>FIRE_START_DAY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TEMP_RANGE</th>\n",
       "      <th>WIND_TEMP_RATIO</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>LAGGED_PRECIPITATION</th>\n",
       "      <th>LAGGED_AVG_WIND_SPEED</th>\n",
       "      <th>DAY_OF_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1984-01-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>False</td>\n",
       "      <td>1984</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.059494</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1984-01-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>5.59</td>\n",
       "      <td>False</td>\n",
       "      <td>1984</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.078732</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1984-01-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5.37</td>\n",
       "      <td>False</td>\n",
       "      <td>1984</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.076714</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.220</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1984-01-04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>4.70</td>\n",
       "      <td>False</td>\n",
       "      <td>1984</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.090</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1984-01-05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>5.14</td>\n",
       "      <td>False</td>\n",
       "      <td>1984</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.069459</td>\n",
       "      <td>1</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.100</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         DATE  PRECIPITATION  MAX_TEMP  MIN_TEMP  AVG_WIND_SPEED  \\\n",
       "0  1984-01-01            0.0      79.0      51.0            4.70   \n",
       "1  1984-01-02            0.0      71.0      46.0            5.59   \n",
       "2  1984-01-03            0.0      70.0      47.0            5.37   \n",
       "3  1984-01-04            0.0      76.0      45.0            4.70   \n",
       "4  1984-01-05            0.0      74.0      49.0            5.14   \n",
       "\n",
       "   FIRE_START_DAY  YEAR  TEMP_RANGE  WIND_TEMP_RATIO  MONTH  SEASON  \\\n",
       "0           False  1984        28.0         0.059494      1  Winter   \n",
       "1           False  1984        25.0         0.078732      1  Winter   \n",
       "2           False  1984        23.0         0.076714      1  Winter   \n",
       "3           False  1984        31.0         0.061842      1  Winter   \n",
       "4           False  1984        25.0         0.069459      1  Winter   \n",
       "\n",
       "   LAGGED_PRECIPITATION  LAGGED_AVG_WIND_SPEED  DAY_OF_YEAR  \n",
       "0                   0.0                  4.700            1  \n",
       "1                   0.0                  5.145            2  \n",
       "2                   0.0                  5.220            3  \n",
       "3                   0.0                  5.090            4  \n",
       "4                   0.0                  5.100            5  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 讀取資料\n",
    "df = pd.read_csv('data/CA_Weather_Fire_Dataset_1984-2025.csv')\n",
    "\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a6a4521",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECIPITATION</th>\n",
       "      <th>MAX_TEMP</th>\n",
       "      <th>MIN_TEMP</th>\n",
       "      <th>AVG_WIND_SPEED</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TEMP_RANGE</th>\n",
       "      <th>WIND_TEMP_RATIO</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>LAGGED_PRECIPITATION</th>\n",
       "      <th>LAGGED_AVG_WIND_SPEED</th>\n",
       "      <th>DAY_OF_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14987.000000</td>\n",
       "      <td>14987.000000</td>\n",
       "      <td>14987.000000</td>\n",
       "      <td>14976.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14987.000000</td>\n",
       "      <td>14976.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.032315</td>\n",
       "      <td>70.534997</td>\n",
       "      <td>56.494095</td>\n",
       "      <td>7.435098</td>\n",
       "      <td>2004.016813</td>\n",
       "      <td>14.040902</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>6.518281</td>\n",
       "      <td>0.226188</td>\n",
       "      <td>7.434198</td>\n",
       "      <td>182.992994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.179544</td>\n",
       "      <td>7.263447</td>\n",
       "      <td>6.767685</td>\n",
       "      <td>2.129985</td>\n",
       "      <td>11.843342</td>\n",
       "      <td>5.995327</td>\n",
       "      <td>0.035630</td>\n",
       "      <td>3.451037</td>\n",
       "      <td>0.648705</td>\n",
       "      <td>1.387849</td>\n",
       "      <td>105.523627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.227143</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>6.040000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.085238</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.518571</td>\n",
       "      <td>92.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.102222</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.478571</td>\n",
       "      <td>183.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.120462</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>8.278571</td>\n",
       "      <td>274.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.530000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>26.170000</td>\n",
       "      <td>2025.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.459123</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>8.180000</td>\n",
       "      <td>13.932857</td>\n",
       "      <td>366.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRECIPITATION      MAX_TEMP      MIN_TEMP  AVG_WIND_SPEED  \\\n",
       "count   14987.000000  14987.000000  14987.000000    14976.000000   \n",
       "mean        0.032315     70.534997     56.494095        7.435098   \n",
       "std         0.179544      7.263447      6.767685        2.129985   \n",
       "min         0.000000     50.000000     33.000000        1.790000   \n",
       "25%         0.000000     65.000000     51.000000        6.040000   \n",
       "50%         0.000000     70.000000     57.000000        7.160000   \n",
       "75%         0.000000     75.000000     62.000000        8.500000   \n",
       "max         4.530000    106.000000     77.000000       26.170000   \n",
       "\n",
       "               YEAR    TEMP_RANGE  WIND_TEMP_RATIO         MONTH  \\\n",
       "count  14988.000000  14987.000000     14976.000000  14988.000000   \n",
       "mean    2004.016813     14.040902         0.107019      6.518281   \n",
       "std       11.843342      5.995327         0.035630      3.451037   \n",
       "min     1984.000000      2.000000         0.023553      1.000000   \n",
       "25%     1994.000000     10.000000         0.085238      4.000000   \n",
       "50%     2004.000000     12.000000         0.102222      7.000000   \n",
       "75%     2014.000000     17.000000         0.120462     10.000000   \n",
       "max     2025.000000     41.000000         0.459123     12.000000   \n",
       "\n",
       "       LAGGED_PRECIPITATION  LAGGED_AVG_WIND_SPEED   DAY_OF_YEAR  \n",
       "count          14988.000000           14988.000000  14988.000000  \n",
       "mean               0.226188               7.434198    182.992994  \n",
       "std                0.648705               1.387849    105.523627  \n",
       "min                0.000000               3.227143      1.000000  \n",
       "25%                0.000000               6.518571     92.000000  \n",
       "50%                0.000000               7.478571    183.000000  \n",
       "75%                0.060000               8.278571    274.000000  \n",
       "max                8.180000              13.932857    366.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fade8477",
   "metadata": {},
   "source": [
    "| 欄位名稱               | 說明                                                                 |\n",
    "|------------------------|----------------------------------------------------------------------|\n",
    "| DATE                   | 當天的觀測日期                                                       |\n",
    "| PRECIPITATION          | 每日降水量（英吋）                                                   |\n",
    "| MAX_TEMP               | 每日最高氣溫（華氏）                                                 |\n",
    "| MIN_TEMP               | 每日最低氣溫（華氏）                                                 |\n",
    "| AVG_WIND_SPEED         | 每日平均風速（英里/小時）                                           |\n",
    "| FIRE_START_DAY         | 是否於該日發生野火（布林值：True/False）                            |\n",
    "| YEAR                   | 年份                                                                 |\n",
    "| TEMP_RANGE             | 當日最高與最低溫差，反映氣溫變化程度                                |\n",
    "| WIND_TEMP_RATIO        | 平均風速與最高溫度的比值，捕捉風與溫度間的動態關係                  |\n",
    "| MONTH                  | 月份（1–12）                                                        |\n",
    "| SEASON                 | 季節（Winter, Spring, Summer, Fall）                                |\n",
    "| LAGGED_PRECIPITATION   | 前 7 天的累積降水量，反映近一週的濕潤條件                            |\n",
    "| LAGGED_AVG_WIND_SPEED  | 前 7 天的平均風速，反映持續的風力狀況                                |\n",
    "| DAY_OF_YEAR            | 當年度中的天數（1–365 或 366）                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de57672e",
   "metadata": {},
   "source": [
    "<h5>\n",
    "\n",
    "- 對月份做 sin/cos 轉換  保留了數值間的連續性與週期性。\n",
    "  \n",
    "- 1 月與 12 月其實很接近，但 get_dummies() 會把它們視為完全無關。\n",
    "\n",
    "- 而 sin/cos 轉換會保留這種「循環性」。\n",
    "\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5005b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "df['MONTH_SIN'] = np.sin(2 * np.pi * df['MONTH'] / 12)\n",
    "df['MONTH_COS'] = np.cos(2 * np.pi * df['MONTH'] / 12)\n",
    "df['DOY_SIN'] = np.sin(2 * np.pi * df['DAY_OF_YEAR'] / 366)\n",
    "df['DOY_COS'] = np.cos(2 * np.pi * df['DAY_OF_YEAR'] / 366)\n",
    "\n",
    "df = df.drop(columns=['DATE', 'MONTH', 'DAY_OF_YEAR'])\n",
    "\n",
    "# 將 FIRE_START_DAY 轉為整數型（0 或 1）\n",
    "df['FIRE_START_DAY'] = df['FIRE_START_DAY'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9f3f57",
   "metadata": {},
   "source": [
    "<h5>\n",
    "\n",
    "- `PRECIPITATION`幾乎所有值都是 0（沒下雨），只有極少數是非零，所以我們轉成是否有下雨 \n",
    "\n",
    "- `TEMP_MEAN` 溫度範圍（TEMP_RANGE）差異滿大的，從 2 到 41，直接用溫度平均值，有時比分開的 MAX、MIN 更有區分力。\n",
    "\n",
    "</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670d37f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['IS_RAINING'] = (df['PRECIPITATION'] > 0).astype(int) #幾乎所有值都是 0（沒下雨），只有極少數是非零。\n",
    "df['TEMP_MEAN'] = (df['MAX_TEMP'] + df['MIN_TEMP'] / 2).astype(float) #溫度範圍（TEMP_RANGE）差異滿大的，從 2 到 41，直接用溫度平均值，有時比分開的 MAX、MIN 更有區分力。\n",
    "df = df.drop(columns=['MAX_TEMP', 'MIN_TEMP','LAGGED_PRECIPITATION'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0e13859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECIPITATION</th>\n",
       "      <th>AVG_WIND_SPEED</th>\n",
       "      <th>FIRE_START_DAY</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TEMP_RANGE</th>\n",
       "      <th>WIND_TEMP_RATIO</th>\n",
       "      <th>LAGGED_PRECIPITATION</th>\n",
       "      <th>LAGGED_AVG_WIND_SPEED</th>\n",
       "      <th>MONTH_SIN</th>\n",
       "      <th>MONTH_COS</th>\n",
       "      <th>DOY_SIN</th>\n",
       "      <th>DOY_COS</th>\n",
       "      <th>IS_RAINING</th>\n",
       "      <th>TEMP_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14987.000000</td>\n",
       "      <td>14976.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14987.000000</td>\n",
       "      <td>14976.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>1.498800e+04</td>\n",
       "      <td>1.498800e+04</td>\n",
       "      <td>1.498800e+04</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14987.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.032315</td>\n",
       "      <td>7.435098</td>\n",
       "      <td>0.331665</td>\n",
       "      <td>2004.016813</td>\n",
       "      <td>14.040902</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>0.226188</td>\n",
       "      <td>7.434198</td>\n",
       "      <td>-4.336929e-03</td>\n",
       "      <td>-1.308696e-03</td>\n",
       "      <td>8.899901e-05</td>\n",
       "      <td>-0.001207</td>\n",
       "      <td>0.092140</td>\n",
       "      <td>98.782044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.179544</td>\n",
       "      <td>2.129985</td>\n",
       "      <td>0.470827</td>\n",
       "      <td>11.843342</td>\n",
       "      <td>5.995327</td>\n",
       "      <td>0.035630</td>\n",
       "      <td>0.648705</td>\n",
       "      <td>1.387849</td>\n",
       "      <td>7.056530e-01</td>\n",
       "      <td>7.085902e-01</td>\n",
       "      <td>7.075638e-01</td>\n",
       "      <td>0.706696</td>\n",
       "      <td>0.289234</td>\n",
       "      <td>9.773213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1984.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.227143</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-9.999632e-01</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>68.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.085238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.518571</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-7.101350e-01</td>\n",
       "      <td>-0.704066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.102222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.478571</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-0.008583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>99.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2014.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.120462</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>8.278571</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>7.101350e-01</td>\n",
       "      <td>0.704066</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>105.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.530000</td>\n",
       "      <td>26.170000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2025.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.459123</td>\n",
       "      <td>8.180000</td>\n",
       "      <td>13.932857</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>9.999632e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>141.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRECIPITATION  AVG_WIND_SPEED  FIRE_START_DAY          YEAR  \\\n",
       "count   14987.000000    14976.000000    14988.000000  14988.000000   \n",
       "mean        0.032315        7.435098        0.331665   2004.016813   \n",
       "std         0.179544        2.129985        0.470827     11.843342   \n",
       "min         0.000000        1.790000        0.000000   1984.000000   \n",
       "25%         0.000000        6.040000        0.000000   1994.000000   \n",
       "50%         0.000000        7.160000        0.000000   2004.000000   \n",
       "75%         0.000000        8.500000        1.000000   2014.000000   \n",
       "max         4.530000       26.170000        1.000000   2025.000000   \n",
       "\n",
       "         TEMP_RANGE  WIND_TEMP_RATIO  LAGGED_PRECIPITATION  \\\n",
       "count  14987.000000     14976.000000          14988.000000   \n",
       "mean      14.040902         0.107019              0.226188   \n",
       "std        5.995327         0.035630              0.648705   \n",
       "min        2.000000         0.023553              0.000000   \n",
       "25%       10.000000         0.085238              0.000000   \n",
       "50%       12.000000         0.102222              0.000000   \n",
       "75%       17.000000         0.120462              0.060000   \n",
       "max       41.000000         0.459123              8.180000   \n",
       "\n",
       "       LAGGED_AVG_WIND_SPEED     MONTH_SIN     MONTH_COS       DOY_SIN  \\\n",
       "count           14988.000000  1.498800e+04  1.498800e+04  1.498800e+04   \n",
       "mean                7.434198 -4.336929e-03 -1.308696e-03  8.899901e-05   \n",
       "std                 1.387849  7.056530e-01  7.085902e-01  7.075638e-01   \n",
       "min                 3.227143 -1.000000e+00 -1.000000e+00 -9.999632e-01   \n",
       "25%                 6.518571 -8.660254e-01 -8.660254e-01 -7.101350e-01   \n",
       "50%                 7.478571 -2.449294e-16 -1.836970e-16  1.224647e-16   \n",
       "75%                 8.278571  5.000000e-01  8.660254e-01  7.101350e-01   \n",
       "max                13.932857  1.000000e+00  1.000000e+00  9.999632e-01   \n",
       "\n",
       "            DOY_COS    IS_RAINING     TEMP_MEAN  \n",
       "count  14988.000000  14988.000000  14987.000000  \n",
       "mean      -0.001207      0.092140     98.782044  \n",
       "std        0.706696      0.289234      9.773213  \n",
       "min       -1.000000      0.000000     68.500000  \n",
       "25%       -0.704066      0.000000     91.500000  \n",
       "50%       -0.008583      0.000000     99.000000  \n",
       "75%        0.704066      0.000000    105.500000  \n",
       "max        1.000000      1.000000    141.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0552091c",
   "metadata": {},
   "source": [
    "- 根據[NOAA](https://www.noaa.gov/noaa-wildfire)\n",
    "- 和[Climate](https://www.climate.gov/news-features/event-tracker/weather-and-climate-influences-january-2025-fires-around-los-angeles)\n",
    "\n",
    "- 1. 氣溫變異指數（Temperature Variation Index）  \n",
    "\n",
    "| **項目**      | **內容**                                                                                   |\n",
    "|---------------|--------------------------------------------------------------------------------------------|\n",
    "| **定義**      | 每日氣溫的變異程度，反映當天最高和最低氣溫之間的差異。較大的溫差可能與氣候極端性相關，進一步加劇火災風險。 |\n",
    "| **公式**      | `TEMP_VARIATION = MAX_TEMP - MIN_TEMP`                                                     |\n",
    "\n",
    "- 2. 降水與風速比率（Precipitation-Wind Ratio）  \n",
    "\n",
    "| **項目**      | **內容**                                                                                   |\n",
    "|---------------|--------------------------------------------------------------------------------------------|\n",
    "| **定義**      | 衡量降水量與風速之間的關聯。當降水量低且風速高時，通常意味著乾燥條件與強風並存，火災風險上升。            |\n",
    "| **公式**      | `PRECIPITATION_WIND_RATIO = PRECIPITATION / AVG_WIND_SPEED`                                |\n",
    "\n",
    "- 3. 季節性降水與風速關聯指數（Seasonal Precipitation-Wind Index）  \n",
    "\n",
    "| **項目**      | **內容**                                                                                   |\n",
    "|---------------|--------------------------------------------------------------------------------------------|\n",
    "| **定義**      | 綜合考量季節（SEASON）對降水與風速影響的指標。不同季節降水和風速的組合，會對火災風險產生不同作用。          |\n",
    "| **公式**      | `SEASONAL_PRECIP_WIND = (PRECIPITATION * (SEASON == 'Winter')) + (AVG_WIND_SPEED * (SEASON == 'Summer'))` |\n",
    "\n",
    "- 4. 季節性乾燥指數（Seasonal Dryness Index）  \n",
    "\n",
    "| **項目**      | **內容**                                                                                   |\n",
    "|---------------|--------------------------------------------------------------------------------------------|\n",
    "| **定義**      | 根據當季（秋季或冬季）的降水量與日溫差來評估乾燥程度。乾燥季節中的高乾燥值與火災風險高度相關。             |\n",
    "| **公式**      | `SEASONAL_DRYNESS = (PRECIPITATION * (SEASON == 'Fall' or SEASON == 'Winter')) / (MAX_TEMP - MIN_TEMP)` |\n",
    "\n",
    "- 5. 日中溫差與風速結合指數（Diurnal Temperature and Wind Speed Index） \n",
    "\n",
    "| **項目**      | **內容**                                                                                   |\n",
    "|---------------|--------------------------------------------------------------------------------------------|\n",
    "| **定義**      | 此指標將每日的氣溫差（即日間溫度變化）與風速結合，評估乾燥和高風速的條件下，火災風險的潛在性。            |\n",
    "| **公式**      | `DIURNAL_TEMP_WIND = (MAX_TEMP - MIN_TEMP) * AVG_WIND_SPEED` |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819cab74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------------\n",
    "# 我分析而得的衍生指標 :\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "df['PRECIPITATION_WIND_RATIO'] = df['PRECIPITATION'] / df['AVG_WIND_SPEED']\n",
    "df['SEASONAL_PRECIP_WIND'] = (df['PRECIPITATION'] * (df['SEASON'] == 'Winter')) + (df['AVG_WIND_SPEED'] * (df['SEASON'] == 'Summer'))\n",
    "df['SEASONAL_DRYNESS'] = (df['PRECIPITATION'] * ((df['SEASON'] == 'Fall') | (df['SEASON'] == 'Winter'))) / (df['MAX_TEMP'] - df['MIN_TEMP'])\n",
    "df['DIURNAL_TEMP_WIND'] = (df['MAX_TEMP'] - df['MIN_TEMP']) * df['AVG_WIND_SPEED']\n",
    "\n",
    "'''\n",
    "\n",
    "# One-Hot Encoding: SEASON\n",
    "df = pd.get_dummies(df, columns=['SEASON'])\n",
    "season_cols = ['SEASON_Fall', 'SEASON_Spring', 'SEASON_Summer', 'SEASON_Winter']\n",
    "df[season_cols] = df[season_cols].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54a4cee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特徵與目標分離\n",
    "X = df.drop(['FIRE_START_DAY'], axis=1)\n",
    "y = df['FIRE_START_DAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb46795",
   "metadata": {},
   "source": [
    "2. 數值特徵標準化（Standardization）\n",
    "為避免某些欄位（如溫度或風速）對模型訓練造成不公平的權重，我們可以對所有數值特徵做 **Z-score** 標準化 **（均值為0，標準差為1）**，但不包含 One-Hot 欄位。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38bb768e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom sklearn.preprocessing import StandardScaler\\n\\n# 找出所有數值欄位（排除 one-hot 和目標變數）\\nnumeric_cols = X.select_dtypes(include=['float64', 'int64']).columns\\n\\n# 建立標準化物件並套用於訓練集和測試集\\nscaler = StandardScaler()\\nX[numeric_cols] = scaler.fit_transform(X[numeric_cols])\\n\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 找出所有數值欄位（排除 one-hot 和目標變數）\n",
    "numeric_cols = X.select_dtypes(include=['float64', 'int64']).columns\n",
    "\n",
    "# 建立標準化物件並套用於訓練集和測試集\n",
    "scaler = StandardScaler()\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23b7cd9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14988 entries, 0 to 14987\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   PRECIPITATION          14987 non-null  float64\n",
      " 1   AVG_WIND_SPEED         14976 non-null  float64\n",
      " 2   YEAR                   14988 non-null  int64  \n",
      " 3   TEMP_RANGE             14987 non-null  float64\n",
      " 4   WIND_TEMP_RATIO        14976 non-null  float64\n",
      " 5   LAGGED_PRECIPITATION   14988 non-null  float64\n",
      " 6   LAGGED_AVG_WIND_SPEED  14988 non-null  float64\n",
      " 7   MONTH_SIN              14988 non-null  float64\n",
      " 8   MONTH_COS              14988 non-null  float64\n",
      " 9   DOY_SIN                14988 non-null  float64\n",
      " 10  DOY_COS                14988 non-null  float64\n",
      " 11  IS_RAINING             14988 non-null  int64  \n",
      " 12  TEMP_MEAN              14987 non-null  float64\n",
      " 13  SEASON_Fall            14988 non-null  bool   \n",
      " 14  SEASON_Spring          14988 non-null  bool   \n",
      " 15  SEASON_Summer          14988 non-null  bool   \n",
      " 16  SEASON_Winter          14988 non-null  bool   \n",
      "dtypes: bool(4), float64(11), int64(2)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "940a74e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRECIPITATION             1\n",
      "AVG_WIND_SPEED           12\n",
      "YEAR                      0\n",
      "TEMP_RANGE                1\n",
      "WIND_TEMP_RATIO          12\n",
      "LAGGED_PRECIPITATION      0\n",
      "LAGGED_AVG_WIND_SPEED     0\n",
      "MONTH_SIN                 0\n",
      "MONTH_COS                 0\n",
      "DOY_SIN                   0\n",
      "DOY_COS                   0\n",
      "IS_RAINING                0\n",
      "TEMP_MEAN                 1\n",
      "SEASON_Fall               0\n",
      "SEASON_Spring             0\n",
      "SEASON_Summer             0\n",
      "SEASON_Winter             0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.isna().sum())\n",
    "X = X.fillna(X.median())\n",
    "assert X.isna().sum().sum() == 0, \"There are still missing values in the dataset.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d995ff04",
   "metadata": {},
   "source": [
    "### 切割資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e398ca44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ba4b1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIRE_START_DAY\n",
      "0    0.668335\n",
      "1    0.331665\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ca0142e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECIPITATION</th>\n",
       "      <th>AVG_WIND_SPEED</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>TEMP_RANGE</th>\n",
       "      <th>WIND_TEMP_RATIO</th>\n",
       "      <th>LAGGED_PRECIPITATION</th>\n",
       "      <th>LAGGED_AVG_WIND_SPEED</th>\n",
       "      <th>MONTH_SIN</th>\n",
       "      <th>MONTH_COS</th>\n",
       "      <th>DOY_SIN</th>\n",
       "      <th>DOY_COS</th>\n",
       "      <th>IS_RAINING</th>\n",
       "      <th>TEMP_MEAN</th>\n",
       "      <th>SEASON_Fall</th>\n",
       "      <th>SEASON_Spring</th>\n",
       "      <th>SEASON_Summer</th>\n",
       "      <th>SEASON_Winter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.61</td>\n",
       "      <td>2016</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.093951</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.277143</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.944489</td>\n",
       "      <td>-0.328542</td>\n",
       "      <td>0</td>\n",
       "      <td>110.5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1997</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.114865</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.414286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.710135</td>\n",
       "      <td>-0.704066</td>\n",
       "      <td>0</td>\n",
       "      <td>105.5</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1572</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.50</td>\n",
       "      <td>1988</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.132812</td>\n",
       "      <td>0.68</td>\n",
       "      <td>10.674286</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.938710</td>\n",
       "      <td>-0.344707</td>\n",
       "      <td>0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>10.07</td>\n",
       "      <td>2019</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.139861</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8.245714</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.320423</td>\n",
       "      <td>-0.947274</td>\n",
       "      <td>0</td>\n",
       "      <td>103.5</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>1986</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.113380</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7.350000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.551102</td>\n",
       "      <td>-0.834438</td>\n",
       "      <td>0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRECIPITATION  AVG_WIND_SPEED  YEAR  TEMP_RANGE  WIND_TEMP_RATIO  \\\n",
       "11798            0.0            7.61  2016        22.0         0.093951   \n",
       "4885             0.0            8.50  1997        11.0         0.114865   \n",
       "1572             0.0            8.50  1988        14.0         0.132812   \n",
       "12985            0.0           10.07  2019         9.0         0.139861   \n",
       "879              0.0            8.05  1986        11.0         0.113380   \n",
       "\n",
       "       LAGGED_PRECIPITATION  LAGGED_AVG_WIND_SPEED  MONTH_SIN  MONTH_COS  \\\n",
       "11798                  0.00               8.277143   0.866025  -0.500000   \n",
       "4885                   0.00               7.414286   0.500000  -0.866025   \n",
       "1572                   0.68              10.674286   0.866025  -0.500000   \n",
       "12985                  0.00               8.245714  -0.500000  -0.866025   \n",
       "879                    0.00               7.350000   0.500000  -0.866025   \n",
       "\n",
       "        DOY_SIN   DOY_COS  IS_RAINING  TEMP_MEAN  SEASON_Fall  SEASON_Spring  \\\n",
       "11798  0.944489 -0.328542           0      110.5        False           True   \n",
       "4885   0.710135 -0.704066           0      105.5        False           True   \n",
       "1572   0.938710 -0.344707           0       89.0        False           True   \n",
       "12985 -0.320423 -0.947274           0      103.5        False          False   \n",
       "879    0.551102 -0.834438           0      101.0        False           True   \n",
       "\n",
       "       SEASON_Summer  SEASON_Winter  \n",
       "11798          False          False  \n",
       "4885           False          False  \n",
       "1572           False          False  \n",
       "12985           True          False  \n",
       "879            False          False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75fdb62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/ygz08/Desktop/Git/localgit/MLOPs/Predictable_wildfire/mlruns/995565665349288736', creation_time=1746261086177, experiment_id='995565665349288736', last_update_time=1746261086177, lifecycle_stage='active', name='CA_Weather_Fire', tags={}>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "mlflow.set_experiment(\"CA_Weather_Fire\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4699d0fc",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7e192d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in run d3a7caf625864e4090a66b75d4c8f4bf\n",
      "Train score: 0.751691926413116\n",
      "Test score: 0.7511674449633089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 16:12:40 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.73      0.80      3047\n",
      "           1       0.58      0.80      0.67      1450\n",
      "\n",
      "    accuracy                           0.75      4497\n",
      "   macro avg       0.73      0.76      0.74      4497\n",
      "weighted avg       0.79      0.75      0.76      4497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'LogisticRegression-model' already exists. Creating a new version of this model...\n",
      "Created version '11' of model 'LogisticRegression-model'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "with mlflow.start_run(run_name='LogisticRegression'):#mlflow\n",
    "    mlflow.tensorflow.autolog()#mlflow\n",
    "    max_iter=1000 \n",
    "    #mlflow.log_param(\"max_iter\", max_iter) #mlflow紀錄參數n_estimators\n",
    "# 方法四：使用 class_weight='balanced'\n",
    "    log_reg = LogisticRegression(max_iter=max_iter, class_weight='balanced')\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    run_id = mlflow.active_run().info.run_id#mlflow\n",
    "    print(f\"Model saved in run {run_id}\")#mlflow\n",
    "    \n",
    "\n",
    "    # 檢查訓練與測試分數\n",
    "    print(\"Train score:\", log_reg.score(X_train, y_train))\n",
    "    print(\"Test score:\", log_reg.score(X_test, y_test))\n",
    "\n",
    "    mlflow.log_metric(\"Train score\", log_reg.score(X_train, y_train))#mlflow\n",
    "    mlflow.log_metric(\"Test score\", log_reg.score(X_test, y_test))#mlflow\n",
    "\n",
    "\n",
    "    # 存檔模型mlflow\n",
    "    model_name = \"LogisticRegression-model\"\n",
    "    mlflow.sklearn.log_model(     #mlflow.sklearn.log_model() #紀錄sklearn模型\n",
    "        sk_model=log_reg, \n",
    "        artifact_path=\"LogisticRegression-model\",\n",
    "        registered_model_name=model_name,  #\n",
    "    )\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, log_reg.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6357f43d",
   "metadata": {},
   "source": [
    "✅ 模型優點\n",
    "- 對「有火災」的 recall 很高：0.80\n",
    "    - 表示你抓到 80% 的火災案例，這對野火預測是關鍵（比 precision 更重要）。\n",
    "- f1-score 有火災類別也達到 0.67，代表整體模型並不差。\n",
    "\n",
    "⚠️ 模型限制\n",
    "- precision 只有 0.58，也就是說：\n",
    "    - 模型預測「有火災」的案例中，有 42% 是誤報（false positive）。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc8e488",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a8927047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in run 83f9e1397f6c4b18aaade5c87e2d8f07\n",
      "Train score: 0.9454770755885997\n",
      "Test score: 0.7894151656659996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 16:38:06 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      3047\n",
      "           1       0.67      0.69      0.68      1450\n",
      "\n",
      "    accuracy                           0.79      4497\n",
      "   macro avg       0.76      0.76      0.76      4497\n",
      "weighted avg       0.79      0.79      0.79      4497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'RandomForest-model' already exists. Creating a new version of this model...\n",
      "Created version '8' of model 'RandomForest-model'.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "with mlflow.start_run(run_name='RandomForest'):#mlflow\n",
    "    mlflow.tensorflow.autolog()#mlflow\n",
    "    #max_iter=1000 \n",
    "    #mlflow.log_param(\"max_iter\", max_iter) #mlflow紀錄參數n_estimators\n",
    "# 方法四：使用 class_weight='balanced'\n",
    "    #rf = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
    "    rf = RandomForestClassifier(n_estimators=150, max_depth=15, class_weight='balanced')\n",
    "    rf.fit(X_train, y_train)\n",
    "    run_id = mlflow.active_run().info.run_id#mlflow\n",
    "    print(f\"Model saved in run {run_id}\")#mlflow\n",
    "    \n",
    "\n",
    "    # 檢查訓練與測試分數\n",
    "    print(\"Train score:\", rf.score(X_train, y_train))\n",
    "    print(\"Test score:\", rf.score(X_test, y_test))\n",
    "\n",
    "    mlflow.log_metric(\"Train score\", rf.score(X_train, y_train))#mlflow\n",
    "    mlflow.log_metric(\"Test score\", rf.score(X_test, y_test))#mlflow\n",
    "\n",
    "\n",
    "    # 存檔模型mlflow\n",
    "    model_name = \"RandomForest-model\"\n",
    "    mlflow.sklearn.log_model(     #mlflow.sklearn.log_model() #紀錄sklearn模型\n",
    "        sk_model=rf, \n",
    "        artifact_path=\"RandomForest-model\",\n",
    "        registered_model_name=model_name,  #\n",
    "    )\n",
    "    \n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, rf.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a23773b6",
   "metadata": {},
   "source": [
    "### 模型評估 :\n",
    "- Before Tuning\n",
    "  - **Train score: 1.0**\n",
    "  - **Test score: 0.7883033133199912**\n",
    "  - **accuracy  0.79**\n",
    "\n",
    "✅ 模型優勢\n",
    "- 對無火災類別（0）有較高的 precision 和 recall，尤其 recall 高達 0.88，模型能夠準確地識別大部分「無火災」的情況。\n",
    "- f1-score 達到了 0.85，代表模型對「無火災」的預測表現非常好。\n",
    "\n",
    "⚠️ 模型的挑戰\n",
    "- 對有火災（1）類別，precision 是 0.70，而 recall 只有 0.60，這意味著：\n",
    "    - 對有火災的預測還有進步空間，模型錯過了一部分火災案例，這對於防火系統來說是很關鍵的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67925d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "                   n_iter=30, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [None, 5, 10, 20, 30],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   random_state=42, scoring=&#x27;roc_auc&#x27;, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomizedSearchCV</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\">?<span>Documentation for RandomizedSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "                   n_iter=30, n_jobs=-1,\n",
       "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
       "                                        &#x27;max_depth&#x27;: [None, 5, 10, 20, 30],\n",
       "                                        &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                                        &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                                        &#x27;n_estimators&#x27;: [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   random_state=42, scoring=&#x27;roc_auc&#x27;, verbose=1)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>best_estimator_: RandomForestClassifier</div></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=10,\n",
       "                       n_estimators=300, random_state=42)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class=\"sk-toggleable__content fitted\"><pre>RandomForestClassifier(max_depth=10, min_samples_leaf=2, min_samples_split=10,\n",
       "                       n_estimators=300, random_state=42)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "                   n_iter=30, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [None, 5, 10, 20, 30],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [100, 200, 300, 400,\n",
       "                                                         500]},\n",
       "                   random_state=42, scoring='roc_auc', verbose=1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tuned Random Forest¶\n",
    "from sklearn.model_selection import  RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Set up the search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(random_state=42),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit search\n",
    "random_search.fit(X_train, y_train)a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef60dd84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best Random Forest (Tuned) ---\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      3047\n",
      "           1       0.70      0.65      0.68      1450\n",
      "\n",
      "    accuracy                           0.80      4497\n",
      "   macro avg       0.77      0.76      0.76      4497\n",
      "weighted avg       0.79      0.80      0.80      4497\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2644  403]\n",
      " [ 506  944]]\n",
      "ROC AUC Score: 0.8581001097744532\n"
     ]
    }
   ],
   "source": [
    "# Get the best model\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "best_rf = random_search.best_estimator_\n",
    "\n",
    "# Predict\n",
    "y_pred_best_rf = best_rf.predict(X_test)\n",
    "y_proba_best_rf = best_rf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluation\n",
    "print(\"--- Best Random Forest (Tuned) ---\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_best_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best_rf))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_proba_best_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e0cd7f",
   "metadata": {},
   "source": [
    "### 結果分析：\n",
    "- After Tuning\n",
    "  - **accuracy  0.8**\n",
    "  - **ROC AUC  0.858**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a642742d",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## XG Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af317904",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [16:23:57] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"class_weight\", \"lambda_\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved in run 9e9d679c113c40a18cab588059d55060\n",
      "Train score: 0.8434848918120293\n",
      "Test score: 0.7954191683344451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 16:24:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      3047\n",
      "           1       0.70      0.64      0.67      1450\n",
      "\n",
      "    accuracy                           0.80      4497\n",
      "   macro avg       0.77      0.76      0.76      4497\n",
      "weighted avg       0.79      0.80      0.79      4497\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'XGBClassifier-model' already exists. Creating a new version of this model...\n",
      "Created version '6' of model 'XGBClassifier-model'.\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "#Train score: 0.9090649127823849\n",
    "#Test score: 0.7820769401823437\n",
    "\n",
    "with mlflow.start_run(run_name='XGBClassifier'):#mlflow\n",
    "    mlflow.tensorflow.autolog()#mlflow\n",
    "    max_iter=1000 \n",
    "    #mlflow.log_param(\"max_iter\", max_iter) #mlflow紀錄參數n_estimators\n",
    "# 方法四：使用 class_weight='balanced'\n",
    "    xgb = XGBClassifier(\n",
    "        random_state=42, \n",
    "        class_weight='balanced',  # 對不平衡數據進行調整\n",
    "        alpha=0.1,  # L1 正則化強度，通常設為較小的正值\n",
    "        lambda_=1.0,  # L2 正則化強度，默認為1\n",
    "        n_estimators=100,  # 樹的數量\n",
    "        max_depth=6,  # 每棵樹的最大深度\n",
    "        learning_rate=0.1  # 學習率\n",
    "    )\n",
    "    xgb.fit(X_train, y_train)\n",
    "    run_id = mlflow.active_run().info.run_id#mlflow\n",
    "    print(f\"Model saved in run {run_id}\")#mlflow\n",
    "    \n",
    "\n",
    "    # 檢查訓練與測試分數\n",
    "    print(\"Train score:\", xgb.score(X_train, y_train))\n",
    "    print(\"Test score:\", xgb.score(X_test, y_test))\n",
    "\n",
    "    mlflow.log_metric(\"Train score\", xgb.score(X_train, y_train))#mlflow\n",
    "    mlflow.log_metric(\"Test score\", xgb.score(X_test, y_test))#mlflow\n",
    "\n",
    "\n",
    "    # 存檔模型mlflow\n",
    "    model_name = \"XGBClassifier-model\"\n",
    "    mlflow.sklearn.log_model(     #mlflow.sklearn.log_model() #紀錄sklearn模型\n",
    "        sk_model=xgb, \n",
    "        artifact_path=\"XGBClassifier-model\",\n",
    "        registered_model_name=model_name,  #\n",
    "    )\n",
    "\n",
    "    from sklearn.metrics import classification_report\n",
    "    print(classification_report(y_test, xgb.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03f2226",
   "metadata": {},
   "source": [
    "### 模型評估：\n",
    "\n",
    "- 精度 (Precision)：對於類別 0（負樣本），精度達到 0.84，對於類別 1（正樣本），精度為 0.70。這意味著模型在預測正樣本時可能有一些錯誤，可能會錯誤地標記一些負樣本為正樣本。\n",
    "\n",
    "- 召回率 (Recall)：對於類別 0，召回率為 0.87，這是比較好的，說明模型能夠正確標記大部分的負樣本。然而，對於類別 1，召回率是 0.64，意味著有相當一部分的正樣本未被成功預測出來，這可能是過擬合的跡象或者模型對某些特徵不夠敏感。\n",
    "\n",
    "- F1-score：在平衡精度和召回率後，類別 0 的 F1-score 是 0.85，而類別 1 的 F1-score 是 0.67，這表明模型對於類別 0 的預測表現要好於類別 1。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f7d0005b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1725fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\training.py:183: UserWarning: [16:26:55] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"lambda_\", \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "# 2) Tuned XGBoost via RandomizedSearchCV\n",
    "param_dist_xgb = {\n",
    "    'alpha' : [0.0, 0.1, 0.5, 1.0, 2.0],  # L1 正則化強度，通常設為較小的正值\n",
    "    'lambda_' : [0.0, 0.1, 0.5, 1.0, 2.0],  # L2 正則化強度，默認為1\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [3, 5, 7, 10, 15],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.5],\n",
    "    'min_child_weight': [1, 3, 5]\n",
    "}\n",
    "\n",
    "xgb_search = RandomizedSearchCV(\n",
    "    estimator=XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss'),\n",
    "    param_distributions=param_dist_xgb,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='roc_auc',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit search\n",
    "xgb_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_xgb = xgb_search.best_estimator_\n",
    "\n",
    "# Predict with best model\n",
    "y_pred_best_xgb = best_xgb.predict(X_test)\n",
    "y_proba_best_xgb = best_xgb.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "37a2d98a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Best XGBoost (Tuned) ---\n",
      "Best Parameters: {'subsample': 0.8, 'n_estimators': 500, 'min_child_weight': 1, 'max_depth': 7, 'learning_rate': 0.01, 'lambda_': 0.1, 'gamma': 0.1, 'colsample_bytree': 1.0, 'alpha': 0.5}\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      3047\n",
      "           1       0.70      0.65      0.67      1450\n",
      "\n",
      "    accuracy                           0.80      4497\n",
      "   macro avg       0.77      0.76      0.76      4497\n",
      "weighted avg       0.79      0.80      0.79      4497\n",
      "\n",
      "Confusion Matrix:\n",
      " [[2636  411]\n",
      " [ 510  940]]\n",
      "ROC AUC Score: 0.8619060013806683\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, roc_auc_score\n",
    "print(\"--- Best XGBoost (Tuned) ---\")\n",
    "print(\"Best Parameters:\", xgb_search.best_params_)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_best_xgb))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_best_xgb))\n",
    "print(\"ROC AUC Score:\", roc_auc_score(y_test, y_proba_best_xgb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9abc23bd",
   "metadata": {},
   "source": [
    "### 結果分析：\n",
    "- 精度 (Precision)：\n",
    "\n",
    "    - 類別 0（沒有野火發生） precision: 0.84，這表明大部分被預測為沒有野火的樣本確實是沒有野火。\n",
    "\n",
    "    - 類別 1（有野火發生） precision: 0.70，這表示模型對於有野火的預測並不如對無野火的預測準確。\n",
    "\n",
    "- 召回率 (Recall)：\n",
    "\n",
    "    - 類別 0 recall: 0.87，這說明模型能夠有效地捕捉到大多數沒有野火的樣本。\n",
    "\n",
    "    - 類別 1 recall: 0.65，這表示對有野火的預測仍然有改進的空間，可能是因為過擬合或特徵選擇不夠充分。\n",
    "\n",
    "- F1 分數 (F1-Score)：\n",
    "\n",
    "    - 類別 0 F1-Score: 0.85，這說明對類別 0 的預測效果良好。\n",
    "\n",
    "    - 類別 1 F1-Score: 0.67，這顯示對類別 1 的預測仍然有提升的空間，可能需要更多針對該類別的特徵或優化。\n",
    "\n",
    "- ROC AUC Score：0.8619，這是衡量模型區分能力的指標，值較高，說明模型對區分兩類有較好的能力。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac104a58",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7cdc51c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.regularizers import l1, l2, l1_l2\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f576b002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {np.int64(0): np.float64(0.7525824964131994), np.int64(1): np.float64(1.4897756319227493)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "# 查看結果\n",
    "print(\"Class Weights:\", class_weight_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46c0601b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_1           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ batch_normalization_1           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 16:34:08 WARNING mlflow.tensorflow: Encountered unexpected error while inferring batch size from training dataset: Sequential model 'sequential_1' has no defined input shape yet.\n",
      "2025/05/04 16:34:08 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'pandas.core.frame.DataFrame'>. Dataset logging skipped.\n",
      "2025/05/04 16:34:08 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'DataFrame' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.5738 - Recall: 0.7428 - acc: 0.7326 - loss: 1.0362"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - Precision: 0.5740 - Recall: 0.7433 - acc: 0.7327 - loss: 1.0350 - val_Precision: 0.3224 - val_Recall: 1.0000 - val_acc: 0.3224 - val_loss: 14.8866\n",
      "Epoch 2/100\n",
      "\u001b[1m77/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6017 - Recall: 0.8134 - acc: 0.7526 - loss: 0.7531"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6014 - Recall: 0.8129 - acc: 0.7526 - loss: 0.7511 - val_Precision: 0.3227 - val_Recall: 1.0000 - val_acc: 0.3231 - val_loss: 3.1040\n",
      "Epoch 3/100\n",
      "\u001b[1m79/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.5989 - Recall: 0.7870 - acc: 0.7558 - loss: 0.6465"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.5993 - Recall: 0.7872 - acc: 0.7559 - loss: 0.6457 - val_Precision: 0.3253 - val_Recall: 1.0000 - val_acc: 0.3311 - val_loss: 1.9589\n",
      "Epoch 4/100\n",
      "\u001b[1m80/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.5994 - Recall: 0.8117 - acc: 0.7549 - loss: 0.5864"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.5994 - Recall: 0.8115 - acc: 0.7549 - loss: 0.5862 - val_Precision: 0.4625 - val_Recall: 0.9186 - val_acc: 0.6295 - val_loss: 0.7851\n",
      "Epoch 5/100\n",
      "\u001b[1m72/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6146 - Recall: 0.7788 - acc: 0.7551 - loss: 0.5631"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6138 - Recall: 0.7807 - acc: 0.7557 - loss: 0.5619 - val_Precision: 0.4985 - val_Recall: 0.8952 - val_acc: 0.6758 - val_loss: 0.7393\n",
      "Epoch 6/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6058 - Recall: 0.7998 - acc: 0.7634 - loss: 0.5297"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - Precision: 0.6058 - Recall: 0.7999 - acc: 0.7634 - loss: 0.5297 - val_Precision: 0.5462 - val_Recall: 0.8517 - val_acc: 0.7240 - val_loss: 0.6011\n",
      "Epoch 7/100\n",
      "\u001b[1m78/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6011 - Recall: 0.7959 - acc: 0.7579 - loss: 0.5289"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6015 - Recall: 0.7962 - acc: 0.7580 - loss: 0.5287 - val_Precision: 0.5856 - val_Recall: 0.8138 - val_acc: 0.7543 - val_loss: 0.5466\n",
      "Epoch 8/100\n",
      "\u001b[1m78/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6101 - Recall: 0.8052 - acc: 0.7626 - loss: 0.5182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6097 - Recall: 0.8049 - acc: 0.7623 - loss: 0.5184 - val_Precision: 0.5951 - val_Recall: 0.7814 - val_acc: 0.7581 - val_loss: 0.5117\n",
      "Epoch 9/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6054 - Recall: 0.7920 - acc: 0.7558 - loss: 0.5237 - val_Precision: 0.5876 - val_Recall: 0.8048 - val_acc: 0.7549 - val_loss: 0.5310\n",
      "Epoch 10/100\n",
      "\u001b[1m68/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6077 - Recall: 0.7852 - acc: 0.7550 - loss: 0.5158"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6080 - Recall: 0.7871 - acc: 0.7557 - loss: 0.5146 - val_Precision: 0.6047 - val_Recall: 0.7924 - val_acc: 0.7661 - val_loss: 0.5010\n",
      "Epoch 11/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.6096 - Recall: 0.8035 - acc: 0.7634 - loss: 0.5080 - val_Precision: 0.5883 - val_Recall: 0.8021 - val_acc: 0.7552 - val_loss: 0.5294\n",
      "Epoch 12/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6173 - Recall: 0.8037 - acc: 0.7631 - loss: 0.5003 - val_Precision: 0.6060 - val_Recall: 0.7745 - val_acc: 0.7650 - val_loss: 0.5041\n",
      "Epoch 13/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6154 - Recall: 0.7994 - acc: 0.7635 - loss: 0.5052 - val_Precision: 0.6131 - val_Recall: 0.7607 - val_acc: 0.7681 - val_loss: 0.5025\n",
      "Epoch 14/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6065 - Recall: 0.7796 - acc: 0.7610 - loss: 0.5043 - val_Precision: 0.5659 - val_Recall: 0.8352 - val_acc: 0.7403 - val_loss: 0.5417\n",
      "Epoch 15/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.5955 - Recall: 0.8077 - acc: 0.7548 - loss: 0.5039 - val_Precision: 0.5931 - val_Recall: 0.7972 - val_acc: 0.7583 - val_loss: 0.5149\n",
      "Epoch 16/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6129 - Recall: 0.8035 - acc: 0.7642 - loss: 0.5074 - val_Precision: 0.5923 - val_Recall: 0.7924 - val_acc: 0.7572 - val_loss: 0.5087\n",
      "Epoch 17/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6168 - Recall: 0.8078 - acc: 0.7656 - loss: 0.4961 - val_Precision: 0.6099 - val_Recall: 0.7848 - val_acc: 0.7687 - val_loss: 0.5028\n",
      "Epoch 18/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6182 - Recall: 0.7975 - acc: 0.7679 - loss: 0.5009 - val_Precision: 0.5968 - val_Recall: 0.7993 - val_acc: 0.7612 - val_loss: 0.5125\n",
      "Epoch 19/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6096 - Recall: 0.8092 - acc: 0.7617 - loss: 0.5056 - val_Precision: 0.5718 - val_Recall: 0.8379 - val_acc: 0.7454 - val_loss: 0.5273\n",
      "Epoch 20/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6016 - Recall: 0.8080 - acc: 0.7551 - loss: 0.5066 - val_Precision: 0.5823 - val_Recall: 0.8124 - val_acc: 0.7516 - val_loss: 0.5205\n",
      "Epoch 21/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6006 - Recall: 0.8220 - acc: 0.7572 - loss: 0.4909 - val_Precision: 0.5924 - val_Recall: 0.8000 - val_acc: 0.7581 - val_loss: 0.5138\n",
      "Epoch 22/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6059 - Recall: 0.7988 - acc: 0.7617 - loss: 0.5016 - val_Precision: 0.5692 - val_Recall: 0.8366 - val_acc: 0.7432 - val_loss: 0.5410\n",
      "Epoch 23/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.5993 - Recall: 0.8075 - acc: 0.7570 - loss: 0.5013 - val_Precision: 0.5909 - val_Recall: 0.8028 - val_acc: 0.7572 - val_loss: 0.5113\n",
      "Epoch 24/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6064 - Recall: 0.7941 - acc: 0.7585 - loss: 0.5028 - val_Precision: 0.5907 - val_Recall: 0.8014 - val_acc: 0.7569 - val_loss: 0.5170\n",
      "Epoch 25/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6050 - Recall: 0.7965 - acc: 0.7589 - loss: 0.4964 - val_Precision: 0.5847 - val_Recall: 0.8090 - val_acc: 0.7532 - val_loss: 0.5120\n",
      "Epoch 26/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6078 - Recall: 0.8026 - acc: 0.7610 - loss: 0.4927 - val_Precision: 0.5877 - val_Recall: 0.8131 - val_acc: 0.7558 - val_loss: 0.5203\n",
      "Epoch 27/100\n",
      "\u001b[1m80/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6037 - Recall: 0.8094 - acc: 0.7576 - loss: 0.4986"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6039 - Recall: 0.8092 - acc: 0.7577 - loss: 0.4986 - val_Precision: 0.6082 - val_Recall: 0.7848 - val_acc: 0.7676 - val_loss: 0.4971\n",
      "Epoch 28/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6198 - Recall: 0.8086 - acc: 0.7702 - loss: 0.4899 - val_Precision: 0.5716 - val_Recall: 0.8310 - val_acc: 0.7447 - val_loss: 0.5153\n",
      "Epoch 29/100\n",
      "\u001b[1m68/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6141 - Recall: 0.7929 - acc: 0.7727 - loss: 0.4791"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6136 - Recall: 0.7940 - acc: 0.7707 - loss: 0.4825 - val_Precision: 0.6056 - val_Recall: 0.7910 - val_acc: 0.7665 - val_loss: 0.4917\n",
      "Epoch 30/100\n",
      "\u001b[1m77/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6101 - Recall: 0.7920 - acc: 0.7565 - loss: 0.5080"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6101 - Recall: 0.7927 - acc: 0.7568 - loss: 0.5074 - val_Precision: 0.6133 - val_Recall: 0.7690 - val_acc: 0.7692 - val_loss: 0.4876\n",
      "Epoch 31/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6111 - Recall: 0.7766 - acc: 0.7568 - loss: 0.5096 - val_Precision: 0.6042 - val_Recall: 0.7876 - val_acc: 0.7652 - val_loss: 0.4987\n",
      "Epoch 32/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6192 - Recall: 0.8031 - acc: 0.7641 - loss: 0.4987 - val_Precision: 0.6105 - val_Recall: 0.7697 - val_acc: 0.7674 - val_loss: 0.4890\n",
      "Epoch 33/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6136 - Recall: 0.7811 - acc: 0.7671 - loss: 0.5006 - val_Precision: 0.5873 - val_Recall: 0.8028 - val_acc: 0.7545 - val_loss: 0.5019\n",
      "Epoch 34/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6199 - Recall: 0.8066 - acc: 0.7643 - loss: 0.4931 - val_Precision: 0.5845 - val_Recall: 0.8090 - val_acc: 0.7529 - val_loss: 0.5066\n",
      "Epoch 35/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6037 - Recall: 0.8028 - acc: 0.7554 - loss: 0.5010 - val_Precision: 0.5861 - val_Recall: 0.8124 - val_acc: 0.7545 - val_loss: 0.5175\n",
      "Epoch 36/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6173 - Recall: 0.8134 - acc: 0.7679 - loss: 0.4879 - val_Precision: 0.5799 - val_Recall: 0.8262 - val_acc: 0.7509 - val_loss: 0.5251\n",
      "Epoch 37/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6062 - Recall: 0.8006 - acc: 0.7595 - loss: 0.4971 - val_Precision: 0.5927 - val_Recall: 0.8028 - val_acc: 0.7585 - val_loss: 0.5079\n",
      "Epoch 38/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6125 - Recall: 0.8027 - acc: 0.7634 - loss: 0.4925 - val_Precision: 0.5810 - val_Recall: 0.8159 - val_acc: 0.7509 - val_loss: 0.5156\n",
      "Epoch 39/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6209 - Recall: 0.8043 - acc: 0.7691 - loss: 0.4874"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.6208 - Recall: 0.8042 - acc: 0.7690 - loss: 0.4876 - val_Precision: 0.6077 - val_Recall: 0.7745 - val_acc: 0.7661 - val_loss: 0.4815\n",
      "Epoch 40/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6142 - Recall: 0.8128 - acc: 0.7639 - loss: 0.4925 - val_Precision: 0.5884 - val_Recall: 0.8055 - val_acc: 0.7556 - val_loss: 0.5094\n",
      "Epoch 41/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6139 - Recall: 0.8123 - acc: 0.7681 - loss: 0.4889 - val_Precision: 0.6044 - val_Recall: 0.7903 - val_acc: 0.7656 - val_loss: 0.4931\n",
      "Epoch 42/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6128 - Recall: 0.7946 - acc: 0.7630 - loss: 0.4994 - val_Precision: 0.5901 - val_Recall: 0.8014 - val_acc: 0.7565 - val_loss: 0.5067\n",
      "Epoch 43/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6105 - Recall: 0.8055 - acc: 0.7661 - loss: 0.4931 - val_Precision: 0.5720 - val_Recall: 0.8331 - val_acc: 0.7452 - val_loss: 0.5271\n",
      "Epoch 44/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6137 - Recall: 0.8104 - acc: 0.7622 - loss: 0.4949 - val_Precision: 0.5908 - val_Recall: 0.8145 - val_acc: 0.7583 - val_loss: 0.5079\n",
      "Epoch 45/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6060 - Recall: 0.8053 - acc: 0.7603 - loss: 0.4954 - val_Precision: 0.5802 - val_Recall: 0.8179 - val_acc: 0.7505 - val_loss: 0.5337\n",
      "Epoch 46/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6170 - Recall: 0.8063 - acc: 0.7641 - loss: 0.4993 - val_Precision: 0.6052 - val_Recall: 0.7814 - val_acc: 0.7652 - val_loss: 0.4941\n",
      "Epoch 47/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6110 - Recall: 0.8105 - acc: 0.7648 - loss: 0.4958 - val_Precision: 0.6124 - val_Recall: 0.7648 - val_acc: 0.7681 - val_loss: 0.4936\n",
      "Epoch 48/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6169 - Recall: 0.7922 - acc: 0.7653 - loss: 0.4986 - val_Precision: 0.5921 - val_Recall: 0.7979 - val_acc: 0.7576 - val_loss: 0.5072\n",
      "Epoch 49/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6156 - Recall: 0.8074 - acc: 0.7669 - loss: 0.4918 - val_Precision: 0.6033 - val_Recall: 0.7952 - val_acc: 0.7654 - val_loss: 0.5004\n",
      "Epoch 50/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6191 - Recall: 0.8059 - acc: 0.7675 - loss: 0.5000 - val_Precision: 0.6170 - val_Recall: 0.7655 - val_acc: 0.7712 - val_loss: 0.4875\n",
      "Epoch 51/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6237 - Recall: 0.8057 - acc: 0.7702 - loss: 0.4937 - val_Precision: 0.6020 - val_Recall: 0.7752 - val_acc: 0.7623 - val_loss: 0.4919\n",
      "Epoch 52/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6167 - Recall: 0.7909 - acc: 0.7666 - loss: 0.4947 - val_Precision: 0.5953 - val_Recall: 0.8124 - val_acc: 0.7614 - val_loss: 0.5095\n",
      "Epoch 53/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6035 - Recall: 0.8144 - acc: 0.7602 - loss: 0.4928 - val_Precision: 0.5903 - val_Recall: 0.8117 - val_acc: 0.7576 - val_loss: 0.5008\n",
      "Epoch 54/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6075 - Recall: 0.8010 - acc: 0.7655 - loss: 0.4952 - val_Precision: 0.5713 - val_Recall: 0.8317 - val_acc: 0.7445 - val_loss: 0.5240\n",
      "Epoch 55/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6061 - Recall: 0.8180 - acc: 0.7596 - loss: 0.4927 - val_Precision: 0.5892 - val_Recall: 0.8090 - val_acc: 0.7565 - val_loss: 0.5071\n",
      "Epoch 56/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6094 - Recall: 0.7948 - acc: 0.7615 - loss: 0.4973 - val_Precision: 0.5858 - val_Recall: 0.8193 - val_acc: 0.7549 - val_loss: 0.5059\n",
      "Epoch 57/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6080 - Recall: 0.8138 - acc: 0.7664 - loss: 0.4828 - val_Precision: 0.6097 - val_Recall: 0.7841 - val_acc: 0.7685 - val_loss: 0.4993\n",
      "Epoch 58/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6275 - Recall: 0.8021 - acc: 0.7720 - loss: 0.4886 - val_Precision: 0.6015 - val_Recall: 0.7972 - val_acc: 0.7643 - val_loss: 0.4979\n",
      "Epoch 59/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6080 - Recall: 0.8185 - acc: 0.7639 - loss: 0.4881 - val_Precision: 0.6127 - val_Recall: 0.7834 - val_acc: 0.7705 - val_loss: 0.4989\n",
      "Epoch 60/100\n",
      "\u001b[1m77/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6190 - Recall: 0.8014 - acc: 0.7639 - loss: 0.4987"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6186 - Recall: 0.8019 - acc: 0.7640 - loss: 0.4983 - val_Precision: 0.6250 - val_Recall: 0.7586 - val_acc: 0.7754 - val_loss: 0.4800\n",
      "Epoch 61/100\n",
      "\u001b[1m80/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - Precision: 0.6111 - Recall: 0.7850 - acc: 0.7623 - loss: 0.4948"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6112 - Recall: 0.7855 - acc: 0.7624 - loss: 0.4948 - val_Precision: 0.6262 - val_Recall: 0.7614 - val_acc: 0.7765 - val_loss: 0.4799\n",
      "Epoch 62/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6197 - Recall: 0.7978 - acc: 0.7706 - loss: 0.4855 - val_Precision: 0.5741 - val_Recall: 0.8393 - val_acc: 0.7474 - val_loss: 0.5177\n",
      "Epoch 63/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6102 - Recall: 0.8266 - acc: 0.7659 - loss: 0.4876 - val_Precision: 0.6111 - val_Recall: 0.7890 - val_acc: 0.7701 - val_loss: 0.4893\n",
      "Epoch 64/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6164 - Recall: 0.8102 - acc: 0.7654 - loss: 0.4907 - val_Precision: 0.6048 - val_Recall: 0.7883 - val_acc: 0.7656 - val_loss: 0.4917\n",
      "Epoch 65/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6086 - Recall: 0.8090 - acc: 0.7585 - loss: 0.4970 - val_Precision: 0.5864 - val_Recall: 0.8166 - val_acc: 0.7552 - val_loss: 0.5174\n",
      "Epoch 66/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6167 - Recall: 0.8066 - acc: 0.7646 - loss: 0.4923 - val_Precision: 0.6055 - val_Recall: 0.7897 - val_acc: 0.7663 - val_loss: 0.5051\n",
      "Epoch 67/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6086 - Recall: 0.7975 - acc: 0.7603 - loss: 0.4995 - val_Precision: 0.6035 - val_Recall: 0.7841 - val_acc: 0.7643 - val_loss: 0.5034\n",
      "Epoch 68/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6195 - Recall: 0.8070 - acc: 0.7669 - loss: 0.4972 - val_Precision: 0.5974 - val_Recall: 0.7848 - val_acc: 0.7601 - val_loss: 0.5059\n",
      "Epoch 69/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6149 - Recall: 0.7999 - acc: 0.7682 - loss: 0.4941 - val_Precision: 0.5884 - val_Recall: 0.8152 - val_acc: 0.7565 - val_loss: 0.5117\n",
      "Epoch 70/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6094 - Recall: 0.8049 - acc: 0.7615 - loss: 0.4875 - val_Precision: 0.5968 - val_Recall: 0.8097 - val_acc: 0.7623 - val_loss: 0.5007\n",
      "Epoch 71/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - Precision: 0.6139 - Recall: 0.8038 - acc: 0.7600 - loss: 0.5003 - val_Precision: 0.6006 - val_Recall: 0.7924 - val_acc: 0.7632 - val_loss: 0.5010\n",
      "Epoch 72/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6096 - Recall: 0.7941 - acc: 0.7589 - loss: 0.4968 - val_Precision: 0.5986 - val_Recall: 0.8062 - val_acc: 0.7632 - val_loss: 0.4994\n",
      "Epoch 73/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6192 - Recall: 0.8038 - acc: 0.7629 - loss: 0.4996 - val_Precision: 0.5991 - val_Recall: 0.7924 - val_acc: 0.7621 - val_loss: 0.4967\n",
      "Epoch 74/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6186 - Recall: 0.8104 - acc: 0.7675 - loss: 0.4837 - val_Precision: 0.5869 - val_Recall: 0.8131 - val_acc: 0.7552 - val_loss: 0.5153\n",
      "Epoch 75/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6190 - Recall: 0.8109 - acc: 0.7704 - loss: 0.4849 - val_Precision: 0.5855 - val_Recall: 0.8172 - val_acc: 0.7545 - val_loss: 0.4968\n",
      "Epoch 76/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6020 - Recall: 0.7953 - acc: 0.7589 - loss: 0.4940 - val_Precision: 0.5828 - val_Recall: 0.8303 - val_acc: 0.7536 - val_loss: 0.5222\n",
      "Epoch 77/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6170 - Recall: 0.8079 - acc: 0.7657 - loss: 0.4869 - val_Precision: 0.5766 - val_Recall: 0.8359 - val_acc: 0.7492 - val_loss: 0.5219\n",
      "Epoch 78/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6132 - Recall: 0.8053 - acc: 0.7646 - loss: 0.4929 - val_Precision: 0.5889 - val_Recall: 0.8110 - val_acc: 0.7565 - val_loss: 0.5062\n",
      "Epoch 79/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6085 - Recall: 0.7966 - acc: 0.7644 - loss: 0.4901 - val_Precision: 0.5662 - val_Recall: 0.8497 - val_acc: 0.7416 - val_loss: 0.5259\n",
      "Epoch 80/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6061 - Recall: 0.8195 - acc: 0.7593 - loss: 0.4963 - val_Precision: 0.6104 - val_Recall: 0.7910 - val_acc: 0.7698 - val_loss: 0.4966\n",
      "Epoch 81/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6215 - Recall: 0.7957 - acc: 0.7697 - loss: 0.4918 - val_Precision: 0.5965 - val_Recall: 0.8014 - val_acc: 0.7612 - val_loss: 0.5027\n",
      "Epoch 82/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6127 - Recall: 0.8074 - acc: 0.7647 - loss: 0.4858 - val_Precision: 0.6107 - val_Recall: 0.7821 - val_acc: 0.7690 - val_loss: 0.4900\n",
      "Epoch 83/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6071 - Recall: 0.8077 - acc: 0.7640 - loss: 0.4845 - val_Precision: 0.6136 - val_Recall: 0.7841 - val_acc: 0.7712 - val_loss: 0.4847\n",
      "Epoch 84/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6174 - Recall: 0.8003 - acc: 0.7637 - loss: 0.4898 - val_Precision: 0.6007 - val_Recall: 0.7979 - val_acc: 0.7638 - val_loss: 0.4924\n",
      "Epoch 85/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6009 - Recall: 0.8123 - acc: 0.7575 - loss: 0.4954 - val_Precision: 0.5900 - val_Recall: 0.8028 - val_acc: 0.7565 - val_loss: 0.5156\n",
      "Epoch 86/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6145 - Recall: 0.7977 - acc: 0.7660 - loss: 0.4880 - val_Precision: 0.5926 - val_Recall: 0.8117 - val_acc: 0.7594 - val_loss: 0.5062\n",
      "Epoch 87/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6142 - Recall: 0.8068 - acc: 0.7658 - loss: 0.4883 - val_Precision: 0.6079 - val_Recall: 0.7869 - val_acc: 0.7676 - val_loss: 0.5005\n",
      "Epoch 88/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6309 - Recall: 0.7915 - acc: 0.7711 - loss: 0.4915 - val_Precision: 0.5861 - val_Recall: 0.8241 - val_acc: 0.7556 - val_loss: 0.5130\n",
      "Epoch 89/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6174 - Recall: 0.8193 - acc: 0.7694 - loss: 0.4841 - val_Precision: 0.5831 - val_Recall: 0.8228 - val_acc: 0.7532 - val_loss: 0.5251\n",
      "Epoch 90/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6100 - Recall: 0.8085 - acc: 0.7636 - loss: 0.4858 - val_Precision: 0.5957 - val_Recall: 0.8069 - val_acc: 0.7612 - val_loss: 0.5117\n",
      "Epoch 91/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6202 - Recall: 0.7985 - acc: 0.7703 - loss: 0.4893 - val_Precision: 0.5841 - val_Recall: 0.8241 - val_acc: 0.7541 - val_loss: 0.5135\n",
      "Epoch 92/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6187 - Recall: 0.8130 - acc: 0.7716 - loss: 0.4848 - val_Precision: 0.5780 - val_Recall: 0.8303 - val_acc: 0.7498 - val_loss: 0.5166\n",
      "Epoch 93/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6175 - Recall: 0.8121 - acc: 0.7659 - loss: 0.4911 - val_Precision: 0.6071 - val_Recall: 0.7876 - val_acc: 0.7672 - val_loss: 0.4889\n",
      "Epoch 94/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6069 - Recall: 0.8160 - acc: 0.7665 - loss: 0.4824 - val_Precision: 0.5971 - val_Recall: 0.7993 - val_acc: 0.7614 - val_loss: 0.5033\n",
      "Epoch 95/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6089 - Recall: 0.8085 - acc: 0.7677 - loss: 0.4850 - val_Precision: 0.6039 - val_Recall: 0.7959 - val_acc: 0.7658 - val_loss: 0.5016\n",
      "Epoch 96/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6093 - Recall: 0.7957 - acc: 0.7630 - loss: 0.4971 - val_Precision: 0.5999 - val_Recall: 0.8034 - val_acc: 0.7638 - val_loss: 0.4934\n",
      "Epoch 97/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6280 - Recall: 0.8074 - acc: 0.7722 - loss: 0.4845 - val_Precision: 0.5901 - val_Recall: 0.8083 - val_acc: 0.7572 - val_loss: 0.5062\n",
      "Epoch 98/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6251 - Recall: 0.8037 - acc: 0.7706 - loss: 0.4905 - val_Precision: 0.6017 - val_Recall: 0.8021 - val_acc: 0.7650 - val_loss: 0.4898\n",
      "Epoch 99/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - Precision: 0.6082 - Recall: 0.8166 - acc: 0.7573 - loss: 0.4898 - val_Precision: 0.5631 - val_Recall: 0.8490 - val_acc: 0.7389 - val_loss: 0.5346\n",
      "Epoch 100/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - Precision: 0.6289 - Recall: 0.8246 - acc: 0.7718 - loss: 0.4819 - val_Precision: 0.6189 - val_Recall: 0.7738 - val_acc: 0.7734 - val_loss: 0.4861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/04 16:34:55 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: Cannot log input example or model signature for input with type <class 'pandas.core.frame.DataFrame'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n",
      "2025/05/04 16:34:55 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/05/04 16:35:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "Registered model 'DNN-model' already exists. Creating a new version of this model...\n",
      "Created version '8' of model 'DNN-model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8778    0.7732    0.8222      3047\n",
      "           1     0.6189    0.7738    0.6877      1450\n",
      "\n",
      "    accuracy                         0.7734      4497\n",
      "   macro avg     0.7483    0.7735    0.7550      4497\n",
      "weighted avg     0.7943    0.7734    0.7788      4497\n",
      "\n",
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 985us/step - Precision: 0.6184 - Recall: 0.7472 - acc: 0.7679 - loss: 0.4915\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='DNN'):#mlflow\n",
    "    mlflow.tensorflow.autolog()#mlflow    \n",
    "\n",
    "    n_input = X_train.shape[1]\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(256, input_shape=(n_input,), activation='relu',\n",
    "                    kernel_regularizer=regularizers.l2(0.001)))  # L2\n",
    "    model.add(Dropout(0.3))  # 增加 Dropout\n",
    "    model.add(Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    # 模型optimizer 和 learning rate\n",
    "\n",
    "\n",
    "    initial_lr = 0.001\n",
    "    from tensorflow.keras.optimizers import schedules\n",
    "    lr_schedule = schedules.ExponentialDecay(\n",
    "        initial_learning_rate=initial_lr,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True)\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    optimizer = Adam(learning_rate=lr_schedule)\n",
    "    model.summary()\n",
    "\n",
    "    mlflow.log_param(\"loss\", 'bce') #mlflow\n",
    "    model.compile(loss='bce', optimizer=optimizer, metrics=['acc', 'Recall', 'Precision'])\n",
    "\n",
    "    # EarlyStopping: 根據 val_loss 停止訓練\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "    # ModelCheckpoint: 儲存最佳模型\n",
    "    from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "    checkpoint = ModelCheckpoint('./models_temp/DNN_best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128, verbose=1, class_weight=class_weight_dict)\n",
    "\n",
    "    train_loss, train_acc, train_recall, train_precision = model.evaluate(X_train, y_train, verbose=0)\n",
    "    test_loss, test_acc, test_recall, test_precision = model.evaluate(X_test, y_test, verbose=0)\n",
    "    mlflow.log_metric(\"Train score\", train_acc)#mlflow\n",
    "    mlflow.log_metric(\"Test score\", test_acc)#mlflow\n",
    "    #註冊模型\n",
    "    run_id = mlflow.active_run().info.run_id#mlflow\n",
    "    result = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run_id}/model\",  # 你要用 mlflow.log_model 存的位置\n",
    "        name=\"DNN-model\"              # 註冊後的 model name\n",
    "    )\n",
    "    #confusion matrix\n",
    "    from sklearn.metrics import classification_report\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_class = (y_pred > 0.5).astype(int) \n",
    "    print(classification_report(y_test, y_pred_class, digits=4))\n",
    "\n",
    "    \n",
    "    model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95b5e33",
   "metadata": {},
   "source": [
    "### 結果分析：\n",
    "- Recall 提升了不少\n",
    "\n",
    "    - Recall（靈敏度）高達 ~82%，這對於偵測火災（正類）是好事，表示較少漏判火災發生。\n",
    "\n",
    "- Precision 稍低，但在接受範圍內\n",
    "\n",
    "    - Precision 約 57%，代表有一些假陽性，但 Recall 更重要時（例如防災應用），這是可以接受的 trade-off。\n",
    "\n",
    "- class_weight 有明顯效果\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9760495",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b8e08ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07754032",
   "metadata": {},
   "outputs": [],
   "source": [
    "#準備序列數據 (Prepare sequences)\n",
    "df_seq = df.sort_values(by=['YEAR', 'MONTH']).reset_index(drop=True)\n",
    "X_all = df_seq.drop(columns=['YEAR', 'MONTH', 'FIRE_START_DAY'])\n",
    "X_all = X_all.fillna(X.median())\n",
    "assert X_all.isna().sum().sum() == 0, \"There are still missing values in the dataset.\"\n",
    "y_all = df_seq['FIRE_START_DAY']\n",
    "def create_sequences(X, y, time_steps=12): #時間步長為12\n",
    "    Xs, ys = [], []\n",
    "    for i in range(len(X) - time_steps): #(11980, 12, 17) \n",
    "        Xs.append(X[i:(i + time_steps)])#(11980, 12, 17)\n",
    "        ys.append(y[i + time_steps])#(11980,)\n",
    "    #X[i:(i + time_steps)] 會取出從 i 到 i+time_steps 的資料，這樣就能夠形成一個時間序列的樣本。\n",
    "    return np.array(Xs), np.array(ys)\n",
    "\n",
    "#對於每個樣本，Xs 會包含過去12個時刻的特徵，而 ys 會包含12個時間步長後的目標變數。\n",
    "time_steps  = 12\n",
    "X_seq, y_seq = create_sequences(X_all, y_all, time_steps=time_steps)\n",
    "\n",
    "#訓練/測試集切分 (Train/test split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_seq, y_seq,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y_seq\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "93d0ac48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PRECIPITATION</th>\n",
       "      <th>MAX_TEMP</th>\n",
       "      <th>MIN_TEMP</th>\n",
       "      <th>AVG_WIND_SPEED</th>\n",
       "      <th>TEMP_RANGE</th>\n",
       "      <th>WIND_TEMP_RATIO</th>\n",
       "      <th>LAGGED_PRECIPITATION</th>\n",
       "      <th>LAGGED_AVG_WIND_SPEED</th>\n",
       "      <th>TEMP_VARIATION</th>\n",
       "      <th>PRECIPITATION_WIND_RATIO</th>\n",
       "      <th>SEASONAL_PRECIP_WIND</th>\n",
       "      <th>SEASONAL_DRYNESS</th>\n",
       "      <th>DIURNAL_TEMP_WIND</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "      <td>14988.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.032313</td>\n",
       "      <td>70.534961</td>\n",
       "      <td>56.494129</td>\n",
       "      <td>7.434878</td>\n",
       "      <td>14.040766</td>\n",
       "      <td>0.107016</td>\n",
       "      <td>0.226188</td>\n",
       "      <td>7.434198</td>\n",
       "      <td>14.040766</td>\n",
       "      <td>0.003538</td>\n",
       "      <td>2.022262</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>100.008452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.179538</td>\n",
       "      <td>7.263206</td>\n",
       "      <td>6.767461</td>\n",
       "      <td>2.129146</td>\n",
       "      <td>5.995150</td>\n",
       "      <td>0.035616</td>\n",
       "      <td>0.648705</td>\n",
       "      <td>1.387849</td>\n",
       "      <td>5.995150</td>\n",
       "      <td>0.018879</td>\n",
       "      <td>3.495890</td>\n",
       "      <td>0.027388</td>\n",
       "      <td>40.484232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.790000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.023553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.227143</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.160000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>51.000000</td>\n",
       "      <td>6.040000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.085395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.518571</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>72.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>57.000000</td>\n",
       "      <td>7.160000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.102222</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.478571</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>93.120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.120462</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>8.278571</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.370000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.530000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>26.170000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.459123</td>\n",
       "      <td>8.180000</td>\n",
       "      <td>13.932857</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.405188</td>\n",
       "      <td>14.760000</td>\n",
       "      <td>1.465000</td>\n",
       "      <td>405.900000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PRECIPITATION      MAX_TEMP      MIN_TEMP  AVG_WIND_SPEED  \\\n",
       "count   14988.000000  14988.000000  14988.000000    14988.000000   \n",
       "mean        0.032313     70.534961     56.494129        7.434878   \n",
       "std         0.179538      7.263206      6.767461        2.129146   \n",
       "min         0.000000     50.000000     33.000000        1.790000   \n",
       "25%         0.000000     65.000000     51.000000        6.040000   \n",
       "50%         0.000000     70.000000     57.000000        7.160000   \n",
       "75%         0.000000     75.000000     62.000000        8.500000   \n",
       "max         4.530000    106.000000     77.000000       26.170000   \n",
       "\n",
       "         TEMP_RANGE  WIND_TEMP_RATIO  LAGGED_PRECIPITATION  \\\n",
       "count  14988.000000     14988.000000          14988.000000   \n",
       "mean      14.040766         0.107016              0.226188   \n",
       "std        5.995150         0.035616              0.648705   \n",
       "min        2.000000         0.023553              0.000000   \n",
       "25%       10.000000         0.085395              0.000000   \n",
       "50%       12.000000         0.102222              0.000000   \n",
       "75%       17.000000         0.120462              0.060000   \n",
       "max       41.000000         0.459123              8.180000   \n",
       "\n",
       "       LAGGED_AVG_WIND_SPEED  TEMP_VARIATION  PRECIPITATION_WIND_RATIO  \\\n",
       "count           14988.000000    14988.000000              14988.000000   \n",
       "mean                7.434198       14.040766                  0.003538   \n",
       "std                 1.387849        5.995150                  0.018879   \n",
       "min                 3.227143        2.000000                  0.000000   \n",
       "25%                 6.518571       10.000000                  0.000000   \n",
       "50%                 7.478571       12.000000                  0.000000   \n",
       "75%                 8.278571       17.000000                  0.000000   \n",
       "max                13.932857       41.000000                  0.405188   \n",
       "\n",
       "       SEASONAL_PRECIP_WIND  SEASONAL_DRYNESS  DIURNAL_TEMP_WIND  \n",
       "count          14988.000000      14988.000000       14988.000000  \n",
       "mean               2.022262          0.003404         100.008452  \n",
       "std                3.495890          0.027388          40.484232  \n",
       "min                0.000000          0.000000           7.160000  \n",
       "25%                0.000000          0.000000          72.450000  \n",
       "50%                0.000000          0.000000          93.120000  \n",
       "75%                5.370000          0.000000         120.750000  \n",
       "max               14.760000          1.465000         405.900000  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all.describe() #檢查資料集的統計資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6505527f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ygz08\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_18 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m20,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_19 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m12,416\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_22 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m33\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,441</span> (130.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,441\u001b[0m (130.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,441</span> (130.63 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m33,441\u001b[0m (130.63 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m91/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.4661 - Recall: 0.5336 - acc: 0.6514 - loss: 0.7525\n",
      "Epoch 1: val_loss improved from inf to 0.66075, saving model to ./models_temp/LSTM_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - Precision: 0.4693 - Recall: 0.5382 - acc: 0.6535 - loss: 0.7502 - val_Precision: 0.5811 - val_Recall: 0.7173 - val_acc: 0.7346 - val_loss: 0.6608\n",
      "Epoch 2/100\n",
      "\u001b[1m90/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - Precision: 0.6089 - Recall: 0.7130 - acc: 0.7545 - loss: 0.6122\n",
      "Epoch 2: val_loss improved from 0.66075 to 0.56166, saving model to ./models_temp/LSTM_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - Precision: 0.6088 - Recall: 0.7128 - acc: 0.7543 - loss: 0.6121 - val_Precision: 0.6464 - val_Recall: 0.6217 - val_acc: 0.7617 - val_loss: 0.5617\n",
      "Epoch 3/100\n",
      "\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.6083 - Recall: 0.7254 - acc: 0.7461 - loss: 0.5946\n",
      "Epoch 3: val_loss did not improve from 0.56166\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6082 - Recall: 0.7255 - acc: 0.7462 - loss: 0.5943 - val_Precision: 0.5896 - val_Recall: 0.7515 - val_acc: 0.7440 - val_loss: 0.5758\n",
      "Epoch 4/100\n",
      "\u001b[1m88/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5851 - Recall: 0.7378 - acc: 0.7394 - loss: 0.5686\n",
      "Epoch 4: val_loss did not improve from 0.56166\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.5856 - Recall: 0.7379 - acc: 0.7397 - loss: 0.5683 - val_Precision: 0.5475 - val_Recall: 0.8169 - val_acc: 0.7153 - val_loss: 0.5937\n",
      "Epoch 5/100\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5843 - Recall: 0.7660 - acc: 0.7411 - loss: 0.5564\n",
      "Epoch 5: val_loss improved from 0.56166 to 0.54433, saving model to ./models_temp/LSTM_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.5844 - Recall: 0.7659 - acc: 0.7411 - loss: 0.5564 - val_Precision: 0.6031 - val_Recall: 0.7324 - val_acc: 0.7513 - val_loss: 0.5443\n",
      "Epoch 6/100\n",
      "\u001b[1m91/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5845 - Recall: 0.7535 - acc: 0.7464 - loss: 0.5528\n",
      "Epoch 6: val_loss did not improve from 0.54433\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.5849 - Recall: 0.7535 - acc: 0.7464 - loss: 0.5528 - val_Precision: 0.5587 - val_Recall: 0.8139 - val_acc: 0.7250 - val_loss: 0.5803\n",
      "Epoch 7/100\n",
      "\u001b[1m92/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.5865 - Recall: 0.7763 - acc: 0.7404 - loss: 0.5474\n",
      "Epoch 7: val_loss improved from 0.54433 to 0.51860, saving model to ./models_temp/LSTM_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.5867 - Recall: 0.7760 - acc: 0.7407 - loss: 0.5473 - val_Precision: 0.6391 - val_Recall: 0.6610 - val_acc: 0.7637 - val_loss: 0.5186\n",
      "Epoch 8/100\n",
      "\u001b[1m87/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.5940 - Recall: 0.7617 - acc: 0.7445 - loss: 0.5398\n",
      "Epoch 8: val_loss did not improve from 0.51860\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.5938 - Recall: 0.7614 - acc: 0.7447 - loss: 0.5401 - val_Precision: 0.5403 - val_Recall: 0.8219 - val_acc: 0.7089 - val_loss: 0.5866\n",
      "Epoch 9/100\n",
      "\u001b[1m91/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5879 - Recall: 0.7574 - acc: 0.7402 - loss: 0.5462\n",
      "Epoch 9: val_loss did not improve from 0.51860\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.5880 - Recall: 0.7574 - acc: 0.7404 - loss: 0.5460 - val_Precision: 0.6062 - val_Recall: 0.7264 - val_acc: 0.7527 - val_loss: 0.5382\n",
      "Epoch 10/100\n",
      "\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5848 - Recall: 0.7323 - acc: 0.7434 - loss: 0.5439\n",
      "Epoch 10: val_loss did not improve from 0.51860\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.5849 - Recall: 0.7327 - acc: 0.7434 - loss: 0.5438 - val_Precision: 0.5873 - val_Recall: 0.7847 - val_acc: 0.7457 - val_loss: 0.5453\n",
      "Epoch 11/100\n",
      "\u001b[1m93/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5828 - Recall: 0.7713 - acc: 0.7427 - loss: 0.5360\n",
      "Epoch 11: val_loss did not improve from 0.51860\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.5829 - Recall: 0.7712 - acc: 0.7428 - loss: 0.5360 - val_Precision: 0.5891 - val_Recall: 0.7414 - val_acc: 0.7427 - val_loss: 0.5456\n",
      "Epoch 12/100\n",
      "\u001b[1m92/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5777 - Recall: 0.7537 - acc: 0.7371 - loss: 0.5394\n",
      "Epoch 12: val_loss did not improve from 0.51860\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.5781 - Recall: 0.7540 - acc: 0.7374 - loss: 0.5392 - val_Precision: 0.5702 - val_Recall: 0.8008 - val_acc: 0.7336 - val_loss: 0.5580\n",
      "Epoch 13/100\n",
      "\u001b[1m91/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.5830 - Recall: 0.7581 - acc: 0.7440 - loss: 0.5399\n",
      "Epoch 13: val_loss did not improve from 0.51860\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.5833 - Recall: 0.7586 - acc: 0.7441 - loss: 0.5396 - val_Precision: 0.5557 - val_Recall: 0.8129 - val_acc: 0.7223 - val_loss: 0.5712\n",
      "Epoch 14/100\n",
      "\u001b[1m90/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5883 - Recall: 0.7588 - acc: 0.7448 - loss: 0.5317\n",
      "Epoch 14: val_loss did not improve from 0.51860\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.5883 - Recall: 0.7591 - acc: 0.7447 - loss: 0.5316 - val_Precision: 0.5281 - val_Recall: 0.8521 - val_acc: 0.6983 - val_loss: 0.5825\n",
      "Epoch 15/100\n",
      "\u001b[1m92/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5793 - Recall: 0.7674 - acc: 0.7348 - loss: 0.5367\n",
      "Epoch 15: val_loss did not improve from 0.51860\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.5795 - Recall: 0.7673 - acc: 0.7350 - loss: 0.5366 - val_Precision: 0.5218 - val_Recall: 0.8662 - val_acc: 0.6923 - val_loss: 0.5831\n",
      "Epoch 16/100\n",
      "\u001b[1m91/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5830 - Recall: 0.7829 - acc: 0.7431 - loss: 0.5260\n",
      "Epoch 16: val_loss did not improve from 0.51860\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.5834 - Recall: 0.7822 - acc: 0.7432 - loss: 0.5262 - val_Precision: 0.5930 - val_Recall: 0.7666 - val_acc: 0.7480 - val_loss: 0.5293\n",
      "Epoch 17/100\n",
      "\u001b[1m90/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5828 - Recall: 0.7836 - acc: 0.7398 - loss: 0.5322\n",
      "Epoch 17: val_loss did not improve from 0.51860\n",
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.5832 - Recall: 0.7831 - acc: 0.7402 - loss: 0.5320 - val_Precision: 0.5685 - val_Recall: 0.8139 - val_acc: 0.7333 - val_loss: 0.5468\n",
      "Epoch 17: early stopping\n",
      "Restoring model weights from the end of the best epoch: 7.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 203ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'LSTM-model' already exists. Creating a new version of this model...\n",
      "Created version '8' of model 'LSTM-model'.\n",
      "Registered model 'LSTM-model' already exists. Creating a new version of this model...\n",
      "Created version '9' of model 'LSTM-model'.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# ⚠️ 確保 y 是 numpy array 且為 float32\n",
    "y_train = y_train.astype(np.float32)\n",
    "y_test = y_test.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "X_train = X_train.astype(np.float32)\n",
    "\n",
    "# ⚖️ 計算 class_weight\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weight_dict = dict(zip(classes, class_weights))\n",
    "\n",
    "# 🎯 模型訓練\n",
    "with mlflow.start_run(run_name='LSTM'):\n",
    "    mlflow.tensorflow.autolog()\n",
    "\n",
    "    model = Sequential([\n",
    "        LSTM(64, input_shape=(X_train.shape[1], X_train.shape[2]), return_sequences=True,\n",
    "             kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.3),\n",
    "        LSTM(32, kernel_regularizer=l2(0.001)),\n",
    "        Dropout(0.3),\n",
    "        Dense(1, activation='sigmoid', kernel_regularizer=l2(0.001))\n",
    "    ])\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='bce', optimizer=Adam(learning_rate=0.0005), metrics=['acc', 'Recall', 'Precision'])\n",
    "\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "    checkpoint = ModelCheckpoint('./models_temp/LSTM_best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=100,\n",
    "        batch_size=128,\n",
    "        callbacks=[early_stop, checkpoint],\n",
    "        class_weight=class_weight_dict,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # 評估\n",
    "    train_loss, train_acc, train_recall, train_precision = model.evaluate(X_train, y_train, verbose=0)\n",
    "    test_loss, test_acc, test_recall, test_precision = model.evaluate(X_test, y_test, verbose=0)\n",
    "    mlflow.log_metric(\"Train score\", train_acc)#mlflow\n",
    "    mlflow.log_metric(\"Test score\", test_acc)#mlflow\n",
    "    #註冊模型\n",
    "    run_id = mlflow.active_run().info.run_id#mlflow\n",
    "    result = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run_id}/model\",  # 你要用 mlflow.log_model 存的位置\n",
    "        name=\"LSTM-model\"              # 註冊後的 model name\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b93e2b5",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Attention mechanism"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1069101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['FIRE_START_DAY'], axis=1)\n",
    "y = df['FIRE_START_DAY']\n",
    "X = X.fillna(X.median())\n",
    "assert X.isna().sum().sum() == 0, \"There are still missing values in the dataset.\"\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ea275db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_13\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_13\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">76</span> │ input_layer_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_31[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ reshape_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_33[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │ flatten_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_21[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │ dropout_34[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_13      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m19\u001b[0m)        │         \u001b[38;5;34m76\u001b[0m │ input_layer_13[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │      \u001b[38;5;34m2,560\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ dropout_31[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │     \u001b[38;5;34m66,048\u001b[0m │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ reshape_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dropout_33[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m16,512\u001b[0m │ flatten_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_21[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDropout\u001b[0m)           │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │        \u001b[38;5;34m129\u001b[0m │ dropout_34[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,325</span> (333.30 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m85,325\u001b[0m (333.30 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">85,287</span> (333.15 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m85,287\u001b[0m (333.15 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38</span> (152.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m38\u001b[0m (152.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/03 21:57:42 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'pandas.core.frame.DataFrame'>. Dataset logging skipped.\n",
      "2025/05/03 21:57:42 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: 'DataFrame' object has no attribute 'flatten'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.5878 - Recall: 0.7180 - acc: 0.7401 - loss: 0.5509\n",
      "Epoch 1: val_loss improved from inf to 20.11911, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - Precision: 0.5879 - Recall: 0.7194 - acc: 0.7402 - loss: 0.5502 - val_Precision: 0.3224 - val_Recall: 1.0000 - val_acc: 0.3224 - val_loss: 20.1191\n",
      "Epoch 2/100\n",
      "\u001b[1m79/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.5903 - Recall: 0.8170 - acc: 0.7449 - loss: 0.5033\n",
      "Epoch 2: val_loss improved from 20.11911 to 1.25602, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.5904 - Recall: 0.8160 - acc: 0.7450 - loss: 0.5034 - val_Precision: 0.3310 - val_Recall: 0.9993 - val_acc: 0.3485 - val_loss: 1.2560\n",
      "Epoch 3/100\n",
      "\u001b[1m78/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.5865 - Recall: 0.8013 - acc: 0.7450 - loss: 0.5009\n",
      "Epoch 3: val_loss improved from 1.25602 to 0.60706, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.5865 - Recall: 0.8014 - acc: 0.7449 - loss: 0.5011 - val_Precision: 0.4992 - val_Recall: 0.8414 - val_acc: 0.6767 - val_loss: 0.6071\n",
      "Epoch 4/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6047 - Recall: 0.7908 - acc: 0.7528 - loss: 0.5101\n",
      "Epoch 4: val_loss did not improve from 0.60706\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6046 - Recall: 0.7909 - acc: 0.7527 - loss: 0.5100 - val_Precision: 0.4656 - val_Recall: 0.8862 - val_acc: 0.6353 - val_loss: 0.6598\n",
      "Epoch 5/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.5914 - Recall: 0.7955 - acc: 0.7494 - loss: 0.5006\n",
      "Epoch 5: val_loss did not improve from 0.60706\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.5915 - Recall: 0.7956 - acc: 0.7494 - loss: 0.5006 - val_Precision: 0.5020 - val_Recall: 0.8538 - val_acc: 0.6798 - val_loss: 0.6091\n",
      "Epoch 6/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.5891 - Recall: 0.7987 - acc: 0.7483 - loss: 0.4955\n",
      "Epoch 6: val_loss improved from 0.60706 to 0.56355, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.5892 - Recall: 0.7988 - acc: 0.7484 - loss: 0.4955 - val_Precision: 0.5290 - val_Recall: 0.8483 - val_acc: 0.7076 - val_loss: 0.5635\n",
      "Epoch 7/100\n",
      "\u001b[1m75/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.5857 - Recall: 0.7915 - acc: 0.7482 - loss: 0.4984\n",
      "Epoch 7: val_loss improved from 0.56355 to 0.51582, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - Precision: 0.5864 - Recall: 0.7924 - acc: 0.7483 - loss: 0.4984 - val_Precision: 0.5852 - val_Recall: 0.7745 - val_acc: 0.7503 - val_loss: 0.5158\n",
      "Epoch 8/100\n",
      "\u001b[1m76/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6073 - Recall: 0.7819 - acc: 0.7617 - loss: 0.4912\n",
      "Epoch 8: val_loss improved from 0.51582 to 0.49418, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6065 - Recall: 0.7830 - acc: 0.7609 - loss: 0.4913 - val_Precision: 0.5905 - val_Recall: 0.7717 - val_acc: 0.7538 - val_loss: 0.4942\n",
      "Epoch 9/100\n",
      "\u001b[1m80/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.6007 - Recall: 0.7897 - acc: 0.7516 - loss: 0.4896\n",
      "Epoch 9: val_loss did not improve from 0.49418\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6007 - Recall: 0.7898 - acc: 0.7517 - loss: 0.4898 - val_Precision: 0.5671 - val_Recall: 0.8103 - val_acc: 0.7394 - val_loss: 0.5253\n",
      "Epoch 10/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.6054 - Recall: 0.8079 - acc: 0.7611 - loss: 0.4860\n",
      "Epoch 10: val_loss did not improve from 0.49418\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6052 - Recall: 0.8079 - acc: 0.7610 - loss: 0.4862 - val_Precision: 0.5663 - val_Recall: 0.8186 - val_acc: 0.7394 - val_loss: 0.5186\n",
      "Epoch 11/100\n",
      "\u001b[1m78/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6046 - Recall: 0.8087 - acc: 0.7573 - loss: 0.4928\n",
      "Epoch 11: val_loss did not improve from 0.49418\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6047 - Recall: 0.8088 - acc: 0.7575 - loss: 0.4927 - val_Precision: 0.5776 - val_Recall: 0.8083 - val_acc: 0.7476 - val_loss: 0.5166\n",
      "Epoch 12/100\n",
      "\u001b[1m79/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.6104 - Recall: 0.8111 - acc: 0.7615 - loss: 0.4848\n",
      "Epoch 12: val_loss did not improve from 0.49418\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6103 - Recall: 0.8103 - acc: 0.7614 - loss: 0.4850 - val_Precision: 0.5785 - val_Recall: 0.7876 - val_acc: 0.7465 - val_loss: 0.5088\n",
      "Epoch 13/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.5984 - Recall: 0.8125 - acc: 0.7508 - loss: 0.4892\n",
      "Epoch 13: val_loss improved from 0.49418 to 0.49343, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.5985 - Recall: 0.8124 - acc: 0.7509 - loss: 0.4893 - val_Precision: 0.5912 - val_Recall: 0.7710 - val_acc: 0.7543 - val_loss: 0.4934\n",
      "Epoch 14/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.5989 - Recall: 0.7974 - acc: 0.7530 - loss: 0.4937\n",
      "Epoch 14: val_loss did not improve from 0.49343\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.5989 - Recall: 0.7975 - acc: 0.7531 - loss: 0.4935 - val_Precision: 0.5890 - val_Recall: 0.8014 - val_acc: 0.7556 - val_loss: 0.5179\n",
      "Epoch 15/100\n",
      "\u001b[1m79/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - Precision: 0.5914 - Recall: 0.8021 - acc: 0.7514 - loss: 0.4946\n",
      "Epoch 15: val_loss did not improve from 0.49343\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.5920 - Recall: 0.8020 - acc: 0.7516 - loss: 0.4945 - val_Precision: 0.5883 - val_Recall: 0.7952 - val_acc: 0.7545 - val_loss: 0.4960\n",
      "Epoch 16/100\n",
      "\u001b[1m76/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.6088 - Recall: 0.8065 - acc: 0.7622 - loss: 0.4791\n",
      "Epoch 16: val_loss did not improve from 0.49343\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6082 - Recall: 0.8063 - acc: 0.7617 - loss: 0.4799 - val_Precision: 0.5570 - val_Recall: 0.8359 - val_acc: 0.7327 - val_loss: 0.5372\n",
      "Epoch 17/100\n",
      "\u001b[1m76/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6040 - Recall: 0.8118 - acc: 0.7594 - loss: 0.4872\n",
      "Epoch 17: val_loss did not improve from 0.49343\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6039 - Recall: 0.8115 - acc: 0.7592 - loss: 0.4873 - val_Precision: 0.5892 - val_Recall: 0.7786 - val_acc: 0.7536 - val_loss: 0.5002\n",
      "Epoch 18/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6232 - Recall: 0.8147 - acc: 0.7651 - loss: 0.4807\n",
      "Epoch 18: val_loss improved from 0.49343 to 0.49209, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6230 - Recall: 0.8146 - acc: 0.7650 - loss: 0.4808 - val_Precision: 0.5952 - val_Recall: 0.7634 - val_acc: 0.7563 - val_loss: 0.4921\n",
      "Epoch 19/100\n",
      "\u001b[1m79/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6096 - Recall: 0.7879 - acc: 0.7618 - loss: 0.4763\n",
      "Epoch 19: val_loss did not improve from 0.49209\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6094 - Recall: 0.7883 - acc: 0.7615 - loss: 0.4767 - val_Precision: 0.5707 - val_Recall: 0.8103 - val_acc: 0.7423 - val_loss: 0.5130\n",
      "Epoch 20/100\n",
      "\u001b[1m78/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.5966 - Recall: 0.8057 - acc: 0.7516 - loss: 0.4855\n",
      "Epoch 20: val_loss did not improve from 0.49209\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.5970 - Recall: 0.8055 - acc: 0.7520 - loss: 0.4853 - val_Precision: 0.5842 - val_Recall: 0.7993 - val_acc: 0.7518 - val_loss: 0.5345\n",
      "Epoch 21/100\n",
      "\u001b[1m80/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.5911 - Recall: 0.7955 - acc: 0.7519 - loss: 0.4870\n",
      "Epoch 21: val_loss did not improve from 0.49209\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.5917 - Recall: 0.7956 - acc: 0.7521 - loss: 0.4870 - val_Precision: 0.5867 - val_Recall: 0.7931 - val_acc: 0.7532 - val_loss: 0.4978\n",
      "Epoch 22/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6054 - Recall: 0.8105 - acc: 0.7574 - loss: 0.4937\n",
      "Epoch 22: val_loss improved from 0.49209 to 0.47882, saving model to ./models_temp/attention_best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6055 - Recall: 0.8105 - acc: 0.7575 - loss: 0.4934 - val_Precision: 0.6049 - val_Recall: 0.7717 - val_acc: 0.7638 - val_loss: 0.4788\n",
      "Epoch 23/100\n",
      "\u001b[1m74/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6101 - Recall: 0.8044 - acc: 0.7616 - loss: 0.4810\n",
      "Epoch 23: val_loss did not improve from 0.47882\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6100 - Recall: 0.8048 - acc: 0.7617 - loss: 0.4810 - val_Precision: 0.5659 - val_Recall: 0.8324 - val_acc: 0.7400 - val_loss: 0.5129\n",
      "Epoch 24/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6060 - Recall: 0.8276 - acc: 0.7641 - loss: 0.4699\n",
      "Epoch 24: val_loss did not improve from 0.47882\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6059 - Recall: 0.8273 - acc: 0.7639 - loss: 0.4702 - val_Precision: 0.5963 - val_Recall: 0.7731 - val_acc: 0.7581 - val_loss: 0.4964\n",
      "Epoch 25/100\n",
      "\u001b[1m78/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6129 - Recall: 0.7842 - acc: 0.7592 - loss: 0.4818\n",
      "Epoch 25: val_loss did not improve from 0.47882\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6127 - Recall: 0.7852 - acc: 0.7594 - loss: 0.4817 - val_Precision: 0.5591 - val_Recall: 0.8476 - val_acc: 0.7354 - val_loss: 0.5205\n",
      "Epoch 26/100\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6188 - Recall: 0.8123 - acc: 0.7654 - loss: 0.4846\n",
      "Epoch 26: val_loss did not improve from 0.47882\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6188 - Recall: 0.8123 - acc: 0.7654 - loss: 0.4846 - val_Precision: 0.5746 - val_Recall: 0.8159 - val_acc: 0.7458 - val_loss: 0.5225\n",
      "Epoch 27/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6181 - Recall: 0.8108 - acc: 0.7676 - loss: 0.4677\n",
      "Epoch 27: val_loss did not improve from 0.47882\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6179 - Recall: 0.8107 - acc: 0.7674 - loss: 0.4680 - val_Precision: 0.5841 - val_Recall: 0.8021 - val_acc: 0.7521 - val_loss: 0.4966\n",
      "Epoch 28/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6069 - Recall: 0.8156 - acc: 0.7588 - loss: 0.4731\n",
      "Epoch 28: val_loss did not improve from 0.47882\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6069 - Recall: 0.8156 - acc: 0.7588 - loss: 0.4733 - val_Precision: 0.6062 - val_Recall: 0.7600 - val_acc: 0.7634 - val_loss: 0.4857\n",
      "Epoch 29/100\n",
      "\u001b[1m77/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6149 - Recall: 0.7847 - acc: 0.7658 - loss: 0.4777\n",
      "Epoch 29: val_loss did not improve from 0.47882\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6148 - Recall: 0.7857 - acc: 0.7656 - loss: 0.4778 - val_Precision: 0.5980 - val_Recall: 0.7931 - val_acc: 0.7614 - val_loss: 0.4911\n",
      "Epoch 30/100\n",
      "\u001b[1m81/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6132 - Recall: 0.8012 - acc: 0.7573 - loss: 0.4830\n",
      "Epoch 30: val_loss did not improve from 0.47882\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6132 - Recall: 0.8011 - acc: 0.7574 - loss: 0.4830 - val_Precision: 0.5807 - val_Recall: 0.8014 - val_acc: 0.7494 - val_loss: 0.5012\n",
      "Epoch 31/100\n",
      "\u001b[1m78/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - Precision: 0.6232 - Recall: 0.8267 - acc: 0.7709 - loss: 0.4675\n",
      "Epoch 31: val_loss did not improve from 0.47882\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - Precision: 0.6226 - Recall: 0.8258 - acc: 0.7705 - loss: 0.4681 - val_Precision: 0.5910 - val_Recall: 0.7772 - val_acc: 0.7547 - val_loss: 0.4921\n",
      "Epoch 32/100\n",
      "\u001b[1m77/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - Precision: 0.6188 - Recall: 0.7996 - acc: 0.7677 - loss: 0.4733\n",
      "Epoch 32: val_loss did not improve from 0.47882\n",
      "\u001b[1m82/82\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - Precision: 0.6180 - Recall: 0.8000 - acc: 0.7671 - loss: 0.4736 - val_Precision: 0.5858 - val_Recall: 0.7841 - val_acc: 0.7516 - val_loss: 0.5112\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 22.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/03 21:58:07 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: Cannot log input example or model signature for input with type <class 'pandas.core.frame.DataFrame'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n",
      "2025/05/03 21:58:07 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/05/03 21:58:13 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/141\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - Precision: 0.3077 - Recall: 0.5714 - acc: 0.6250 - loss: 0.7323"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'attention-model' already exists. Creating a new version of this model...\n",
      "Created version '6' of model 'attention-model'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m141/141\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - Precision: 0.6040 - Recall: 0.7525 - acc: 0.7591 - loss: 0.4873\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, MultiHeadAttention, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "#\n",
    "with mlflow.start_run(run_name='AttentionMechanisim'):#mlflow\n",
    "    mlflow.tensorflow.autolog()#mlflow    \n",
    "    n_input = X_train.shape[1]\n",
    "    # Model\n",
    "    # 定義模型\n",
    "    input_layer = Input(shape=(n_input,))\n",
    "    x = BatchNormalization()(input_layer)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    # Reshape 輸入，以便進行注意力機制（將它變成三維張量）\n",
    "    x = Reshape((1, 128))(x)  # 假設每個樣本有 128 個特徵，這樣就會有 1 個時間步\n",
    "    # 添加多頭注意力層\n",
    "    x_attention = MultiHeadAttention(num_heads=4, key_dim=32)(x, x)  # query, key 和 value 都是 x\n",
    "    x_attention = Dropout(0.1)(x_attention)\n",
    "    # 將注意力層的輸出展平\n",
    "    x_flattened = Flatten()(x_attention)\n",
    "    # 經過展平後的處理\n",
    "    x = Dense(128, activation='relu')(x_flattened)\n",
    "    x = Dropout(0.1)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "\n",
    "    # Model\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.summary()\n",
    "    # 模型optimizer 和 learning rate\n",
    "    initial_lr = 0.001\n",
    "    from tensorflow.keras.optimizers import schedules\n",
    "    lr_schedule = schedules.ExponentialDecay(\n",
    "        initial_learning_rate=initial_lr,\n",
    "        decay_steps=100000,\n",
    "        decay_rate=0.96,\n",
    "        staircase=True)\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    optimizer = Adam(learning_rate=lr_schedule)\n",
    "\n",
    "    model.compile(loss='bce', optimizer=optimizer, metrics=['acc', 'Recall', 'Precision'])\n",
    "    # EarlyStopping: 根據 val_loss 停止訓練\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True)\n",
    "    # ModelCheckpoint: 儲存最佳模型\n",
    "    checkpoint = ModelCheckpoint('./models_temp/attention_best_model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=128, verbose=1, callbacks=[early_stop, checkpoint], class_weight=class_weight_dict)\n",
    "\n",
    "    train_loss, train_acc, train_recall, train_precision = model.evaluate(X_train, y_train, verbose=0)\n",
    "    test_loss, test_acc, test_recall, test_precision = model.evaluate(X_test, y_test, verbose=0)\n",
    "    mlflow.log_metric(\"Train score\", train_acc)#mlflow\n",
    "    mlflow.log_metric(\"Test score\", test_acc)#mlflow\n",
    "    #註冊模型\n",
    "    run_id = mlflow.active_run().info.run_id#mlflow\n",
    "    result = mlflow.register_model(\n",
    "        model_uri=f\"runs:/{run_id}/model\",  # 你要用 mlflow.log_model 存的位置\n",
    "        name=\"attention-model\"              # 註冊後的 model name\n",
    "    )\n",
    "\n",
    "    # 評估模型\n",
    "    model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97836e68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
